2024-12-20 22:41:43,504 - INFO - workdir: ./pre-trained/5fold/complex, adsorbate: complex
2024-12-20 22:41:44,189 - INFO - dataset size: 1679, batch size: 8
2024-12-20 22:41:44,189 - INFO - train/valid/test size: 1343/336/0
2024-12-20 22:41:45,835 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 22:41:47,344 - INFO - initial lr: 0.000200000, meanAE: 0.7450605578959548
2024-12-20 22:41:57,284 - INFO - Epoch 1, train_loss: 0.606208, val_loss: 0.566115, val_mae: 0.576619
2024-12-20 22:42:07,203 - INFO - Epoch 2, train_loss: 0.558798, val_loss: 0.512331, val_mae: 0.545507
2024-12-20 22:42:17,010 - INFO - Epoch 3, train_loss: 0.533911, val_loss: 0.492764, val_mae: 0.533187
2024-12-20 22:42:26,890 - INFO - Epoch 4, train_loss: 0.491359, val_loss: 0.460392, val_mae: 0.501110
2024-12-20 22:42:36,697 - INFO - Epoch 5, train_loss: 0.394047, val_loss: 0.371362, val_mae: 0.468702
2024-12-20 22:42:46,581 - INFO - Epoch 6, train_loss: 0.248239, val_loss: 0.195777, val_mae: 0.335071
2024-12-20 22:42:56,399 - INFO - Epoch 7, train_loss: 0.170904, val_loss: 0.141518, val_mae: 0.273891
2024-12-20 22:43:06,424 - INFO - Epoch 8, train_loss: 0.138295, val_loss: 0.125979, val_mae: 0.265775
2024-12-20 22:43:16,462 - INFO - Epoch 9, train_loss: 0.120463, val_loss: 0.106579, val_mae: 0.248628
2024-12-20 22:43:26,464 - INFO - Epoch 10, train_loss: 0.088988, val_loss: 0.067974, val_mae: 0.195075
2024-12-20 22:43:36,240 - INFO - Epoch 11, train_loss: 0.072468, val_loss: 0.070143, val_mae: 0.209320
2024-12-20 22:43:45,998 - INFO - Epoch 12, train_loss: 0.052838, val_loss: 0.044639, val_mae: 0.158097
2024-12-20 22:43:55,877 - INFO - Epoch 13, train_loss: 0.049744, val_loss: 0.038730, val_mae: 0.145812
2024-12-20 22:44:05,634 - INFO - Epoch 14, train_loss: 0.041981, val_loss: 0.077463, val_mae: 0.200273
2024-12-20 22:44:15,404 - INFO - Epoch 15, train_loss: 0.060919, val_loss: 0.054958, val_mae: 0.179115
2024-12-20 22:44:25,225 - INFO - Epoch 16, train_loss: 0.033285, val_loss: 0.046778, val_mae: 0.163655
2024-12-20 22:44:35,064 - INFO - Epoch 17, train_loss: 0.039704, val_loss: 0.039395, val_mae: 0.154134
2024-12-20 22:44:44,835 - INFO - Epoch 18, train_loss: 0.030913, val_loss: 0.035260, val_mae: 0.142332
2024-12-20 22:44:54,587 - INFO - Epoch 19, train_loss: 0.020870, val_loss: 0.038118, val_mae: 0.143902
2024-12-20 22:45:04,472 - INFO - Epoch 20, train_loss: 0.025949, val_loss: 0.032590, val_mae: 0.137180
2024-12-20 22:45:14,372 - INFO - Epoch 21, train_loss: 0.023557, val_loss: 0.033594, val_mae: 0.136609
2024-12-20 22:45:24,363 - INFO - Epoch 22, train_loss: 0.029841, val_loss: 0.044828, val_mae: 0.169898
2024-12-20 22:45:34,065 - INFO - Epoch 23, train_loss: 0.033582, val_loss: 0.025994, val_mae: 0.122718
2024-12-20 22:45:43,777 - INFO - Epoch 24, train_loss: 0.032478, val_loss: 0.082268, val_mae: 0.230318
2024-12-20 22:45:53,585 - INFO - Epoch 25, train_loss: 0.035561, val_loss: 0.032302, val_mae: 0.133517
2024-12-20 22:46:03,380 - INFO - Epoch 26, train_loss: 0.017497, val_loss: 0.030566, val_mae: 0.139425
2024-12-20 22:46:13,246 - INFO - Epoch 27, train_loss: 0.029661, val_loss: 0.053558, val_mae: 0.179636
2024-12-20 22:46:23,173 - INFO - Epoch 28, train_loss: 0.028177, val_loss: 0.033579, val_mae: 0.137172
2024-12-20 22:46:33,082 - INFO - Epoch 29, train_loss: 0.034790, val_loss: 0.048088, val_mae: 0.160736
2024-12-20 22:46:42,948 - INFO - Epoch 30, train_loss: 0.025621, val_loss: 0.028568, val_mae: 0.132342
2024-12-20 22:46:52,873 - INFO - Epoch 31, train_loss: 0.019139, val_loss: 0.026528, val_mae: 0.121924
2024-12-20 22:47:02,684 - INFO - Epoch 32, train_loss: 0.013216, val_loss: 0.017745, val_mae: 0.095121
2024-12-20 22:47:12,572 - INFO - Epoch 33, train_loss: 0.012678, val_loss: 0.032755, val_mae: 0.141733
2024-12-20 22:47:22,462 - INFO - Epoch 34, train_loss: 0.016137, val_loss: 0.017838, val_mae: 0.098407
2024-12-20 22:47:32,258 - INFO - Epoch 35, train_loss: 0.012967, val_loss: 0.018425, val_mae: 0.104029
2024-12-20 22:47:42,010 - INFO - Epoch 36, train_loss: 0.012174, val_loss: 0.024297, val_mae: 0.117136
2024-12-20 22:47:51,995 - INFO - Epoch 37, train_loss: 0.011608, val_loss: 0.018684, val_mae: 0.100210
2024-12-20 22:48:01,961 - INFO - Epoch 38, train_loss: 0.022239, val_loss: 0.028726, val_mae: 0.129887
2024-12-20 22:48:11,743 - INFO - Epoch 39, train_loss: 0.027775, val_loss: 0.028370, val_mae: 0.122295
2024-12-20 22:48:21,659 - INFO - Epoch 40, train_loss: 0.015508, val_loss: 0.024345, val_mae: 0.111210
2024-12-20 22:48:31,664 - INFO - Epoch 41, train_loss: 0.018204, val_loss: 0.032886, val_mae: 0.129407
2024-12-20 22:48:41,625 - INFO - Epoch 42, train_loss: 0.010656, val_loss: 0.018283, val_mae: 0.100347
2024-12-20 22:48:51,499 - INFO - Epoch 43, train_loss: 0.012321, val_loss: 0.017723, val_mae: 0.096615
2024-12-20 22:49:01,430 - INFO - Epoch 44, train_loss: 0.008030, val_loss: 0.020472, val_mae: 0.101714
2024-12-20 22:49:11,373 - INFO - Epoch 45, train_loss: 0.010595, val_loss: 0.017765, val_mae: 0.097619
2024-12-20 22:49:21,259 - INFO - Epoch 46, train_loss: 0.008194, val_loss: 0.017415, val_mae: 0.094018
2024-12-20 22:49:31,020 - INFO - Epoch 47, train_loss: 0.022272, val_loss: 0.021995, val_mae: 0.106883
2024-12-20 22:49:40,822 - INFO - Epoch 48, train_loss: 0.012662, val_loss: 0.019179, val_mae: 0.098911
2024-12-20 22:49:50,630 - INFO - Epoch 49, train_loss: 0.008598, val_loss: 0.014670, val_mae: 0.086975
2024-12-20 22:50:00,451 - INFO - Epoch 50, train_loss: 0.006570, val_loss: 0.014007, val_mae: 0.086372
2024-12-20 22:50:10,328 - INFO - Epoch 51, train_loss: 0.004861, val_loss: 0.022023, val_mae: 0.103246
2024-12-20 22:50:20,252 - INFO - Epoch 52, train_loss: 0.006681, val_loss: 0.015240, val_mae: 0.087874
2024-12-20 22:50:30,121 - INFO - Epoch 53, train_loss: 0.003944, val_loss: 0.013536, val_mae: 0.079584
2024-12-20 22:50:40,021 - INFO - Epoch 54, train_loss: 0.004740, val_loss: 0.015880, val_mae: 0.089891
2024-12-20 22:50:49,883 - INFO - Epoch 55, train_loss: 0.005417, val_loss: 0.016428, val_mae: 0.092098
2024-12-20 22:50:59,750 - INFO - Epoch 56, train_loss: 0.008887, val_loss: 0.029296, val_mae: 0.120358
2024-12-20 22:51:09,795 - INFO - Epoch 57, train_loss: 0.019503, val_loss: 0.017697, val_mae: 0.097803
2024-12-20 22:51:19,809 - INFO - Epoch 58, train_loss: 0.005553, val_loss: 0.014302, val_mae: 0.082230
2024-12-20 22:51:29,777 - INFO - Epoch 59, train_loss: 0.005307, val_loss: 0.014417, val_mae: 0.086271
2024-12-20 22:51:39,780 - INFO - Epoch 60, train_loss: 0.003320, val_loss: 0.016946, val_mae: 0.090661
2024-12-20 22:51:49,701 - INFO - Epoch 61, train_loss: 0.003022, val_loss: 0.016641, val_mae: 0.092872
2024-12-20 22:51:59,505 - INFO - Epoch 62, train_loss: 0.003714, val_loss: 0.014937, val_mae: 0.083587
2024-12-20 22:52:09,345 - INFO - Epoch 63, train_loss: 0.002764, val_loss: 0.012644, val_mae: 0.076548
2024-12-20 22:52:19,238 - INFO - Epoch 64, train_loss: 0.004049, val_loss: 0.013725, val_mae: 0.083420
2024-12-20 22:52:29,007 - INFO - Epoch 65, train_loss: 0.002790, val_loss: 0.012291, val_mae: 0.074431
2024-12-20 22:52:38,829 - INFO - Epoch 66, train_loss: 0.002320, val_loss: 0.012691, val_mae: 0.076347
2024-12-20 22:52:48,624 - INFO - Epoch 67, train_loss: 0.002264, val_loss: 0.013637, val_mae: 0.082093
2024-12-20 22:52:58,477 - INFO - Epoch 68, train_loss: 0.001832, val_loss: 0.011943, val_mae: 0.075679
2024-12-20 22:53:08,332 - INFO - Epoch 69, train_loss: 0.002255, val_loss: 0.011526, val_mae: 0.072471
2024-12-20 22:53:18,114 - INFO - Epoch 70, train_loss: 0.001422, val_loss: 0.011494, val_mae: 0.071879
2024-12-20 22:53:28,035 - INFO - Epoch 71, train_loss: 0.001332, val_loss: 0.011570, val_mae: 0.072372
2024-12-20 22:53:37,928 - INFO - Epoch 72, train_loss: 0.001535, val_loss: 0.011387, val_mae: 0.074424
2024-12-20 22:53:47,720 - INFO - Epoch 73, train_loss: 0.001551, val_loss: 0.011425, val_mae: 0.070603
2024-12-20 22:53:57,475 - INFO - Epoch 74, train_loss: 0.001313, val_loss: 0.010917, val_mae: 0.070211
2024-12-20 22:54:07,386 - INFO - Epoch 75, train_loss: 0.001000, val_loss: 0.012115, val_mae: 0.076299
2024-12-20 22:54:17,167 - INFO - Epoch 76, train_loss: 0.001191, val_loss: 0.011065, val_mae: 0.071047
2024-12-20 22:54:27,014 - INFO - Epoch 77, train_loss: 0.000840, val_loss: 0.011246, val_mae: 0.070537
2024-12-20 22:54:36,876 - INFO - Epoch 78, train_loss: 0.000647, val_loss: 0.010787, val_mae: 0.068218
2024-12-20 22:54:46,811 - INFO - Epoch 79, train_loss: 0.000524, val_loss: 0.010719, val_mae: 0.067460
2024-12-20 22:54:56,714 - INFO - Epoch 80, train_loss: 0.000665, val_loss: 0.010979, val_mae: 0.069174
2024-12-20 22:55:06,511 - INFO - Epoch 81, train_loss: 0.000528, val_loss: 0.010421, val_mae: 0.066921
2024-12-20 22:55:16,275 - INFO - Epoch 82, train_loss: 0.000391, val_loss: 0.010418, val_mae: 0.066244
2024-12-20 22:55:26,176 - INFO - Epoch 83, train_loss: 0.000331, val_loss: 0.010165, val_mae: 0.064918
2024-12-20 22:55:36,205 - INFO - Epoch 84, train_loss: 0.000334, val_loss: 0.010307, val_mae: 0.065832
2024-12-20 22:55:45,975 - INFO - Epoch 85, train_loss: 0.000271, val_loss: 0.010254, val_mae: 0.066088
2024-12-20 22:55:55,717 - INFO - Epoch 86, train_loss: 0.000239, val_loss: 0.010130, val_mae: 0.065431
2024-12-20 22:56:05,614 - INFO - Epoch 87, train_loss: 0.000212, val_loss: 0.010242, val_mae: 0.065541
2024-12-20 22:56:15,484 - INFO - Epoch 88, train_loss: 0.000183, val_loss: 0.010293, val_mae: 0.065270
2024-12-20 22:56:25,392 - INFO - Epoch 89, train_loss: 0.000184, val_loss: 0.010240, val_mae: 0.065257
2024-12-20 22:56:35,233 - INFO - Epoch 90, train_loss: 0.000177, val_loss: 0.010100, val_mae: 0.064914
2024-12-20 22:56:45,149 - INFO - Epoch 91, train_loss: 0.000161, val_loss: 0.010260, val_mae: 0.065551
2024-12-20 22:56:55,059 - INFO - Epoch 92, train_loss: 0.000148, val_loss: 0.010128, val_mae: 0.064943
2024-12-20 22:57:04,963 - INFO - Epoch 93, train_loss: 0.000136, val_loss: 0.010142, val_mae: 0.065034
2024-12-20 22:57:14,775 - INFO - Epoch 94, train_loss: 0.000129, val_loss: 0.010277, val_mae: 0.065692
2024-12-20 22:57:24,698 - INFO - Epoch 95, train_loss: 0.000120, val_loss: 0.010203, val_mae: 0.065419
2024-12-20 22:57:34,434 - INFO - Epoch 96, train_loss: 0.000118, val_loss: 0.010249, val_mae: 0.065598
2024-12-20 22:57:44,124 - INFO - Epoch 97, train_loss: 0.000112, val_loss: 0.010198, val_mae: 0.065396
2024-12-20 22:57:53,800 - INFO - Epoch 98, train_loss: 0.000108, val_loss: 0.010214, val_mae: 0.065395
2024-12-20 22:58:03,572 - INFO - Epoch 99, train_loss: 0.000106, val_loss: 0.010217, val_mae: 0.065437
2024-12-20 22:58:13,419 - INFO - Epoch 100, train_loss: 0.000104, val_loss: 0.010221, val_mae: 0.065453
2024-12-20 22:58:14,421 - INFO - Test MAE: 0.064914 with best model at Epoch 90
