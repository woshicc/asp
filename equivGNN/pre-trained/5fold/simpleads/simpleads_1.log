2024-12-20 23:33:15,616 - INFO - workdir: ./pre-trained/5fold/simpleads, adsorbate: simpleads
2024-12-20 23:33:16,225 - INFO - dataset size: 1422, batch size: 8
2024-12-20 23:33:16,225 - INFO - train/valid/test size: 1137/285/0
2024-12-20 23:33:17,847 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 23:33:19,412 - INFO - initial lr: 0.000200000, meanAE: 1.0846439666893979
2024-12-20 23:33:29,643 - INFO - Epoch 1, train_loss: 1.427210, val_loss: 0.779223, val_mae: 0.672256
2024-12-20 23:33:40,080 - INFO - Epoch 2, train_loss: 0.854527, val_loss: 0.742050, val_mae: 0.639474
2024-12-20 23:33:50,507 - INFO - Epoch 3, train_loss: 0.732960, val_loss: 0.604655, val_mae: 0.560278
2024-12-20 23:34:01,172 - INFO - Epoch 4, train_loss: 0.645777, val_loss: 0.534748, val_mae: 0.523727
2024-12-20 23:34:12,074 - INFO - Epoch 5, train_loss: 0.611363, val_loss: 0.495111, val_mae: 0.504054
2024-12-20 23:34:22,844 - INFO - Epoch 6, train_loss: 0.581149, val_loss: 0.469849, val_mae: 0.470492
2024-12-20 23:34:33,723 - INFO - Epoch 7, train_loss: 0.567513, val_loss: 0.410432, val_mae: 0.440938
2024-12-20 23:34:44,606 - INFO - Epoch 8, train_loss: 0.374101, val_loss: 0.208441, val_mae: 0.314956
2024-12-20 23:34:55,437 - INFO - Epoch 9, train_loss: 0.231480, val_loss: 0.204978, val_mae: 0.345872
2024-12-20 23:35:05,923 - INFO - Epoch 10, train_loss: 0.160668, val_loss: 0.110440, val_mae: 0.254049
2024-12-20 23:35:16,458 - INFO - Epoch 11, train_loss: 0.135037, val_loss: 0.124184, val_mae: 0.283199
2024-12-20 23:35:26,988 - INFO - Epoch 12, train_loss: 0.112718, val_loss: 0.091331, val_mae: 0.232778
2024-12-20 23:35:37,578 - INFO - Epoch 13, train_loss: 0.095312, val_loss: 0.099759, val_mae: 0.238488
2024-12-20 23:35:48,093 - INFO - Epoch 14, train_loss: 0.076665, val_loss: 0.080690, val_mae: 0.213960
2024-12-20 23:35:58,807 - INFO - Epoch 15, train_loss: 0.088663, val_loss: 0.068223, val_mae: 0.209216
2024-12-20 23:36:09,481 - INFO - Epoch 16, train_loss: 0.077423, val_loss: 0.059864, val_mae: 0.190383
2024-12-20 23:36:20,193 - INFO - Epoch 17, train_loss: 0.057471, val_loss: 0.071294, val_mae: 0.220927
2024-12-20 23:36:30,810 - INFO - Epoch 18, train_loss: 0.057315, val_loss: 0.052456, val_mae: 0.178246
2024-12-20 23:36:41,520 - INFO - Epoch 19, train_loss: 0.042313, val_loss: 0.051050, val_mae: 0.173840
2024-12-20 23:36:52,192 - INFO - Epoch 20, train_loss: 0.037344, val_loss: 0.041693, val_mae: 0.150946
2024-12-20 23:37:02,818 - INFO - Epoch 21, train_loss: 0.037265, val_loss: 0.033183, val_mae: 0.134141
2024-12-20 23:37:13,594 - INFO - Epoch 22, train_loss: 0.027153, val_loss: 0.083805, val_mae: 0.206124
2024-12-20 23:37:24,316 - INFO - Epoch 23, train_loss: 0.042494, val_loss: 0.031502, val_mae: 0.125016
2024-12-20 23:37:34,861 - INFO - Epoch 24, train_loss: 0.025153, val_loss: 0.047286, val_mae: 0.160962
2024-12-20 23:37:45,538 - INFO - Epoch 25, train_loss: 0.051525, val_loss: 0.045533, val_mae: 0.170803
2024-12-20 23:37:56,179 - INFO - Epoch 26, train_loss: 0.037295, val_loss: 0.041820, val_mae: 0.156811
2024-12-20 23:38:06,837 - INFO - Epoch 27, train_loss: 0.028265, val_loss: 0.039136, val_mae: 0.142502
2024-12-20 23:38:17,543 - INFO - Epoch 28, train_loss: 0.043943, val_loss: 0.028882, val_mae: 0.127062
2024-12-20 23:38:28,149 - INFO - Epoch 29, train_loss: 0.018126, val_loss: 0.023302, val_mae: 0.117113
2024-12-20 23:38:38,922 - INFO - Epoch 30, train_loss: 0.014431, val_loss: 0.024626, val_mae: 0.109299
2024-12-20 23:38:49,589 - INFO - Epoch 31, train_loss: 0.016596, val_loss: 0.025512, val_mae: 0.125525
2024-12-20 23:39:00,400 - INFO - Epoch 32, train_loss: 0.013851, val_loss: 0.028129, val_mae: 0.127835
2024-12-20 23:39:11,453 - INFO - Epoch 33, train_loss: 0.025004, val_loss: 0.023227, val_mae: 0.111948
2024-12-20 23:39:22,503 - INFO - Epoch 34, train_loss: 0.016406, val_loss: 0.042260, val_mae: 0.154054
2024-12-20 23:39:33,274 - INFO - Epoch 35, train_loss: 0.028157, val_loss: 0.040949, val_mae: 0.153277
2024-12-20 23:39:43,866 - INFO - Epoch 36, train_loss: 0.021406, val_loss: 0.022864, val_mae: 0.109478
2024-12-20 23:39:54,484 - INFO - Epoch 37, train_loss: 0.018512, val_loss: 0.041420, val_mae: 0.163680
2024-12-20 23:40:05,137 - INFO - Epoch 38, train_loss: 0.013764, val_loss: 0.021576, val_mae: 0.116993
2024-12-20 23:40:15,752 - INFO - Epoch 39, train_loss: 0.008896, val_loss: 0.018671, val_mae: 0.096110
2024-12-20 23:40:26,312 - INFO - Epoch 40, train_loss: 0.008396, val_loss: 0.016759, val_mae: 0.099111
2024-12-20 23:40:36,904 - INFO - Epoch 41, train_loss: 0.007118, val_loss: 0.015524, val_mae: 0.093495
2024-12-20 23:40:47,445 - INFO - Epoch 42, train_loss: 0.010767, val_loss: 0.025452, val_mae: 0.115088
2024-12-20 23:40:58,036 - INFO - Epoch 43, train_loss: 0.011697, val_loss: 0.016926, val_mae: 0.097241
2024-12-20 23:41:08,600 - INFO - Epoch 44, train_loss: 0.009207, val_loss: 0.026692, val_mae: 0.120303
2024-12-20 23:41:19,247 - INFO - Epoch 45, train_loss: 0.011050, val_loss: 0.019406, val_mae: 0.104622
2024-12-20 23:41:29,809 - INFO - Epoch 46, train_loss: 0.077449, val_loss: 0.046928, val_mae: 0.170222
2024-12-20 23:41:40,343 - INFO - Epoch 47, train_loss: 0.035252, val_loss: 0.022965, val_mae: 0.109740
2024-12-20 23:41:50,870 - INFO - Epoch 48, train_loss: 0.014447, val_loss: 0.016681, val_mae: 0.097423
2024-12-20 23:42:01,362 - INFO - Epoch 49, train_loss: 0.006977, val_loss: 0.014422, val_mae: 0.088430
2024-12-20 23:42:11,960 - INFO - Epoch 50, train_loss: 0.007095, val_loss: 0.013149, val_mae: 0.081812
2024-12-20 23:42:22,590 - INFO - Epoch 51, train_loss: 0.004514, val_loss: 0.012704, val_mae: 0.079532
2024-12-20 23:42:33,205 - INFO - Epoch 52, train_loss: 0.006837, val_loss: 0.014025, val_mae: 0.084482
2024-12-20 23:42:43,822 - INFO - Epoch 53, train_loss: 0.004585, val_loss: 0.016984, val_mae: 0.094504
2024-12-20 23:42:54,568 - INFO - Epoch 54, train_loss: 0.006332, val_loss: 0.014764, val_mae: 0.092605
2024-12-20 23:43:05,080 - INFO - Epoch 55, train_loss: 0.006688, val_loss: 0.017300, val_mae: 0.102897
2024-12-20 23:43:15,707 - INFO - Epoch 56, train_loss: 0.007252, val_loss: 0.013446, val_mae: 0.082592
2024-12-20 23:43:26,271 - INFO - Epoch 57, train_loss: 0.005905, val_loss: 0.013733, val_mae: 0.083328
2024-12-20 23:43:36,910 - INFO - Epoch 58, train_loss: 0.005610, val_loss: 0.012479, val_mae: 0.079202
2024-12-20 23:43:47,718 - INFO - Epoch 59, train_loss: 0.004484, val_loss: 0.014006, val_mae: 0.091015
2024-12-20 23:43:58,302 - INFO - Epoch 60, train_loss: 0.007958, val_loss: 0.013400, val_mae: 0.086663
2024-12-20 23:44:08,793 - INFO - Epoch 61, train_loss: 0.004505, val_loss: 0.014249, val_mae: 0.084204
2024-12-20 23:44:19,425 - INFO - Epoch 62, train_loss: 0.005327, val_loss: 0.012137, val_mae: 0.079059
2024-12-20 23:44:30,100 - INFO - Epoch 63, train_loss: 0.002708, val_loss: 0.010083, val_mae: 0.071747
2024-12-20 23:44:40,711 - INFO - Epoch 64, train_loss: 0.002338, val_loss: 0.011396, val_mae: 0.074569
2024-12-20 23:44:51,351 - INFO - Epoch 65, train_loss: 0.002058, val_loss: 0.009541, val_mae: 0.069452
2024-12-20 23:45:01,990 - INFO - Epoch 66, train_loss: 0.001781, val_loss: 0.009801, val_mae: 0.069097
2024-12-20 23:45:12,770 - INFO - Epoch 67, train_loss: 0.001720, val_loss: 0.009878, val_mae: 0.068767
2024-12-20 23:45:23,454 - INFO - Epoch 68, train_loss: 0.001739, val_loss: 0.009653, val_mae: 0.068763
2024-12-20 23:45:33,961 - INFO - Epoch 69, train_loss: 0.001853, val_loss: 0.009361, val_mae: 0.069137
2024-12-20 23:45:44,513 - INFO - Epoch 70, train_loss: 0.001937, val_loss: 0.009043, val_mae: 0.065562
2024-12-20 23:45:55,129 - INFO - Epoch 71, train_loss: 0.001790, val_loss: 0.009434, val_mae: 0.067003
2024-12-20 23:46:05,735 - INFO - Epoch 72, train_loss: 0.001686, val_loss: 0.009424, val_mae: 0.068703
2024-12-20 23:46:16,279 - INFO - Epoch 73, train_loss: 0.001302, val_loss: 0.009529, val_mae: 0.071817
2024-12-20 23:46:26,760 - INFO - Epoch 74, train_loss: 0.001319, val_loss: 0.008327, val_mae: 0.063591
2024-12-20 23:46:37,472 - INFO - Epoch 75, train_loss: 0.001081, val_loss: 0.009709, val_mae: 0.068143
2024-12-20 23:46:48,044 - INFO - Epoch 76, train_loss: 0.001049, val_loss: 0.008390, val_mae: 0.064788
2024-12-20 23:46:58,741 - INFO - Epoch 77, train_loss: 0.000895, val_loss: 0.009245, val_mae: 0.065609
2024-12-20 23:47:09,647 - INFO - Epoch 78, train_loss: 0.000807, val_loss: 0.008846, val_mae: 0.067863
2024-12-20 23:47:20,689 - INFO - Epoch 79, train_loss: 0.000774, val_loss: 0.007939, val_mae: 0.062791
2024-12-20 23:47:31,506 - INFO - Epoch 80, train_loss: 0.000647, val_loss: 0.008669, val_mae: 0.062641
2024-12-20 23:47:42,105 - INFO - Epoch 81, train_loss: 0.000590, val_loss: 0.008928, val_mae: 0.064878
2024-12-20 23:47:52,559 - INFO - Epoch 82, train_loss: 0.000558, val_loss: 0.008568, val_mae: 0.063551
2024-12-20 23:48:03,137 - INFO - Epoch 83, train_loss: 0.000557, val_loss: 0.008518, val_mae: 0.062054
2024-12-20 23:48:13,761 - INFO - Epoch 84, train_loss: 0.000503, val_loss: 0.008358, val_mae: 0.061383
2024-12-20 23:48:24,338 - INFO - Epoch 85, train_loss: 0.000539, val_loss: 0.008521, val_mae: 0.062823
2024-12-20 23:48:34,924 - INFO - Epoch 86, train_loss: 0.000434, val_loss: 0.008510, val_mae: 0.062577
2024-12-20 23:48:45,452 - INFO - Epoch 87, train_loss: 0.000454, val_loss: 0.008152, val_mae: 0.061371
2024-12-20 23:48:56,220 - INFO - Epoch 88, train_loss: 0.000341, val_loss: 0.008399, val_mae: 0.062668
2024-12-20 23:49:06,858 - INFO - Epoch 89, train_loss: 0.000310, val_loss: 0.008033, val_mae: 0.060349
2024-12-20 23:49:17,370 - INFO - Epoch 90, train_loss: 0.000278, val_loss: 0.008198, val_mae: 0.060895
2024-12-20 23:49:27,912 - INFO - Epoch 91, train_loss: 0.000272, val_loss: 0.008347, val_mae: 0.061145
2024-12-20 23:49:38,482 - INFO - Epoch 92, train_loss: 0.000259, val_loss: 0.008228, val_mae: 0.060957
2024-12-20 23:49:48,938 - INFO - Epoch 93, train_loss: 0.000235, val_loss: 0.008174, val_mae: 0.061093
2024-12-20 23:49:59,474 - INFO - Epoch 94, train_loss: 0.000233, val_loss: 0.008198, val_mae: 0.060860
2024-12-20 23:50:09,959 - INFO - Epoch 95, train_loss: 0.000222, val_loss: 0.008090, val_mae: 0.060662
2024-12-20 23:50:20,513 - INFO - Epoch 96, train_loss: 0.000214, val_loss: 0.008163, val_mae: 0.060862
2024-12-20 23:50:31,133 - INFO - Epoch 97, train_loss: 0.000209, val_loss: 0.008148, val_mae: 0.060736
2024-12-20 23:50:41,719 - INFO - Epoch 98, train_loss: 0.000203, val_loss: 0.008136, val_mae: 0.060635
2024-12-20 23:50:52,275 - INFO - Epoch 99, train_loss: 0.000199, val_loss: 0.008157, val_mae: 0.060738
2024-12-20 23:51:02,904 - INFO - Epoch 100, train_loss: 0.000195, val_loss: 0.008156, val_mae: 0.060730
2024-12-20 23:51:03,904 - INFO - Test MAE: 0.060349 with best model at Epoch 89
