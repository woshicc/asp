2024-12-20 23:14:49,081 - INFO - workdir: ./pre-trained/5fold/simpleads, adsorbate: simpleads
2024-12-20 23:14:49,745 - INFO - dataset size: 1422, batch size: 8
2024-12-20 23:14:49,745 - INFO - train/valid/test size: 1137/285/0
2024-12-20 23:14:51,321 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 23:14:52,886 - INFO - initial lr: 0.000200000, meanAE: 1.1595643589897522
2024-12-20 23:15:03,624 - INFO - Epoch 1, train_loss: 1.402671, val_loss: 0.833131, val_mae: 0.693481
2024-12-20 23:15:14,670 - INFO - Epoch 2, train_loss: 0.846681, val_loss: 0.728530, val_mae: 0.621865
2024-12-20 23:15:25,474 - INFO - Epoch 3, train_loss: 0.707808, val_loss: 0.620353, val_mae: 0.537381
2024-12-20 23:15:36,277 - INFO - Epoch 4, train_loss: 0.633107, val_loss: 0.610145, val_mae: 0.523408
2024-12-20 23:15:47,167 - INFO - Epoch 5, train_loss: 0.586871, val_loss: 0.575684, val_mae: 0.516547
2024-12-20 23:15:57,995 - INFO - Epoch 6, train_loss: 0.563739, val_loss: 0.583901, val_mae: 0.517038
2024-12-20 23:16:08,812 - INFO - Epoch 7, train_loss: 0.542522, val_loss: 0.507247, val_mae: 0.457299
2024-12-20 23:16:19,819 - INFO - Epoch 8, train_loss: 0.359001, val_loss: 0.231074, val_mae: 0.313655
2024-12-20 23:16:30,864 - INFO - Epoch 9, train_loss: 0.240666, val_loss: 0.181371, val_mae: 0.307852
2024-12-20 23:16:41,806 - INFO - Epoch 10, train_loss: 0.151236, val_loss: 0.139327, val_mae: 0.266470
2024-12-20 23:16:52,685 - INFO - Epoch 11, train_loss: 0.122543, val_loss: 0.122019, val_mae: 0.267678
2024-12-20 23:17:03,507 - INFO - Epoch 12, train_loss: 0.110041, val_loss: 0.095085, val_mae: 0.223525
2024-12-20 23:17:14,248 - INFO - Epoch 13, train_loss: 0.099426, val_loss: 0.096144, val_mae: 0.240784
2024-12-20 23:17:25,070 - INFO - Epoch 14, train_loss: 0.083933, val_loss: 0.095504, val_mae: 0.238565
2024-12-20 23:17:35,904 - INFO - Epoch 15, train_loss: 0.075895, val_loss: 0.084094, val_mae: 0.218127
2024-12-20 23:17:46,769 - INFO - Epoch 16, train_loss: 0.092896, val_loss: 0.103947, val_mae: 0.226381
2024-12-20 23:17:57,605 - INFO - Epoch 17, train_loss: 0.065924, val_loss: 0.087680, val_mae: 0.210454
2024-12-20 23:18:08,443 - INFO - Epoch 18, train_loss: 0.072524, val_loss: 0.125797, val_mae: 0.233150
2024-12-20 23:18:19,298 - INFO - Epoch 19, train_loss: 0.061637, val_loss: 0.039347, val_mae: 0.138683
2024-12-20 23:18:30,203 - INFO - Epoch 20, train_loss: 0.038892, val_loss: 0.040242, val_mae: 0.144322
2024-12-20 23:18:41,191 - INFO - Epoch 21, train_loss: 0.047777, val_loss: 0.045561, val_mae: 0.163127
2024-12-20 23:18:52,221 - INFO - Epoch 22, train_loss: 0.030686, val_loss: 0.052634, val_mae: 0.165762
2024-12-20 23:19:03,109 - INFO - Epoch 23, train_loss: 0.032815, val_loss: 0.037250, val_mae: 0.147845
2024-12-20 23:19:14,131 - INFO - Epoch 24, train_loss: 0.032175, val_loss: 0.033872, val_mae: 0.141346
2024-12-20 23:19:24,960 - INFO - Epoch 25, train_loss: 0.037121, val_loss: 0.024595, val_mae: 0.114912
2024-12-20 23:19:35,948 - INFO - Epoch 26, train_loss: 0.021817, val_loss: 0.032806, val_mae: 0.145386
2024-12-20 23:19:46,807 - INFO - Epoch 27, train_loss: 0.023670, val_loss: 0.034804, val_mae: 0.145209
2024-12-20 23:19:57,695 - INFO - Epoch 28, train_loss: 0.031817, val_loss: 0.029819, val_mae: 0.136018
2024-12-20 23:20:08,586 - INFO - Epoch 29, train_loss: 0.036537, val_loss: 0.038379, val_mae: 0.141682
2024-12-20 23:20:19,515 - INFO - Epoch 30, train_loss: 0.026970, val_loss: 0.051174, val_mae: 0.139205
2024-12-20 23:20:30,633 - INFO - Epoch 31, train_loss: 0.020445, val_loss: 0.019722, val_mae: 0.104578
2024-12-20 23:20:41,874 - INFO - Epoch 32, train_loss: 0.013178, val_loss: 0.024558, val_mae: 0.121011
2024-12-20 23:20:53,091 - INFO - Epoch 33, train_loss: 0.012010, val_loss: 0.015371, val_mae: 0.088608
2024-12-20 23:21:04,201 - INFO - Epoch 34, train_loss: 0.013601, val_loss: 0.016649, val_mae: 0.096644
2024-12-20 23:21:15,320 - INFO - Epoch 35, train_loss: 0.018745, val_loss: 0.020745, val_mae: 0.103782
2024-12-20 23:21:26,582 - INFO - Epoch 36, train_loss: 0.020317, val_loss: 0.021906, val_mae: 0.102195
2024-12-20 23:21:37,549 - INFO - Epoch 37, train_loss: 0.043936, val_loss: 0.035679, val_mae: 0.146312
2024-12-20 23:21:48,626 - INFO - Epoch 38, train_loss: 0.024353, val_loss: 0.021580, val_mae: 0.104068
2024-12-20 23:21:59,657 - INFO - Epoch 39, train_loss: 0.022134, val_loss: 0.017540, val_mae: 0.092510
2024-12-20 23:22:10,783 - INFO - Epoch 40, train_loss: 0.039064, val_loss: 0.045986, val_mae: 0.164947
2024-12-20 23:22:21,885 - INFO - Epoch 41, train_loss: 0.026639, val_loss: 0.026465, val_mae: 0.122038
2024-12-20 23:22:33,054 - INFO - Epoch 42, train_loss: 0.015247, val_loss: 0.016022, val_mae: 0.093998
2024-12-20 23:22:44,539 - INFO - Epoch 43, train_loss: 0.010972, val_loss: 0.011980, val_mae: 0.079051
2024-12-20 23:22:55,611 - INFO - Epoch 44, train_loss: 0.008168, val_loss: 0.011013, val_mae: 0.074982
2024-12-20 23:23:06,746 - INFO - Epoch 45, train_loss: 0.008452, val_loss: 0.015027, val_mae: 0.089223
2024-12-20 23:23:17,725 - INFO - Epoch 46, train_loss: 0.018517, val_loss: 0.010300, val_mae: 0.072388
2024-12-20 23:23:28,688 - INFO - Epoch 47, train_loss: 0.006916, val_loss: 0.013099, val_mae: 0.085310
2024-12-20 23:23:39,766 - INFO - Epoch 48, train_loss: 0.006303, val_loss: 0.009622, val_mae: 0.072995
2024-12-20 23:23:50,840 - INFO - Epoch 49, train_loss: 0.006039, val_loss: 0.011747, val_mae: 0.082615
2024-12-20 23:24:01,963 - INFO - Epoch 50, train_loss: 0.005658, val_loss: 0.012504, val_mae: 0.084450
2024-12-20 23:24:13,112 - INFO - Epoch 51, train_loss: 0.006456, val_loss: 0.008456, val_mae: 0.065875
2024-12-20 23:24:24,295 - INFO - Epoch 52, train_loss: 0.005995, val_loss: 0.013993, val_mae: 0.085150
2024-12-20 23:24:35,506 - INFO - Epoch 53, train_loss: 0.004584, val_loss: 0.009790, val_mae: 0.071353
2024-12-20 23:24:46,580 - INFO - Epoch 54, train_loss: 0.004494, val_loss: 0.009768, val_mae: 0.071766
2024-12-20 23:24:57,619 - INFO - Epoch 55, train_loss: 0.008481, val_loss: 0.012938, val_mae: 0.085004
2024-12-20 23:25:08,541 - INFO - Epoch 56, train_loss: 0.006313, val_loss: 0.010129, val_mae: 0.073191
2024-12-20 23:25:19,724 - INFO - Epoch 57, train_loss: 0.005133, val_loss: 0.012621, val_mae: 0.080393
2024-12-20 23:25:30,680 - INFO - Epoch 58, train_loss: 0.010379, val_loss: 0.013098, val_mae: 0.085273
2024-12-20 23:25:41,663 - INFO - Epoch 59, train_loss: 0.005697, val_loss: 0.009112, val_mae: 0.070196
2024-12-20 23:25:52,654 - INFO - Epoch 60, train_loss: 0.004954, val_loss: 0.016080, val_mae: 0.102064
2024-12-20 23:26:03,677 - INFO - Epoch 61, train_loss: 0.004695, val_loss: 0.015566, val_mae: 0.093131
2024-12-20 23:26:14,765 - INFO - Epoch 62, train_loss: 0.004414, val_loss: 0.008805, val_mae: 0.068109
2024-12-20 23:26:25,905 - INFO - Epoch 63, train_loss: 0.002417, val_loss: 0.008276, val_mae: 0.067961
2024-12-20 23:26:37,689 - INFO - Epoch 64, train_loss: 0.003714, val_loss: 0.010007, val_mae: 0.072323
2024-12-20 23:26:48,830 - INFO - Epoch 65, train_loss: 0.004157, val_loss: 0.013136, val_mae: 0.078863
2024-12-20 23:26:59,820 - INFO - Epoch 66, train_loss: 0.003961, val_loss: 0.007778, val_mae: 0.062235
2024-12-20 23:27:10,741 - INFO - Epoch 67, train_loss: 0.002756, val_loss: 0.007966, val_mae: 0.064163
2024-12-20 23:27:21,596 - INFO - Epoch 68, train_loss: 0.001682, val_loss: 0.007119, val_mae: 0.060334
2024-12-20 23:27:32,549 - INFO - Epoch 69, train_loss: 0.001298, val_loss: 0.007469, val_mae: 0.060042
2024-12-20 23:27:43,479 - INFO - Epoch 70, train_loss: 0.001768, val_loss: 0.008385, val_mae: 0.066943
2024-12-20 23:27:54,411 - INFO - Epoch 71, train_loss: 0.001575, val_loss: 0.007408, val_mae: 0.062359
2024-12-20 23:28:05,320 - INFO - Epoch 72, train_loss: 0.001728, val_loss: 0.006974, val_mae: 0.057249
2024-12-20 23:28:16,284 - INFO - Epoch 73, train_loss: 0.001921, val_loss: 0.009223, val_mae: 0.066697
2024-12-20 23:28:27,838 - INFO - Epoch 74, train_loss: 0.001346, val_loss: 0.007767, val_mae: 0.063639
2024-12-20 23:28:38,684 - INFO - Epoch 75, train_loss: 0.001128, val_loss: 0.006725, val_mae: 0.059028
2024-12-20 23:28:49,713 - INFO - Epoch 76, train_loss: 0.000965, val_loss: 0.007113, val_mae: 0.061134
2024-12-20 23:29:00,736 - INFO - Epoch 77, train_loss: 0.000840, val_loss: 0.006533, val_mae: 0.058285
2024-12-20 23:29:11,731 - INFO - Epoch 78, train_loss: 0.000785, val_loss: 0.007490, val_mae: 0.062030
2024-12-20 23:29:22,697 - INFO - Epoch 79, train_loss: 0.000773, val_loss: 0.006935, val_mae: 0.059415
2024-12-20 23:29:33,551 - INFO - Epoch 80, train_loss: 0.000680, val_loss: 0.006745, val_mae: 0.057153
2024-12-20 23:29:44,523 - INFO - Epoch 81, train_loss: 0.000601, val_loss: 0.006433, val_mae: 0.056348
2024-12-20 23:29:55,700 - INFO - Epoch 82, train_loss: 0.000665, val_loss: 0.006512, val_mae: 0.057215
2024-12-20 23:30:06,774 - INFO - Epoch 83, train_loss: 0.000483, val_loss: 0.006782, val_mae: 0.057442
2024-12-20 23:30:17,781 - INFO - Epoch 84, train_loss: 0.000423, val_loss: 0.006582, val_mae: 0.056363
2024-12-20 23:30:28,841 - INFO - Epoch 85, train_loss: 0.000372, val_loss: 0.006597, val_mae: 0.056506
2024-12-20 23:30:39,642 - INFO - Epoch 86, train_loss: 0.000350, val_loss: 0.006447, val_mae: 0.055612
2024-12-20 23:30:50,528 - INFO - Epoch 87, train_loss: 0.000356, val_loss: 0.006290, val_mae: 0.054974
2024-12-20 23:31:01,436 - INFO - Epoch 88, train_loss: 0.000293, val_loss: 0.006472, val_mae: 0.055422
2024-12-20 23:31:12,284 - INFO - Epoch 89, train_loss: 0.000297, val_loss: 0.006550, val_mae: 0.056197
2024-12-20 23:31:23,083 - INFO - Epoch 90, train_loss: 0.000254, val_loss: 0.006513, val_mae: 0.056291
2024-12-20 23:31:33,963 - INFO - Epoch 91, train_loss: 0.000274, val_loss: 0.006538, val_mae: 0.055813
2024-12-20 23:31:44,849 - INFO - Epoch 92, train_loss: 0.000232, val_loss: 0.006570, val_mae: 0.056245
2024-12-20 23:31:55,909 - INFO - Epoch 93, train_loss: 0.000219, val_loss: 0.006410, val_mae: 0.055498
2024-12-20 23:32:06,764 - INFO - Epoch 94, train_loss: 0.000212, val_loss: 0.006489, val_mae: 0.055850
2024-12-20 23:32:17,681 - INFO - Epoch 95, train_loss: 0.000207, val_loss: 0.006469, val_mae: 0.055790
2024-12-20 23:32:28,471 - INFO - Epoch 96, train_loss: 0.000200, val_loss: 0.006447, val_mae: 0.055613
2024-12-20 23:32:39,240 - INFO - Epoch 97, train_loss: 0.000196, val_loss: 0.006449, val_mae: 0.055610
2024-12-20 23:32:49,950 - INFO - Epoch 98, train_loss: 0.000187, val_loss: 0.006425, val_mae: 0.055479
2024-12-20 23:33:00,787 - INFO - Epoch 99, train_loss: 0.000183, val_loss: 0.006435, val_mae: 0.055516
2024-12-20 23:33:11,571 - INFO - Epoch 100, train_loss: 0.000178, val_loss: 0.006433, val_mae: 0.055507
2024-12-20 23:33:12,587 - INFO - Test MAE: 0.054974 with best model at Epoch 87
