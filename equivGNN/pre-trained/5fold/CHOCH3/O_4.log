2024-12-20 11:41:42,998 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: O
2024-12-20 11:41:44,581 - INFO - dataset size: 5739, batch size: 8
2024-12-20 11:41:44,582 - INFO - train/valid/test size: 4592/1147/0
2024-12-20 11:41:46,112 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 11:41:48,459 - INFO - initial lr: 0.000200000, meanAE: 1.5833247314619023
2024-12-20 11:42:10,891 - INFO - Epoch 1, train_loss: 2.564359, val_loss: 1.799427, val_mae: 1.045952
2024-12-20 11:42:33,287 - INFO - Epoch 2, train_loss: 1.541869, val_loss: 1.106244, val_mae: 0.757474
2024-12-20 11:42:56,161 - INFO - Epoch 3, train_loss: 1.024579, val_loss: 0.845226, val_mae: 0.662857
2024-12-20 11:43:18,449 - INFO - Epoch 4, train_loss: 0.755173, val_loss: 0.537191, val_mae: 0.528199
2024-12-20 11:43:41,346 - INFO - Epoch 5, train_loss: 0.448404, val_loss: 0.325891, val_mae: 0.413376
2024-12-20 11:44:04,072 - INFO - Epoch 6, train_loss: 0.275911, val_loss: 0.237642, val_mae: 0.358685
2024-12-20 11:44:27,415 - INFO - Epoch 7, train_loss: 0.185751, val_loss: 0.166402, val_mae: 0.304254
2024-12-20 11:44:50,388 - INFO - Epoch 8, train_loss: 0.140658, val_loss: 0.136288, val_mae: 0.275124
2024-12-20 11:45:13,086 - INFO - Epoch 9, train_loss: 0.110046, val_loss: 0.117287, val_mae: 0.251331
2024-12-20 11:45:35,700 - INFO - Epoch 10, train_loss: 0.100947, val_loss: 0.123059, val_mae: 0.259624
2024-12-20 11:45:57,662 - INFO - Epoch 11, train_loss: 0.086797, val_loss: 0.124198, val_mae: 0.268971
2024-12-20 11:46:21,661 - INFO - Epoch 12, train_loss: 0.086074, val_loss: 0.102536, val_mae: 0.234483
2024-12-20 11:46:45,668 - INFO - Epoch 13, train_loss: 0.078886, val_loss: 0.091311, val_mae: 0.224136
2024-12-20 11:47:09,017 - INFO - Epoch 14, train_loss: 0.072382, val_loss: 0.087903, val_mae: 0.222501
2024-12-20 11:47:31,566 - INFO - Epoch 15, train_loss: 0.067352, val_loss: 0.101544, val_mae: 0.234130
2024-12-20 11:47:53,587 - INFO - Epoch 16, train_loss: 0.066190, val_loss: 0.085898, val_mae: 0.212296
2024-12-20 11:48:16,648 - INFO - Epoch 17, train_loss: 0.060160, val_loss: 0.096559, val_mae: 0.240066
2024-12-20 11:48:39,664 - INFO - Epoch 18, train_loss: 0.066068, val_loss: 0.070438, val_mae: 0.197335
2024-12-20 11:49:02,492 - INFO - Epoch 19, train_loss: 0.050085, val_loss: 0.070216, val_mae: 0.194424
2024-12-20 11:49:24,348 - INFO - Epoch 20, train_loss: 0.054099, val_loss: 0.061027, val_mae: 0.186459
2024-12-20 11:49:47,127 - INFO - Epoch 21, train_loss: 0.054174, val_loss: 0.063247, val_mae: 0.180898
2024-12-20 11:50:09,693 - INFO - Epoch 22, train_loss: 0.056185, val_loss: 0.057626, val_mae: 0.181012
2024-12-20 11:50:32,334 - INFO - Epoch 23, train_loss: 0.047467, val_loss: 0.057420, val_mae: 0.176283
2024-12-20 11:50:55,020 - INFO - Epoch 24, train_loss: 0.047364, val_loss: 0.058692, val_mae: 0.179470
2024-12-20 11:51:17,059 - INFO - Epoch 25, train_loss: 0.043020, val_loss: 0.076295, val_mae: 0.213264
2024-12-20 11:51:40,228 - INFO - Epoch 26, train_loss: 0.044275, val_loss: 0.054051, val_mae: 0.172470
2024-12-20 11:52:02,885 - INFO - Epoch 27, train_loss: 0.039996, val_loss: 0.085908, val_mae: 0.211142
2024-12-20 11:52:26,331 - INFO - Epoch 28, train_loss: 0.041653, val_loss: 0.105494, val_mae: 0.254904
2024-12-20 11:52:49,649 - INFO - Epoch 29, train_loss: 0.039180, val_loss: 0.062912, val_mae: 0.181229
2024-12-20 11:53:12,680 - INFO - Epoch 30, train_loss: 0.038392, val_loss: 0.051042, val_mae: 0.168030
2024-12-20 11:53:35,880 - INFO - Epoch 31, train_loss: 0.032415, val_loss: 0.049801, val_mae: 0.160496
2024-12-20 11:53:57,840 - INFO - Epoch 32, train_loss: 0.032874, val_loss: 0.044306, val_mae: 0.149163
2024-12-20 11:54:20,470 - INFO - Epoch 33, train_loss: 0.028303, val_loss: 0.055211, val_mae: 0.180270
2024-12-20 11:54:42,680 - INFO - Epoch 34, train_loss: 0.028424, val_loss: 0.039428, val_mae: 0.146577
2024-12-20 11:55:05,214 - INFO - Epoch 35, train_loss: 0.023370, val_loss: 0.040391, val_mae: 0.148800
2024-12-20 11:55:27,757 - INFO - Epoch 36, train_loss: 0.025275, val_loss: 0.035604, val_mae: 0.135922
2024-12-20 11:55:49,877 - INFO - Epoch 37, train_loss: 0.023505, val_loss: 0.043904, val_mae: 0.148928
2024-12-20 11:56:12,622 - INFO - Epoch 38, train_loss: 0.025610, val_loss: 0.037822, val_mae: 0.142066
2024-12-20 11:56:35,406 - INFO - Epoch 39, train_loss: 0.020642, val_loss: 0.040760, val_mae: 0.147273
2024-12-20 11:56:58,208 - INFO - Epoch 40, train_loss: 0.019662, val_loss: 0.034809, val_mae: 0.130725
2024-12-20 11:57:20,305 - INFO - Epoch 41, train_loss: 0.019717, val_loss: 0.039768, val_mae: 0.151908
2024-12-20 11:57:42,708 - INFO - Epoch 42, train_loss: 0.017273, val_loss: 0.041744, val_mae: 0.140078
2024-12-20 11:58:05,496 - INFO - Epoch 43, train_loss: 0.017409, val_loss: 0.032188, val_mae: 0.123446
2024-12-20 11:58:27,769 - INFO - Epoch 44, train_loss: 0.017044, val_loss: 0.036186, val_mae: 0.138211
2024-12-20 11:58:50,407 - INFO - Epoch 45, train_loss: 0.016493, val_loss: 0.034930, val_mae: 0.133062
2024-12-20 11:59:12,412 - INFO - Epoch 46, train_loss: 0.013929, val_loss: 0.036920, val_mae: 0.134706
2024-12-20 11:59:34,634 - INFO - Epoch 47, train_loss: 0.014936, val_loss: 0.037946, val_mae: 0.140646
2024-12-20 11:59:58,028 - INFO - Epoch 48, train_loss: 0.015449, val_loss: 0.030422, val_mae: 0.120584
2024-12-20 12:00:21,209 - INFO - Epoch 49, train_loss: 0.011170, val_loss: 0.030813, val_mae: 0.124614
2024-12-20 12:00:44,554 - INFO - Epoch 50, train_loss: 0.012257, val_loss: 0.028140, val_mae: 0.113268
2024-12-20 12:01:07,662 - INFO - Epoch 51, train_loss: 0.011823, val_loss: 0.033057, val_mae: 0.129429
2024-12-20 12:01:30,864 - INFO - Epoch 52, train_loss: 0.010736, val_loss: 0.028117, val_mae: 0.114589
2024-12-20 12:01:53,030 - INFO - Epoch 53, train_loss: 0.009051, val_loss: 0.027606, val_mae: 0.118676
2024-12-20 12:02:15,614 - INFO - Epoch 54, train_loss: 0.010065, val_loss: 0.027600, val_mae: 0.111691
2024-12-20 12:02:38,121 - INFO - Epoch 55, train_loss: 0.009433, val_loss: 0.026410, val_mae: 0.110873
2024-12-20 12:03:00,736 - INFO - Epoch 56, train_loss: 0.008368, val_loss: 0.029346, val_mae: 0.116016
2024-12-20 12:03:23,412 - INFO - Epoch 57, train_loss: 0.007914, val_loss: 0.025358, val_mae: 0.109201
2024-12-20 12:03:45,444 - INFO - Epoch 58, train_loss: 0.006999, val_loss: 0.025781, val_mae: 0.105394
2024-12-20 12:04:08,171 - INFO - Epoch 59, train_loss: 0.006197, val_loss: 0.023600, val_mae: 0.101037
2024-12-20 12:04:31,154 - INFO - Epoch 60, train_loss: 0.005680, val_loss: 0.025518, val_mae: 0.103739
2024-12-20 12:04:54,076 - INFO - Epoch 61, train_loss: 0.006686, val_loss: 0.023818, val_mae: 0.101783
2024-12-20 12:05:16,072 - INFO - Epoch 62, train_loss: 0.006428, val_loss: 0.023080, val_mae: 0.103768
2024-12-20 12:05:38,615 - INFO - Epoch 63, train_loss: 0.004095, val_loss: 0.023723, val_mae: 0.098305
2024-12-20 12:06:01,526 - INFO - Epoch 64, train_loss: 0.004222, val_loss: 0.023549, val_mae: 0.104966
2024-12-20 12:06:23,591 - INFO - Epoch 65, train_loss: 0.004212, val_loss: 0.025125, val_mae: 0.103933
2024-12-20 12:06:46,214 - INFO - Epoch 66, train_loss: 0.004216, val_loss: 0.022877, val_mae: 0.099777
2024-12-20 12:07:08,412 - INFO - Epoch 67, train_loss: 0.003493, val_loss: 0.023180, val_mae: 0.099083
2024-12-20 12:07:30,763 - INFO - Epoch 68, train_loss: 0.002878, val_loss: 0.022169, val_mae: 0.096491
2024-12-20 12:07:53,981 - INFO - Epoch 69, train_loss: 0.002908, val_loss: 0.021922, val_mae: 0.096505
2024-12-20 12:08:17,278 - INFO - Epoch 70, train_loss: 0.003205, val_loss: 0.022352, val_mae: 0.096771
2024-12-20 12:08:40,617 - INFO - Epoch 71, train_loss: 0.002673, val_loss: 0.021983, val_mae: 0.095029
2024-12-20 12:09:03,795 - INFO - Epoch 72, train_loss: 0.002046, val_loss: 0.020273, val_mae: 0.091603
2024-12-20 12:09:26,842 - INFO - Epoch 73, train_loss: 0.001639, val_loss: 0.021271, val_mae: 0.095153
2024-12-20 12:09:49,491 - INFO - Epoch 74, train_loss: 0.001501, val_loss: 0.020783, val_mae: 0.091248
2024-12-20 12:10:12,180 - INFO - Epoch 75, train_loss: 0.001379, val_loss: 0.021564, val_mae: 0.092526
2024-12-20 12:10:34,880 - INFO - Epoch 76, train_loss: 0.001225, val_loss: 0.020009, val_mae: 0.089005
2024-12-20 12:10:57,599 - INFO - Epoch 77, train_loss: 0.001049, val_loss: 0.020615, val_mae: 0.090490
2024-12-20 12:11:20,453 - INFO - Epoch 78, train_loss: 0.000896, val_loss: 0.020158, val_mae: 0.089449
2024-12-20 12:11:42,747 - INFO - Epoch 79, train_loss: 0.000812, val_loss: 0.020248, val_mae: 0.089677
2024-12-20 12:12:04,984 - INFO - Epoch 80, train_loss: 0.000710, val_loss: 0.020056, val_mae: 0.088054
2024-12-20 12:12:27,081 - INFO - Epoch 81, train_loss: 0.000590, val_loss: 0.020708, val_mae: 0.089418
2024-12-20 12:12:49,203 - INFO - Epoch 82, train_loss: 0.000592, val_loss: 0.020120, val_mae: 0.087989
2024-12-20 12:13:11,269 - INFO - Epoch 83, train_loss: 0.000491, val_loss: 0.019920, val_mae: 0.087434
2024-12-20 12:13:33,146 - INFO - Epoch 84, train_loss: 0.000441, val_loss: 0.019849, val_mae: 0.087272
2024-12-20 12:13:54,908 - INFO - Epoch 85, train_loss: 0.000339, val_loss: 0.019644, val_mae: 0.086603
2024-12-20 12:14:17,053 - INFO - Epoch 86, train_loss: 0.000286, val_loss: 0.020049, val_mae: 0.087364
2024-12-20 12:14:39,352 - INFO - Epoch 87, train_loss: 0.000265, val_loss: 0.019915, val_mae: 0.086970
2024-12-20 12:15:01,571 - INFO - Epoch 88, train_loss: 0.000224, val_loss: 0.019802, val_mae: 0.086333
2024-12-20 12:15:24,055 - INFO - Epoch 89, train_loss: 0.000182, val_loss: 0.019852, val_mae: 0.086658
2024-12-20 12:15:46,886 - INFO - Epoch 90, train_loss: 0.000166, val_loss: 0.019833, val_mae: 0.086420
2024-12-20 12:16:10,142 - INFO - Epoch 91, train_loss: 0.000144, val_loss: 0.019824, val_mae: 0.086639
2024-12-20 12:16:33,143 - INFO - Epoch 92, train_loss: 0.000133, val_loss: 0.019853, val_mae: 0.086720
2024-12-20 12:16:55,930 - INFO - Epoch 93, train_loss: 0.000117, val_loss: 0.019815, val_mae: 0.086478
2024-12-20 12:17:19,608 - INFO - Epoch 94, train_loss: 0.000103, val_loss: 0.019780, val_mae: 0.086160
2024-12-20 12:17:41,565 - INFO - Epoch 95, train_loss: 0.000097, val_loss: 0.019762, val_mae: 0.086166
2024-12-20 12:18:04,700 - INFO - Epoch 96, train_loss: 0.000091, val_loss: 0.019773, val_mae: 0.086251
2024-12-20 12:18:27,267 - INFO - Epoch 97, train_loss: 0.000084, val_loss: 0.019747, val_mae: 0.086171
2024-12-20 12:18:50,090 - INFO - Epoch 98, train_loss: 0.000080, val_loss: 0.019754, val_mae: 0.086184
2024-12-20 12:19:12,959 - INFO - Epoch 99, train_loss: 0.000077, val_loss: 0.019760, val_mae: 0.086175
2024-12-20 12:19:35,135 - INFO - Epoch 100, train_loss: 0.000075, val_loss: 0.019762, val_mae: 0.086170
2024-12-20 12:19:37,021 - INFO - Test MAE: 0.086160 with best model at Epoch 94
