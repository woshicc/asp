2024-12-20 14:34:13,016 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: C
2024-12-20 14:34:14,374 - INFO - dataset size: 5096, batch size: 8
2024-12-20 14:34:14,374 - INFO - train/valid/test size: 4077/1019/0
2024-12-20 14:34:16,002 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 14:34:18,285 - INFO - initial lr: 0.000200000, meanAE: 2.927044801422438
2024-12-20 14:34:40,160 - INFO - Epoch 1, train_loss: 5.234065, val_loss: 2.691795, val_mae: 1.248803
2024-12-20 14:35:01,552 - INFO - Epoch 2, train_loss: 2.143634, val_loss: 2.055171, val_mae: 1.056683
2024-12-20 14:35:21,606 - INFO - Epoch 3, train_loss: 1.319842, val_loss: 1.234086, val_mae: 0.747805
2024-12-20 14:35:42,564 - INFO - Epoch 4, train_loss: 1.035337, val_loss: 1.084382, val_mae: 0.711537
2024-12-20 14:36:03,196 - INFO - Epoch 5, train_loss: 0.905738, val_loss: 1.023768, val_mae: 0.728972
2024-12-20 14:36:22,709 - INFO - Epoch 6, train_loss: 0.771862, val_loss: 0.881518, val_mae: 0.715924
2024-12-20 14:36:42,443 - INFO - Epoch 7, train_loss: 0.443973, val_loss: 0.389729, val_mae: 0.414680
2024-12-20 14:37:02,565 - INFO - Epoch 8, train_loss: 0.279404, val_loss: 0.335500, val_mae: 0.387001
2024-12-20 14:37:22,999 - INFO - Epoch 9, train_loss: 0.208354, val_loss: 0.244278, val_mae: 0.327962
2024-12-20 14:37:42,422 - INFO - Epoch 10, train_loss: 0.174387, val_loss: 0.198443, val_mae: 0.300169
2024-12-20 14:38:02,334 - INFO - Epoch 11, train_loss: 0.140200, val_loss: 0.171956, val_mae: 0.279929
2024-12-20 14:38:22,619 - INFO - Epoch 12, train_loss: 0.132513, val_loss: 0.199319, val_mae: 0.314690
2024-12-20 14:38:42,968 - INFO - Epoch 13, train_loss: 0.101761, val_loss: 0.176611, val_mae: 0.293654
2024-12-20 14:39:02,806 - INFO - Epoch 14, train_loss: 0.098968, val_loss: 0.140669, val_mae: 0.258806
2024-12-20 14:39:22,750 - INFO - Epoch 15, train_loss: 0.096545, val_loss: 0.163258, val_mae: 0.274222
2024-12-20 14:39:42,566 - INFO - Epoch 16, train_loss: 0.084247, val_loss: 0.128083, val_mae: 0.249574
2024-12-20 14:40:03,279 - INFO - Epoch 17, train_loss: 0.079158, val_loss: 0.112080, val_mae: 0.230017
2024-12-20 14:40:23,354 - INFO - Epoch 18, train_loss: 0.073387, val_loss: 0.087639, val_mae: 0.191703
2024-12-20 14:40:43,738 - INFO - Epoch 19, train_loss: 0.066771, val_loss: 0.089058, val_mae: 0.197660
2024-12-20 14:41:03,877 - INFO - Epoch 20, train_loss: 0.062786, val_loss: 0.141744, val_mae: 0.275366
2024-12-20 14:41:24,352 - INFO - Epoch 21, train_loss: 0.068995, val_loss: 0.082985, val_mae: 0.195366
2024-12-20 14:41:43,685 - INFO - Epoch 22, train_loss: 0.058365, val_loss: 0.096838, val_mae: 0.216429
2024-12-20 14:42:04,058 - INFO - Epoch 23, train_loss: 0.059098, val_loss: 0.087477, val_mae: 0.209458
2024-12-20 14:42:24,985 - INFO - Epoch 24, train_loss: 0.075313, val_loss: 0.109016, val_mae: 0.248527
2024-12-20 14:42:46,542 - INFO - Epoch 25, train_loss: 0.053336, val_loss: 0.073516, val_mae: 0.183647
2024-12-20 14:43:07,112 - INFO - Epoch 26, train_loss: 0.042790, val_loss: 0.082951, val_mae: 0.182941
2024-12-20 14:43:27,258 - INFO - Epoch 27, train_loss: 0.050603, val_loss: 0.119508, val_mae: 0.246387
2024-12-20 14:43:48,176 - INFO - Epoch 28, train_loss: 0.051955, val_loss: 0.065368, val_mae: 0.176249
2024-12-20 14:44:08,233 - INFO - Epoch 29, train_loss: 0.041471, val_loss: 0.060014, val_mae: 0.170856
2024-12-20 14:44:27,789 - INFO - Epoch 30, train_loss: 0.037921, val_loss: 0.054498, val_mae: 0.155234
2024-12-20 14:44:47,618 - INFO - Epoch 31, train_loss: 0.036324, val_loss: 0.047062, val_mae: 0.145562
2024-12-20 14:45:07,558 - INFO - Epoch 32, train_loss: 0.061246, val_loss: 0.101255, val_mae: 0.225910
2024-12-20 14:45:27,526 - INFO - Epoch 33, train_loss: 0.045409, val_loss: 0.039174, val_mae: 0.137840
2024-12-20 14:45:46,711 - INFO - Epoch 34, train_loss: 0.024577, val_loss: 0.042725, val_mae: 0.143415
2024-12-20 14:46:06,798 - INFO - Epoch 35, train_loss: 0.021958, val_loss: 0.043303, val_mae: 0.142609
2024-12-20 14:46:26,748 - INFO - Epoch 36, train_loss: 0.019297, val_loss: 0.035160, val_mae: 0.128406
2024-12-20 14:46:46,728 - INFO - Epoch 37, train_loss: 0.021015, val_loss: 0.066795, val_mae: 0.176232
2024-12-20 14:47:06,336 - INFO - Epoch 38, train_loss: 0.023470, val_loss: 0.054843, val_mae: 0.161932
2024-12-20 14:47:26,334 - INFO - Epoch 39, train_loss: 0.027787, val_loss: 0.038341, val_mae: 0.133574
2024-12-20 14:47:46,080 - INFO - Epoch 40, train_loss: 0.018756, val_loss: 0.035939, val_mae: 0.129375
2024-12-20 14:48:06,603 - INFO - Epoch 41, train_loss: 0.021993, val_loss: 0.061797, val_mae: 0.179885
2024-12-20 14:48:26,393 - INFO - Epoch 42, train_loss: 0.021607, val_loss: 0.040574, val_mae: 0.138107
2024-12-20 14:48:46,541 - INFO - Epoch 43, train_loss: 0.017322, val_loss: 0.034108, val_mae: 0.120441
2024-12-20 14:49:06,401 - INFO - Epoch 44, train_loss: 0.295691, val_loss: 0.062241, val_mae: 0.181705
2024-12-20 14:49:26,750 - INFO - Epoch 45, train_loss: 0.024512, val_loss: 0.032921, val_mae: 0.117779
2024-12-20 14:49:45,978 - INFO - Epoch 46, train_loss: 0.012516, val_loss: 0.030423, val_mae: 0.113100
2024-12-20 14:50:06,161 - INFO - Epoch 47, train_loss: 0.009554, val_loss: 0.028671, val_mae: 0.107028
2024-12-20 14:50:26,947 - INFO - Epoch 48, train_loss: 0.008733, val_loss: 0.031440, val_mae: 0.113020
2024-12-20 14:50:48,512 - INFO - Epoch 49, train_loss: 0.007762, val_loss: 0.029884, val_mae: 0.109540
2024-12-20 14:51:08,791 - INFO - Epoch 50, train_loss: 0.007285, val_loss: 0.027624, val_mae: 0.103695
2024-12-20 14:51:28,672 - INFO - Epoch 51, train_loss: 0.006731, val_loss: 0.026910, val_mae: 0.099476
2024-12-20 14:51:49,620 - INFO - Epoch 52, train_loss: 0.006936, val_loss: 0.027554, val_mae: 0.102824
2024-12-20 14:52:09,585 - INFO - Epoch 53, train_loss: 0.006479, val_loss: 0.027010, val_mae: 0.108295
2024-12-20 14:52:29,049 - INFO - Epoch 54, train_loss: 0.008296, val_loss: 0.030394, val_mae: 0.114764
2024-12-20 14:52:48,881 - INFO - Epoch 55, train_loss: 0.006405, val_loss: 0.026955, val_mae: 0.106493
2024-12-20 14:53:08,788 - INFO - Epoch 56, train_loss: 0.005974, val_loss: 0.025555, val_mae: 0.099816
2024-12-20 14:53:28,798 - INFO - Epoch 57, train_loss: 0.006114, val_loss: 0.028735, val_mae: 0.102316
2024-12-20 14:53:48,162 - INFO - Epoch 58, train_loss: 0.007140, val_loss: 0.030572, val_mae: 0.111479
2024-12-20 14:54:08,405 - INFO - Epoch 59, train_loss: 0.007034, val_loss: 0.027564, val_mae: 0.105113
2024-12-20 14:54:28,739 - INFO - Epoch 60, train_loss: 0.009241, val_loss: 0.031651, val_mae: 0.106340
2024-12-20 14:54:48,795 - INFO - Epoch 61, train_loss: 0.006253, val_loss: 0.025418, val_mae: 0.095244
2024-12-20 14:55:08,176 - INFO - Epoch 62, train_loss: 0.005323, val_loss: 0.027804, val_mae: 0.100574
2024-12-20 14:55:28,003 - INFO - Epoch 63, train_loss: 0.005082, val_loss: 0.026638, val_mae: 0.095332
2024-12-20 14:55:48,138 - INFO - Epoch 64, train_loss: 0.006214, val_loss: 0.029325, val_mae: 0.107760
2024-12-20 14:56:08,783 - INFO - Epoch 65, train_loss: 0.005462, val_loss: 0.025816, val_mae: 0.097734
2024-12-20 14:56:28,666 - INFO - Epoch 66, train_loss: 0.004919, val_loss: 0.027529, val_mae: 0.098303
2024-12-20 14:56:48,766 - INFO - Epoch 67, train_loss: 0.005471, val_loss: 0.026099, val_mae: 0.093222
2024-12-20 14:57:08,757 - INFO - Epoch 68, train_loss: 0.004438, val_loss: 0.025528, val_mae: 0.091857
2024-12-20 14:57:29,385 - INFO - Epoch 69, train_loss: 0.004038, val_loss: 0.026066, val_mae: 0.094737
2024-12-20 14:57:48,863 - INFO - Epoch 70, train_loss: 0.003627, val_loss: 0.024619, val_mae: 0.091093
2024-12-20 14:58:09,306 - INFO - Epoch 71, train_loss: 0.003283, val_loss: 0.024652, val_mae: 0.091005
2024-12-20 14:58:30,314 - INFO - Epoch 72, train_loss: 0.003564, val_loss: 0.026161, val_mae: 0.095377
2024-12-20 14:58:51,846 - INFO - Epoch 73, train_loss: 0.003081, val_loss: 0.023112, val_mae: 0.086729
2024-12-20 14:59:11,284 - INFO - Epoch 74, train_loss: 0.002400, val_loss: 0.025332, val_mae: 0.091637
2024-12-20 14:59:31,085 - INFO - Epoch 75, train_loss: 0.002144, val_loss: 0.023769, val_mae: 0.087715
2024-12-20 14:59:51,978 - INFO - Epoch 76, train_loss: 0.002582, val_loss: 0.024786, val_mae: 0.089706
2024-12-20 15:00:11,575 - INFO - Epoch 77, train_loss: 0.001937, val_loss: 0.024574, val_mae: 0.088723
2024-12-20 15:00:31,022 - INFO - Epoch 78, train_loss: 0.001394, val_loss: 0.023771, val_mae: 0.084488
2024-12-20 15:00:50,705 - INFO - Epoch 79, train_loss: 0.001264, val_loss: 0.023125, val_mae: 0.084246
2024-12-20 15:01:10,798 - INFO - Epoch 80, train_loss: 0.001089, val_loss: 0.023471, val_mae: 0.084340
2024-12-20 15:01:30,743 - INFO - Epoch 81, train_loss: 0.001143, val_loss: 0.022547, val_mae: 0.084668
2024-12-20 15:01:50,120 - INFO - Epoch 82, train_loss: 0.000909, val_loss: 0.023747, val_mae: 0.083929
2024-12-20 15:02:10,303 - INFO - Epoch 83, train_loss: 0.000893, val_loss: 0.022624, val_mae: 0.084420
2024-12-20 15:02:30,384 - INFO - Epoch 84, train_loss: 0.000694, val_loss: 0.023015, val_mae: 0.082881
2024-12-20 15:02:50,354 - INFO - Epoch 85, train_loss: 0.000556, val_loss: 0.022596, val_mae: 0.081946
2024-12-20 15:03:10,396 - INFO - Epoch 86, train_loss: 0.000526, val_loss: 0.022923, val_mae: 0.082547
2024-12-20 15:03:30,088 - INFO - Epoch 87, train_loss: 0.000440, val_loss: 0.022553, val_mae: 0.081451
2024-12-20 15:03:50,195 - INFO - Epoch 88, train_loss: 0.000369, val_loss: 0.022535, val_mae: 0.081481
2024-12-20 15:04:10,335 - INFO - Epoch 89, train_loss: 0.000316, val_loss: 0.022939, val_mae: 0.081859
2024-12-20 15:04:30,706 - INFO - Epoch 90, train_loss: 0.000292, val_loss: 0.022735, val_mae: 0.082073
2024-12-20 15:04:50,941 - INFO - Epoch 91, train_loss: 0.000262, val_loss: 0.022743, val_mae: 0.081224
2024-12-20 15:05:11,276 - INFO - Epoch 92, train_loss: 0.000232, val_loss: 0.022675, val_mae: 0.081367
2024-12-20 15:05:31,291 - INFO - Epoch 93, train_loss: 0.000210, val_loss: 0.022593, val_mae: 0.081521
2024-12-20 15:05:50,971 - INFO - Epoch 94, train_loss: 0.000191, val_loss: 0.022790, val_mae: 0.081423
2024-12-20 15:06:13,110 - INFO - Epoch 95, train_loss: 0.000175, val_loss: 0.022705, val_mae: 0.081276
2024-12-20 15:06:34,881 - INFO - Epoch 96, train_loss: 0.000166, val_loss: 0.022666, val_mae: 0.081175
2024-12-20 15:06:55,347 - INFO - Epoch 97, train_loss: 0.000156, val_loss: 0.022680, val_mae: 0.081337
2024-12-20 15:07:15,001 - INFO - Epoch 98, train_loss: 0.000149, val_loss: 0.022675, val_mae: 0.081310
2024-12-20 15:07:34,633 - INFO - Epoch 99, train_loss: 0.000144, val_loss: 0.022681, val_mae: 0.081294
2024-12-20 15:07:54,819 - INFO - Epoch 100, train_loss: 0.000142, val_loss: 0.022676, val_mae: 0.081291
2024-12-20 15:07:56,583 - INFO - Test MAE: 0.081175 with best model at Epoch 96
