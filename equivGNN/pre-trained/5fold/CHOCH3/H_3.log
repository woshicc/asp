2024-12-20 20:23:38,319 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: H
2024-12-20 20:23:40,171 - INFO - dataset size: 6696, batch size: 8
2024-12-20 20:23:40,171 - INFO - train/valid/test size: 5357/1339/0
2024-12-20 20:23:41,846 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 20:23:44,652 - INFO - initial lr: 0.000200000, meanAE: 0.5703798332375184
2024-12-20 20:24:11,834 - INFO - Epoch 1, train_loss: 0.253938, val_loss: 0.188211, val_mae: 0.325564
2024-12-20 20:24:38,431 - INFO - Epoch 2, train_loss: 0.134095, val_loss: 0.111517, val_mae: 0.237779
2024-12-20 20:25:05,023 - INFO - Epoch 3, train_loss: 0.087073, val_loss: 0.082265, val_mae: 0.198051
2024-12-20 20:25:31,927 - INFO - Epoch 4, train_loss: 0.061953, val_loss: 0.055576, val_mae: 0.160874
2024-12-20 20:25:57,683 - INFO - Epoch 5, train_loss: 0.042553, val_loss: 0.041046, val_mae: 0.147192
2024-12-20 20:26:25,771 - INFO - Epoch 6, train_loss: 0.032673, val_loss: 0.035984, val_mae: 0.141669
2024-12-20 20:26:54,306 - INFO - Epoch 7, train_loss: 0.028576, val_loss: 0.027844, val_mae: 0.116681
2024-12-20 20:27:19,747 - INFO - Epoch 8, train_loss: 0.025767, val_loss: 0.025912, val_mae: 0.114565
2024-12-20 20:27:46,789 - INFO - Epoch 9, train_loss: 0.022411, val_loss: 0.024560, val_mae: 0.109405
2024-12-20 20:28:13,034 - INFO - Epoch 10, train_loss: 0.021293, val_loss: 0.024292, val_mae: 0.107251
2024-12-20 20:28:38,574 - INFO - Epoch 11, train_loss: 0.018761, val_loss: 0.025720, val_mae: 0.115388
2024-12-20 20:29:04,284 - INFO - Epoch 12, train_loss: 0.017842, val_loss: 0.019352, val_mae: 0.096388
2024-12-20 20:29:30,448 - INFO - Epoch 13, train_loss: 0.015287, val_loss: 0.021506, val_mae: 0.106095
2024-12-20 20:29:55,656 - INFO - Epoch 14, train_loss: 0.014936, val_loss: 0.020101, val_mae: 0.093690
2024-12-20 20:30:21,981 - INFO - Epoch 15, train_loss: 0.014409, val_loss: 0.018541, val_mae: 0.092708
2024-12-20 20:30:49,179 - INFO - Epoch 16, train_loss: 0.012813, val_loss: 0.018701, val_mae: 0.099722
2024-12-20 20:31:14,813 - INFO - Epoch 17, train_loss: 0.012636, val_loss: 0.024989, val_mae: 0.112670
2024-12-20 20:31:41,497 - INFO - Epoch 18, train_loss: 0.014120, val_loss: 0.018955, val_mae: 0.093474
2024-12-20 20:32:07,726 - INFO - Epoch 19, train_loss: 0.013127, val_loss: 0.013958, val_mae: 0.084024
2024-12-20 20:32:34,734 - INFO - Epoch 20, train_loss: 0.009863, val_loss: 0.018082, val_mae: 0.086015
2024-12-20 20:33:01,587 - INFO - Epoch 21, train_loss: 0.011643, val_loss: 0.014961, val_mae: 0.084905
2024-12-20 20:33:27,793 - INFO - Epoch 22, train_loss: 0.010332, val_loss: 0.015900, val_mae: 0.087206
2024-12-20 20:33:53,539 - INFO - Epoch 23, train_loss: 0.009425, val_loss: 0.024108, val_mae: 0.114496
2024-12-20 20:34:21,182 - INFO - Epoch 24, train_loss: 0.011134, val_loss: 0.014907, val_mae: 0.083565
2024-12-20 20:34:49,518 - INFO - Epoch 25, train_loss: 0.010061, val_loss: 0.027168, val_mae: 0.083567
2024-12-20 20:35:15,753 - INFO - Epoch 26, train_loss: 0.010047, val_loss: 0.012508, val_mae: 0.077177
2024-12-20 20:35:41,645 - INFO - Epoch 27, train_loss: 0.009174, val_loss: 0.013649, val_mae: 0.079498
2024-12-20 20:36:07,652 - INFO - Epoch 28, train_loss: 0.009000, val_loss: 0.012272, val_mae: 0.073802
2024-12-20 20:36:33,410 - INFO - Epoch 29, train_loss: 0.007796, val_loss: 0.012540, val_mae: 0.075223
2024-12-20 20:36:59,230 - INFO - Epoch 30, train_loss: 0.006973, val_loss: 0.012505, val_mae: 0.076463
2024-12-20 20:37:25,154 - INFO - Epoch 31, train_loss: 0.006625, val_loss: 0.013423, val_mae: 0.071841
2024-12-20 20:37:50,336 - INFO - Epoch 32, train_loss: 0.006862, val_loss: 0.011678, val_mae: 0.070914
2024-12-20 20:38:17,532 - INFO - Epoch 33, train_loss: 0.006405, val_loss: 0.012862, val_mae: 0.081652
2024-12-20 20:38:45,139 - INFO - Epoch 34, train_loss: 0.006690, val_loss: 0.011349, val_mae: 0.069590
2024-12-20 20:39:11,712 - INFO - Epoch 35, train_loss: 0.004966, val_loss: 0.009162, val_mae: 0.062619
2024-12-20 20:39:38,995 - INFO - Epoch 36, train_loss: 0.005224, val_loss: 0.010728, val_mae: 0.070431
2024-12-20 20:40:07,767 - INFO - Epoch 37, train_loss: 0.004399, val_loss: 0.010077, val_mae: 0.064721
2024-12-20 20:40:36,735 - INFO - Epoch 38, train_loss: 0.003964, val_loss: 0.013054, val_mae: 0.076320
2024-12-20 20:41:05,990 - INFO - Epoch 39, train_loss: 0.005426, val_loss: 0.012138, val_mae: 0.076045
2024-12-20 20:41:34,679 - INFO - Epoch 40, train_loss: 0.005231, val_loss: 0.009685, val_mae: 0.063966
2024-12-20 20:42:02,284 - INFO - Epoch 41, train_loss: 0.004191, val_loss: 0.008805, val_mae: 0.061517
2024-12-20 20:42:29,301 - INFO - Epoch 42, train_loss: 0.003259, val_loss: 0.009289, val_mae: 0.061465
2024-12-20 20:42:55,881 - INFO - Epoch 43, train_loss: 0.003374, val_loss: 0.010087, val_mae: 0.064537
2024-12-20 20:43:21,687 - INFO - Epoch 44, train_loss: 0.005918, val_loss: 0.010122, val_mae: 0.068588
2024-12-20 20:43:47,457 - INFO - Epoch 45, train_loss: 0.003418, val_loss: 0.009214, val_mae: 0.063012
2024-12-20 20:44:13,508 - INFO - Epoch 46, train_loss: 0.002726, val_loss: 0.009026, val_mae: 0.060843
2024-12-20 20:44:39,096 - INFO - Epoch 47, train_loss: 0.002605, val_loss: 0.008532, val_mae: 0.059576
2024-12-20 20:45:04,981 - INFO - Epoch 48, train_loss: 0.003253, val_loss: 0.008679, val_mae: 0.060514
2024-12-20 20:45:31,152 - INFO - Epoch 49, train_loss: 0.002557, val_loss: 0.009144, val_mae: 0.059087
2024-12-20 20:45:56,594 - INFO - Epoch 50, train_loss: 0.002220, val_loss: 0.009671, val_mae: 0.062289
2024-12-20 20:46:23,035 - INFO - Epoch 51, train_loss: 0.002725, val_loss: 0.008775, val_mae: 0.058592
2024-12-20 20:46:49,326 - INFO - Epoch 52, train_loss: 0.002329, val_loss: 0.008255, val_mae: 0.056236
2024-12-20 20:47:15,313 - INFO - Epoch 53, train_loss: 0.001794, val_loss: 0.008904, val_mae: 0.060837
2024-12-20 20:47:41,489 - INFO - Epoch 54, train_loss: 0.002919, val_loss: 0.007696, val_mae: 0.053478
2024-12-20 20:48:08,192 - INFO - Epoch 55, train_loss: 0.002105, val_loss: 0.008674, val_mae: 0.055280
2024-12-20 20:48:34,551 - INFO - Epoch 56, train_loss: 0.001458, val_loss: 0.007733, val_mae: 0.057167
2024-12-20 20:49:00,959 - INFO - Epoch 57, train_loss: 0.001376, val_loss: 0.007747, val_mae: 0.053677
2024-12-20 20:49:27,158 - INFO - Epoch 58, train_loss: 0.001621, val_loss: 0.009847, val_mae: 0.065730
2024-12-20 20:49:52,484 - INFO - Epoch 59, train_loss: 0.001493, val_loss: 0.008387, val_mae: 0.058895
2024-12-20 20:50:18,448 - INFO - Epoch 60, train_loss: 0.001115, val_loss: 0.007832, val_mae: 0.053784
2024-12-20 20:50:44,306 - INFO - Epoch 61, train_loss: 0.000898, val_loss: 0.008020, val_mae: 0.053489
2024-12-20 20:51:10,415 - INFO - Epoch 62, train_loss: 0.000945, val_loss: 0.007898, val_mae: 0.055091
2024-12-20 20:51:36,832 - INFO - Epoch 63, train_loss: 0.000986, val_loss: 0.007591, val_mae: 0.052714
2024-12-20 20:52:02,896 - INFO - Epoch 64, train_loss: 0.001037, val_loss: 0.007448, val_mae: 0.053774
2024-12-20 20:52:28,478 - INFO - Epoch 65, train_loss: 0.000799, val_loss: 0.007104, val_mae: 0.050296
2024-12-20 20:52:54,262 - INFO - Epoch 66, train_loss: 0.000628, val_loss: 0.007183, val_mae: 0.049789
2024-12-20 20:53:21,117 - INFO - Epoch 67, train_loss: 0.000614, val_loss: 0.007302, val_mae: 0.051788
2024-12-20 20:53:46,585 - INFO - Epoch 68, train_loss: 0.000549, val_loss: 0.007201, val_mae: 0.049930
2024-12-20 20:54:12,681 - INFO - Epoch 69, train_loss: 0.000557, val_loss: 0.007642, val_mae: 0.051461
2024-12-20 20:54:38,737 - INFO - Epoch 70, train_loss: 0.000512, val_loss: 0.007298, val_mae: 0.051277
2024-12-20 20:55:04,697 - INFO - Epoch 71, train_loss: 0.000526, val_loss: 0.007234, val_mae: 0.049603
2024-12-20 20:55:30,920 - INFO - Epoch 72, train_loss: 0.000387, val_loss: 0.006961, val_mae: 0.049912
2024-12-20 20:55:57,403 - INFO - Epoch 73, train_loss: 0.000364, val_loss: 0.007369, val_mae: 0.050498
2024-12-20 20:56:23,542 - INFO - Epoch 74, train_loss: 0.000324, val_loss: 0.007856, val_mae: 0.050798
2024-12-20 20:56:49,937 - INFO - Epoch 75, train_loss: 0.000315, val_loss: 0.007225, val_mae: 0.049667
2024-12-20 20:57:16,324 - INFO - Epoch 76, train_loss: 0.000225, val_loss: 0.007325, val_mae: 0.049098
2024-12-20 20:57:44,528 - INFO - Epoch 77, train_loss: 0.000184, val_loss: 0.007340, val_mae: 0.049184
2024-12-20 20:58:11,356 - INFO - Epoch 78, train_loss: 0.000149, val_loss: 0.007221, val_mae: 0.048836
2024-12-20 20:58:37,660 - INFO - Epoch 79, train_loss: 0.000144, val_loss: 0.007165, val_mae: 0.048365
2024-12-20 20:59:03,680 - INFO - Epoch 80, train_loss: 0.000133, val_loss: 0.007243, val_mae: 0.048721
2024-12-20 20:59:30,436 - INFO - Epoch 81, train_loss: 0.000104, val_loss: 0.007084, val_mae: 0.048050
2024-12-20 20:59:56,598 - INFO - Epoch 82, train_loss: 0.000101, val_loss: 0.007011, val_mae: 0.047748
2024-12-20 21:00:22,413 - INFO - Epoch 83, train_loss: 0.000084, val_loss: 0.007127, val_mae: 0.048290
2024-12-20 21:00:48,077 - INFO - Epoch 84, train_loss: 0.000068, val_loss: 0.007182, val_mae: 0.048499
2024-12-20 21:01:14,332 - INFO - Epoch 85, train_loss: 0.000057, val_loss: 0.007171, val_mae: 0.047922
2024-12-20 21:01:40,486 - INFO - Epoch 86, train_loss: 0.000047, val_loss: 0.007140, val_mae: 0.048236
2024-12-20 21:02:06,025 - INFO - Epoch 87, train_loss: 0.000041, val_loss: 0.007096, val_mae: 0.047973
2024-12-20 21:02:32,169 - INFO - Epoch 88, train_loss: 0.000033, val_loss: 0.007081, val_mae: 0.047823
2024-12-20 21:02:58,362 - INFO - Epoch 89, train_loss: 0.000030, val_loss: 0.007126, val_mae: 0.047845
2024-12-20 21:03:24,198 - INFO - Epoch 90, train_loss: 0.000026, val_loss: 0.007101, val_mae: 0.047881
2024-12-20 21:03:50,194 - INFO - Epoch 91, train_loss: 0.000023, val_loss: 0.007102, val_mae: 0.047902
2024-12-20 21:04:16,838 - INFO - Epoch 92, train_loss: 0.000020, val_loss: 0.007081, val_mae: 0.047721
2024-12-20 21:04:43,334 - INFO - Epoch 93, train_loss: 0.000017, val_loss: 0.007061, val_mae: 0.047646
2024-12-20 21:05:09,680 - INFO - Epoch 94, train_loss: 0.000016, val_loss: 0.007106, val_mae: 0.047763
2024-12-20 21:05:35,711 - INFO - Epoch 95, train_loss: 0.000015, val_loss: 0.007087, val_mae: 0.047698
2024-12-20 21:06:01,095 - INFO - Epoch 96, train_loss: 0.000014, val_loss: 0.007092, val_mae: 0.047756
2024-12-20 21:06:27,106 - INFO - Epoch 97, train_loss: 0.000013, val_loss: 0.007098, val_mae: 0.047735
2024-12-20 21:06:52,848 - INFO - Epoch 98, train_loss: 0.000012, val_loss: 0.007092, val_mae: 0.047717
2024-12-20 21:07:19,622 - INFO - Epoch 99, train_loss: 0.000012, val_loss: 0.007093, val_mae: 0.047718
2024-12-20 21:07:45,315 - INFO - Epoch 100, train_loss: 0.000012, val_loss: 0.007091, val_mae: 0.047710
2024-12-20 21:07:47,434 - INFO - Test MAE: 0.047646 with best model at Epoch 93
