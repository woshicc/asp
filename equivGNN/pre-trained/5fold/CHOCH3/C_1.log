2024-12-20 12:53:18,700 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: C
2024-12-20 12:53:20,018 - INFO - dataset size: 5096, batch size: 8
2024-12-20 12:53:20,019 - INFO - train/valid/test size: 4077/1019/0
2024-12-20 12:53:21,672 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 12:53:24,035 - INFO - initial lr: 0.000200000, meanAE: 2.8934804407071426
2024-12-20 12:53:43,816 - INFO - Epoch 1, train_loss: 5.356674, val_loss: 2.600883, val_mae: 1.277642
2024-12-20 12:54:04,099 - INFO - Epoch 2, train_loss: 2.182372, val_loss: 1.829526, val_mae: 1.016649
2024-12-20 12:54:24,866 - INFO - Epoch 3, train_loss: 1.325634, val_loss: 1.084851, val_mae: 0.763279
2024-12-20 12:54:45,131 - INFO - Epoch 4, train_loss: 1.043627, val_loss: 0.928013, val_mae: 0.698456
2024-12-20 12:55:05,389 - INFO - Epoch 5, train_loss: 0.926617, val_loss: 0.820197, val_mae: 0.652237
2024-12-20 12:55:25,711 - INFO - Epoch 6, train_loss: 0.789655, val_loss: 0.709106, val_mae: 0.643901
2024-12-20 12:55:47,244 - INFO - Epoch 7, train_loss: 0.458607, val_loss: 0.368491, val_mae: 0.439711
2024-12-20 12:56:07,995 - INFO - Epoch 8, train_loss: 0.306254, val_loss: 0.286175, val_mae: 0.382477
2024-12-20 12:56:29,323 - INFO - Epoch 9, train_loss: 0.218510, val_loss: 0.199465, val_mae: 0.323761
2024-12-20 12:56:49,938 - INFO - Epoch 10, train_loss: 0.165055, val_loss: 0.154761, val_mae: 0.289140
2024-12-20 12:57:11,634 - INFO - Epoch 11, train_loss: 0.132269, val_loss: 0.156361, val_mae: 0.293922
2024-12-20 12:57:32,015 - INFO - Epoch 12, train_loss: 0.142095, val_loss: 0.186754, val_mae: 0.341761
2024-12-20 12:57:52,409 - INFO - Epoch 13, train_loss: 0.101744, val_loss: 0.232865, val_mae: 0.360744
2024-12-20 12:58:12,747 - INFO - Epoch 14, train_loss: 0.100703, val_loss: 0.142388, val_mae: 0.275059
2024-12-20 12:58:33,487 - INFO - Epoch 15, train_loss: 0.091108, val_loss: 0.081737, val_mae: 0.216597
2024-12-20 12:58:53,943 - INFO - Epoch 16, train_loss: 0.083021, val_loss: 0.072426, val_mae: 0.200241
2024-12-20 12:59:13,884 - INFO - Epoch 17, train_loss: 0.077882, val_loss: 0.090835, val_mae: 0.229484
2024-12-20 12:59:33,425 - INFO - Epoch 18, train_loss: 0.074444, val_loss: 0.212304, val_mae: 0.349213
2024-12-20 12:59:53,785 - INFO - Epoch 19, train_loss: 0.074735, val_loss: 0.086346, val_mae: 0.229797
2024-12-20 13:00:13,733 - INFO - Epoch 20, train_loss: 0.066863, val_loss: 0.068535, val_mae: 0.196372
2024-12-20 13:00:33,808 - INFO - Epoch 21, train_loss: 0.067124, val_loss: 0.065195, val_mae: 0.188705
2024-12-20 13:00:53,548 - INFO - Epoch 22, train_loss: 0.065706, val_loss: 0.064229, val_mae: 0.198230
2024-12-20 13:01:14,631 - INFO - Epoch 23, train_loss: 0.051306, val_loss: 0.039167, val_mae: 0.151311
2024-12-20 13:01:34,704 - INFO - Epoch 24, train_loss: 0.087764, val_loss: 0.113237, val_mae: 0.260709
2024-12-20 13:01:54,717 - INFO - Epoch 25, train_loss: 0.098769, val_loss: 0.062810, val_mae: 0.189147
2024-12-20 13:02:15,004 - INFO - Epoch 26, train_loss: 0.047214, val_loss: 0.054394, val_mae: 0.180117
2024-12-20 13:02:35,396 - INFO - Epoch 27, train_loss: 0.036806, val_loss: 0.051863, val_mae: 0.175848
2024-12-20 13:02:55,818 - INFO - Epoch 28, train_loss: 0.043083, val_loss: 0.056634, val_mae: 0.184763
2024-12-20 13:03:16,016 - INFO - Epoch 29, train_loss: 0.035361, val_loss: 0.053110, val_mae: 0.176716
2024-12-20 13:03:36,091 - INFO - Epoch 30, train_loss: 0.029591, val_loss: 0.107662, val_mae: 0.219918
2024-12-20 13:03:56,410 - INFO - Epoch 31, train_loss: 0.046038, val_loss: 0.056517, val_mae: 0.180654
2024-12-20 13:04:16,628 - INFO - Epoch 32, train_loss: 0.035541, val_loss: 0.082403, val_mae: 0.232241
2024-12-20 13:04:37,198 - INFO - Epoch 33, train_loss: 0.036485, val_loss: 0.083689, val_mae: 0.230326
2024-12-20 13:04:58,262 - INFO - Epoch 34, train_loss: 0.031463, val_loss: 0.041381, val_mae: 0.150667
2024-12-20 13:05:19,178 - INFO - Epoch 35, train_loss: 0.034701, val_loss: 0.068081, val_mae: 0.199346
2024-12-20 13:05:39,109 - INFO - Epoch 36, train_loss: 0.031172, val_loss: 0.040002, val_mae: 0.150141
2024-12-20 13:05:59,508 - INFO - Epoch 37, train_loss: 0.026334, val_loss: 0.036785, val_mae: 0.150577
2024-12-20 13:06:20,228 - INFO - Epoch 38, train_loss: 0.022602, val_loss: 0.039189, val_mae: 0.149899
2024-12-20 13:06:40,823 - INFO - Epoch 39, train_loss: 0.023239, val_loss: 0.031322, val_mae: 0.135422
2024-12-20 13:07:01,216 - INFO - Epoch 40, train_loss: 0.026228, val_loss: 0.039718, val_mae: 0.150988
2024-12-20 13:07:20,760 - INFO - Epoch 41, train_loss: 0.023139, val_loss: 0.031175, val_mae: 0.128800
2024-12-20 13:07:40,670 - INFO - Epoch 42, train_loss: 0.023058, val_loss: 0.032684, val_mae: 0.132218
2024-12-20 13:08:00,697 - INFO - Epoch 43, train_loss: 0.019767, val_loss: 0.032800, val_mae: 0.131307
2024-12-20 13:08:20,467 - INFO - Epoch 44, train_loss: 0.016376, val_loss: 0.028472, val_mae: 0.125438
2024-12-20 13:08:39,991 - INFO - Epoch 45, train_loss: 0.015862, val_loss: 0.035401, val_mae: 0.142169
2024-12-20 13:08:59,641 - INFO - Epoch 46, train_loss: 0.016821, val_loss: 0.031790, val_mae: 0.130352
2024-12-20 13:09:20,147 - INFO - Epoch 47, train_loss: 0.014269, val_loss: 0.025996, val_mae: 0.118086
2024-12-20 13:09:39,771 - INFO - Epoch 48, train_loss: 0.019669, val_loss: 0.028815, val_mae: 0.124315
2024-12-20 13:09:59,717 - INFO - Epoch 49, train_loss: 0.013031, val_loss: 0.021996, val_mae: 0.109742
2024-12-20 13:10:20,617 - INFO - Epoch 50, train_loss: 0.013270, val_loss: 0.019861, val_mae: 0.104773
2024-12-20 13:10:40,842 - INFO - Epoch 51, train_loss: 0.011911, val_loss: 0.022022, val_mae: 0.108986
2024-12-20 13:11:01,572 - INFO - Epoch 52, train_loss: 0.010369, val_loss: 0.020390, val_mae: 0.102385
2024-12-20 13:11:21,312 - INFO - Epoch 53, train_loss: 0.009667, val_loss: 0.019549, val_mae: 0.098820
2024-12-20 13:11:41,538 - INFO - Epoch 54, train_loss: 0.008765, val_loss: 0.029209, val_mae: 0.132685
2024-12-20 13:12:01,870 - INFO - Epoch 55, train_loss: 0.010554, val_loss: 0.022416, val_mae: 0.110940
2024-12-20 13:12:22,300 - INFO - Epoch 56, train_loss: 0.011922, val_loss: 0.023141, val_mae: 0.107426
2024-12-20 13:12:42,909 - INFO - Epoch 57, train_loss: 0.007837, val_loss: 0.019190, val_mae: 0.096729
2024-12-20 13:13:04,327 - INFO - Epoch 58, train_loss: 0.006971, val_loss: 0.021249, val_mae: 0.101920
2024-12-20 13:13:24,837 - INFO - Epoch 59, train_loss: 0.005778, val_loss: 0.018759, val_mae: 0.096541
2024-12-20 13:13:45,106 - INFO - Epoch 60, train_loss: 0.007013, val_loss: 0.019752, val_mae: 0.099222
2024-12-20 13:14:04,808 - INFO - Epoch 61, train_loss: 0.007292, val_loss: 0.018770, val_mae: 0.093361
2024-12-20 13:14:25,311 - INFO - Epoch 62, train_loss: 0.005933, val_loss: 0.018316, val_mae: 0.093735
2024-12-20 13:14:45,340 - INFO - Epoch 63, train_loss: 0.005219, val_loss: 0.016192, val_mae: 0.084101
2024-12-20 13:15:05,332 - INFO - Epoch 64, train_loss: 0.003774, val_loss: 0.016379, val_mae: 0.084314
2024-12-20 13:15:24,517 - INFO - Epoch 65, train_loss: 0.003745, val_loss: 0.017450, val_mae: 0.091085
2024-12-20 13:15:44,742 - INFO - Epoch 66, train_loss: 0.004052, val_loss: 0.016225, val_mae: 0.085920
2024-12-20 13:16:04,348 - INFO - Epoch 67, train_loss: 0.003998, val_loss: 0.017547, val_mae: 0.090234
2024-12-20 13:16:24,728 - INFO - Epoch 68, train_loss: 0.003121, val_loss: 0.015345, val_mae: 0.083239
2024-12-20 13:16:45,366 - INFO - Epoch 69, train_loss: 0.002856, val_loss: 0.014880, val_mae: 0.082600
2024-12-20 13:17:05,341 - INFO - Epoch 70, train_loss: 0.002315, val_loss: 0.016753, val_mae: 0.087287
2024-12-20 13:17:24,915 - INFO - Epoch 71, train_loss: 0.002547, val_loss: 0.016071, val_mae: 0.085447
2024-12-20 13:17:45,109 - INFO - Epoch 72, train_loss: 0.002735, val_loss: 0.015611, val_mae: 0.086537
2024-12-20 13:18:05,124 - INFO - Epoch 73, train_loss: 0.002179, val_loss: 0.014721, val_mae: 0.081994
2024-12-20 13:18:24,753 - INFO - Epoch 74, train_loss: 0.001461, val_loss: 0.015079, val_mae: 0.082377
2024-12-20 13:18:44,963 - INFO - Epoch 75, train_loss: 0.001345, val_loss: 0.013901, val_mae: 0.078676
2024-12-20 13:19:05,211 - INFO - Epoch 76, train_loss: 0.001240, val_loss: 0.014446, val_mae: 0.078551
2024-12-20 13:19:25,093 - INFO - Epoch 77, train_loss: 0.001125, val_loss: 0.013888, val_mae: 0.077536
2024-12-20 13:19:45,678 - INFO - Epoch 78, train_loss: 0.001111, val_loss: 0.014413, val_mae: 0.077619
2024-12-20 13:20:06,539 - INFO - Epoch 79, train_loss: 0.000883, val_loss: 0.013844, val_mae: 0.076629
2024-12-20 13:20:27,935 - INFO - Epoch 80, train_loss: 0.000743, val_loss: 0.013995, val_mae: 0.075912
2024-12-20 13:20:48,787 - INFO - Epoch 81, train_loss: 0.000592, val_loss: 0.013859, val_mae: 0.075684
2024-12-20 13:21:09,409 - INFO - Epoch 82, train_loss: 0.000542, val_loss: 0.014202, val_mae: 0.076568
2024-12-20 13:21:30,637 - INFO - Epoch 83, train_loss: 0.000503, val_loss: 0.013505, val_mae: 0.074206
2024-12-20 13:21:50,605 - INFO - Epoch 84, train_loss: 0.000425, val_loss: 0.013761, val_mae: 0.075571
2024-12-20 13:22:10,880 - INFO - Epoch 85, train_loss: 0.000358, val_loss: 0.013642, val_mae: 0.074514
2024-12-20 13:22:31,493 - INFO - Epoch 86, train_loss: 0.000307, val_loss: 0.013681, val_mae: 0.074790
2024-12-20 13:22:52,377 - INFO - Epoch 87, train_loss: 0.000256, val_loss: 0.013432, val_mae: 0.074227
2024-12-20 13:23:12,312 - INFO - Epoch 88, train_loss: 0.000238, val_loss: 0.013698, val_mae: 0.074648
2024-12-20 13:23:32,363 - INFO - Epoch 89, train_loss: 0.000206, val_loss: 0.013559, val_mae: 0.073687
2024-12-20 13:23:52,240 - INFO - Epoch 90, train_loss: 0.000176, val_loss: 0.013523, val_mae: 0.073697
2024-12-20 13:24:12,182 - INFO - Epoch 91, train_loss: 0.000155, val_loss: 0.013409, val_mae: 0.072987
2024-12-20 13:24:32,072 - INFO - Epoch 92, train_loss: 0.000138, val_loss: 0.013564, val_mae: 0.073800
2024-12-20 13:24:51,885 - INFO - Epoch 93, train_loss: 0.000124, val_loss: 0.013529, val_mae: 0.073470
2024-12-20 13:25:11,596 - INFO - Epoch 94, train_loss: 0.000113, val_loss: 0.013536, val_mae: 0.073407
2024-12-20 13:25:31,324 - INFO - Epoch 95, train_loss: 0.000105, val_loss: 0.013524, val_mae: 0.073399
2024-12-20 13:25:50,689 - INFO - Epoch 96, train_loss: 0.000097, val_loss: 0.013471, val_mae: 0.073121
2024-12-20 13:26:10,512 - INFO - Epoch 97, train_loss: 0.000091, val_loss: 0.013493, val_mae: 0.073173
2024-12-20 13:26:30,007 - INFO - Epoch 98, train_loss: 0.000087, val_loss: 0.013497, val_mae: 0.073195
2024-12-20 13:26:49,725 - INFO - Epoch 99, train_loss: 0.000084, val_loss: 0.013506, val_mae: 0.073233
2024-12-20 13:27:09,363 - INFO - Epoch 100, train_loss: 0.000082, val_loss: 0.013499, val_mae: 0.073201
2024-12-20 13:27:11,119 - INFO - Test MAE: 0.072987 with best model at Epoch 91
