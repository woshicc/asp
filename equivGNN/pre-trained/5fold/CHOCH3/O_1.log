2024-12-20 09:48:21,028 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: O
2024-12-20 09:48:22,704 - INFO - dataset size: 5739, batch size: 8
2024-12-20 09:48:22,704 - INFO - train/valid/test size: 4591/1148/0
2024-12-20 09:48:24,281 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 09:48:26,761 - INFO - initial lr: 0.000200000, meanAE: 1.5436062484446467
2024-12-20 09:48:49,223 - INFO - Epoch 1, train_loss: 2.588580, val_loss: 1.668047, val_mae: 0.995071
2024-12-20 09:49:11,516 - INFO - Epoch 2, train_loss: 1.554080, val_loss: 1.138800, val_mae: 0.763403
2024-12-20 09:49:33,715 - INFO - Epoch 3, train_loss: 0.999911, val_loss: 0.912885, val_mae: 0.677828
2024-12-20 09:49:55,546 - INFO - Epoch 4, train_loss: 0.734818, val_loss: 0.675316, val_mae: 0.558704
2024-12-20 09:50:17,759 - INFO - Epoch 5, train_loss: 0.444798, val_loss: 0.407538, val_mae: 0.439386
2024-12-20 09:50:40,122 - INFO - Epoch 6, train_loss: 0.286745, val_loss: 0.289145, val_mae: 0.375080
2024-12-20 09:51:02,281 - INFO - Epoch 7, train_loss: 0.197253, val_loss: 0.198417, val_mae: 0.322384
2024-12-20 09:51:24,340 - INFO - Epoch 8, train_loss: 0.146880, val_loss: 0.141934, val_mae: 0.281305
2024-12-20 09:51:46,941 - INFO - Epoch 9, train_loss: 0.117385, val_loss: 0.126575, val_mae: 0.267299
2024-12-20 09:52:09,283 - INFO - Epoch 10, train_loss: 0.101885, val_loss: 0.106176, val_mae: 0.249251
2024-12-20 09:52:31,866 - INFO - Epoch 11, train_loss: 0.090183, val_loss: 0.098870, val_mae: 0.241517
2024-12-20 09:52:54,153 - INFO - Epoch 12, train_loss: 0.083153, val_loss: 0.121221, val_mae: 0.262029
2024-12-20 09:53:16,729 - INFO - Epoch 13, train_loss: 0.082126, val_loss: 0.079747, val_mae: 0.211327
2024-12-20 09:53:38,865 - INFO - Epoch 14, train_loss: 0.068627, val_loss: 0.091826, val_mae: 0.235585
2024-12-20 09:54:01,599 - INFO - Epoch 15, train_loss: 0.070215, val_loss: 0.104914, val_mae: 0.243906
2024-12-20 09:54:24,939 - INFO - Epoch 16, train_loss: 0.064350, val_loss: 0.071256, val_mae: 0.202234
2024-12-20 09:54:47,858 - INFO - Epoch 17, train_loss: 0.062543, val_loss: 0.078723, val_mae: 0.216093
2024-12-20 09:55:10,075 - INFO - Epoch 18, train_loss: 0.068528, val_loss: 0.096017, val_mae: 0.233577
2024-12-20 09:55:32,659 - INFO - Epoch 19, train_loss: 0.051513, val_loss: 0.063491, val_mae: 0.189606
2024-12-20 09:55:54,681 - INFO - Epoch 20, train_loss: 0.058267, val_loss: 0.112934, val_mae: 0.243233
2024-12-20 09:56:16,813 - INFO - Epoch 21, train_loss: 0.055902, val_loss: 0.059406, val_mae: 0.183287
2024-12-20 09:56:38,983 - INFO - Epoch 22, train_loss: 0.044654, val_loss: 0.063813, val_mae: 0.193793
2024-12-20 09:57:01,000 - INFO - Epoch 23, train_loss: 0.055379, val_loss: 0.074989, val_mae: 0.210519
2024-12-20 09:57:22,727 - INFO - Epoch 24, train_loss: 0.052066, val_loss: 0.063324, val_mae: 0.191657
2024-12-20 09:57:44,627 - INFO - Epoch 25, train_loss: 0.042835, val_loss: 0.061078, val_mae: 0.193921
2024-12-20 09:58:06,613 - INFO - Epoch 26, train_loss: 0.045521, val_loss: 0.052759, val_mae: 0.171618
2024-12-20 09:58:28,787 - INFO - Epoch 27, train_loss: 0.042423, val_loss: 0.063598, val_mae: 0.192083
2024-12-20 09:58:50,882 - INFO - Epoch 28, train_loss: 0.038376, val_loss: 0.063855, val_mae: 0.196572
2024-12-20 09:59:12,879 - INFO - Epoch 29, train_loss: 0.037310, val_loss: 0.055112, val_mae: 0.173917
2024-12-20 09:59:35,069 - INFO - Epoch 30, train_loss: 0.039060, val_loss: 0.053494, val_mae: 0.174661
2024-12-20 09:59:57,337 - INFO - Epoch 31, train_loss: 0.031067, val_loss: 0.053066, val_mae: 0.175853
2024-12-20 10:00:19,777 - INFO - Epoch 32, train_loss: 0.030777, val_loss: 0.052789, val_mae: 0.175764
2024-12-20 10:00:42,210 - INFO - Epoch 33, train_loss: 0.029696, val_loss: 0.054978, val_mae: 0.176309
2024-12-20 10:01:04,775 - INFO - Epoch 34, train_loss: 0.030718, val_loss: 0.050720, val_mae: 0.167755
2024-12-20 10:01:26,906 - INFO - Epoch 35, train_loss: 0.028211, val_loss: 0.041873, val_mae: 0.150442
2024-12-20 10:01:49,524 - INFO - Epoch 36, train_loss: 0.023333, val_loss: 0.044668, val_mae: 0.155678
2024-12-20 10:02:12,322 - INFO - Epoch 37, train_loss: 0.021086, val_loss: 0.051445, val_mae: 0.176990
2024-12-20 10:02:35,149 - INFO - Epoch 38, train_loss: 0.025146, val_loss: 0.058559, val_mae: 0.176561
2024-12-20 10:02:57,724 - INFO - Epoch 39, train_loss: 0.023491, val_loss: 0.035225, val_mae: 0.130934
2024-12-20 10:03:19,473 - INFO - Epoch 40, train_loss: 0.020325, val_loss: 0.041153, val_mae: 0.145873
2024-12-20 10:03:41,847 - INFO - Epoch 41, train_loss: 0.018353, val_loss: 0.040871, val_mae: 0.149621
2024-12-20 10:04:03,763 - INFO - Epoch 42, train_loss: 0.019936, val_loss: 0.032505, val_mae: 0.124901
2024-12-20 10:04:25,775 - INFO - Epoch 43, train_loss: 0.017053, val_loss: 0.037815, val_mae: 0.136920
2024-12-20 10:04:47,678 - INFO - Epoch 44, train_loss: 0.017007, val_loss: 0.033454, val_mae: 0.124231
2024-12-20 10:05:09,751 - INFO - Epoch 45, train_loss: 0.015776, val_loss: 0.034953, val_mae: 0.131079
2024-12-20 10:05:31,610 - INFO - Epoch 46, train_loss: 0.015221, val_loss: 0.039142, val_mae: 0.141831
2024-12-20 10:05:53,379 - INFO - Epoch 47, train_loss: 0.014253, val_loss: 0.031335, val_mae: 0.124005
2024-12-20 10:06:16,598 - INFO - Epoch 48, train_loss: 0.013794, val_loss: 0.029299, val_mae: 0.120246
2024-12-20 10:06:38,560 - INFO - Epoch 49, train_loss: 0.011652, val_loss: 0.029636, val_mae: 0.124059
2024-12-20 10:07:00,677 - INFO - Epoch 50, train_loss: 0.011922, val_loss: 0.033467, val_mae: 0.129170
2024-12-20 10:07:22,429 - INFO - Epoch 51, train_loss: 0.014278, val_loss: 0.028220, val_mae: 0.115236
2024-12-20 10:07:44,604 - INFO - Epoch 52, train_loss: 0.012185, val_loss: 0.029191, val_mae: 0.120353
2024-12-20 10:08:07,074 - INFO - Epoch 53, train_loss: 0.010290, val_loss: 0.027029, val_mae: 0.114118
2024-12-20 10:08:29,622 - INFO - Epoch 54, train_loss: 0.008563, val_loss: 0.026655, val_mae: 0.112161
2024-12-20 10:08:52,127 - INFO - Epoch 55, train_loss: 0.007336, val_loss: 0.024819, val_mae: 0.104378
2024-12-20 10:09:14,756 - INFO - Epoch 56, train_loss: 0.009180, val_loss: 0.029681, val_mae: 0.118924
2024-12-20 10:09:36,601 - INFO - Epoch 57, train_loss: 0.006773, val_loss: 0.025383, val_mae: 0.105287
2024-12-20 10:09:59,432 - INFO - Epoch 58, train_loss: 0.006847, val_loss: 0.027330, val_mae: 0.112907
2024-12-20 10:10:22,823 - INFO - Epoch 59, train_loss: 0.007660, val_loss: 0.028725, val_mae: 0.112073
2024-12-20 10:10:45,735 - INFO - Epoch 60, train_loss: 0.006501, val_loss: 0.023662, val_mae: 0.103181
2024-12-20 10:11:08,506 - INFO - Epoch 61, train_loss: 0.004941, val_loss: 0.022975, val_mae: 0.101319
2024-12-20 10:11:30,567 - INFO - Epoch 62, train_loss: 0.004746, val_loss: 0.023517, val_mae: 0.101344
2024-12-20 10:11:52,860 - INFO - Epoch 63, train_loss: 0.005124, val_loss: 0.022386, val_mae: 0.098845
2024-12-20 10:12:14,975 - INFO - Epoch 64, train_loss: 0.005228, val_loss: 0.023520, val_mae: 0.103691
2024-12-20 10:12:37,322 - INFO - Epoch 65, train_loss: 0.003978, val_loss: 0.022678, val_mae: 0.098579
2024-12-20 10:12:59,325 - INFO - Epoch 66, train_loss: 0.003911, val_loss: 0.022969, val_mae: 0.100035
2024-12-20 10:13:21,332 - INFO - Epoch 67, train_loss: 0.003469, val_loss: 0.024356, val_mae: 0.102290
2024-12-20 10:13:43,608 - INFO - Epoch 68, train_loss: 0.003208, val_loss: 0.021691, val_mae: 0.095939
2024-12-20 10:14:05,826 - INFO - Epoch 69, train_loss: 0.002307, val_loss: 0.021093, val_mae: 0.093365
2024-12-20 10:14:28,356 - INFO - Epoch 70, train_loss: 0.002448, val_loss: 0.022076, val_mae: 0.096267
2024-12-20 10:14:50,849 - INFO - Epoch 71, train_loss: 0.002557, val_loss: 0.021551, val_mae: 0.094694
2024-12-20 10:15:13,554 - INFO - Epoch 72, train_loss: 0.002062, val_loss: 0.021333, val_mae: 0.093033
2024-12-20 10:15:36,972 - INFO - Epoch 73, train_loss: 0.001871, val_loss: 0.021240, val_mae: 0.091792
2024-12-20 10:16:00,448 - INFO - Epoch 74, train_loss: 0.001359, val_loss: 0.020947, val_mae: 0.091435
2024-12-20 10:16:23,390 - INFO - Epoch 75, train_loss: 0.001444, val_loss: 0.020807, val_mae: 0.091249
2024-12-20 10:16:46,300 - INFO - Epoch 76, train_loss: 0.001390, val_loss: 0.021231, val_mae: 0.092067
2024-12-20 10:17:09,105 - INFO - Epoch 77, train_loss: 0.001000, val_loss: 0.020706, val_mae: 0.089063
2024-12-20 10:17:31,870 - INFO - Epoch 78, train_loss: 0.001001, val_loss: 0.020583, val_mae: 0.089357
2024-12-20 10:17:54,352 - INFO - Epoch 79, train_loss: 0.000786, val_loss: 0.020660, val_mae: 0.088999
2024-12-20 10:18:18,239 - INFO - Epoch 80, train_loss: 0.000627, val_loss: 0.020391, val_mae: 0.088337
2024-12-20 10:18:40,956 - INFO - Epoch 81, train_loss: 0.000578, val_loss: 0.020414, val_mae: 0.088399
2024-12-20 10:19:03,959 - INFO - Epoch 82, train_loss: 0.000531, val_loss: 0.020570, val_mae: 0.088941
2024-12-20 10:19:26,912 - INFO - Epoch 83, train_loss: 0.000413, val_loss: 0.020028, val_mae: 0.087365
2024-12-20 10:19:49,270 - INFO - Epoch 84, train_loss: 0.000353, val_loss: 0.020264, val_mae: 0.088559
2024-12-20 10:20:11,857 - INFO - Epoch 85, train_loss: 0.000299, val_loss: 0.020297, val_mae: 0.087528
2024-12-20 10:20:34,464 - INFO - Epoch 86, train_loss: 0.000281, val_loss: 0.020383, val_mae: 0.088103
2024-12-20 10:20:57,293 - INFO - Epoch 87, train_loss: 0.000212, val_loss: 0.020140, val_mae: 0.087330
2024-12-20 10:21:19,852 - INFO - Epoch 88, train_loss: 0.000193, val_loss: 0.020091, val_mae: 0.086800
2024-12-20 10:21:41,771 - INFO - Epoch 89, train_loss: 0.000163, val_loss: 0.019950, val_mae: 0.086707
2024-12-20 10:22:04,428 - INFO - Epoch 90, train_loss: 0.000139, val_loss: 0.020036, val_mae: 0.086415
2024-12-20 10:22:26,680 - INFO - Epoch 91, train_loss: 0.000122, val_loss: 0.020132, val_mae: 0.086763
2024-12-20 10:22:48,933 - INFO - Epoch 92, train_loss: 0.000108, val_loss: 0.020003, val_mae: 0.086537
2024-12-20 10:23:11,376 - INFO - Epoch 93, train_loss: 0.000093, val_loss: 0.020022, val_mae: 0.086369
2024-12-20 10:23:33,542 - INFO - Epoch 94, train_loss: 0.000085, val_loss: 0.020115, val_mae: 0.086545
2024-12-20 10:23:56,646 - INFO - Epoch 95, train_loss: 0.000077, val_loss: 0.020089, val_mae: 0.086565
2024-12-20 10:24:18,909 - INFO - Epoch 96, train_loss: 0.000070, val_loss: 0.020076, val_mae: 0.086467
2024-12-20 10:24:41,874 - INFO - Epoch 97, train_loss: 0.000065, val_loss: 0.020074, val_mae: 0.086406
2024-12-20 10:25:04,739 - INFO - Epoch 98, train_loss: 0.000062, val_loss: 0.020070, val_mae: 0.086401
2024-12-20 10:25:27,622 - INFO - Epoch 99, train_loss: 0.000059, val_loss: 0.020068, val_mae: 0.086378
2024-12-20 10:25:49,917 - INFO - Epoch 100, train_loss: 0.000058, val_loss: 0.020065, val_mae: 0.086370
2024-12-20 10:25:51,845 - INFO - Test MAE: 0.086369 with best model at Epoch 93
