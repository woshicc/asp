2024-12-20 15:44:43,630 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: CH3
2024-12-20 15:44:45,241 - INFO - dataset size: 5334, batch size: 8
2024-12-20 15:44:45,241 - INFO - train/valid/test size: 4267/1067/0
2024-12-20 15:44:46,909 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 15:44:49,288 - INFO - initial lr: 0.000200000, meanAE: 0.7473151217648132
2024-12-20 15:45:10,883 - INFO - Epoch 1, train_loss: 0.253389, val_loss: 0.104332, val_mae: 0.248458
2024-12-20 15:45:32,618 - INFO - Epoch 2, train_loss: 0.080008, val_loss: 0.077450, val_mae: 0.208373
2024-12-20 15:45:53,720 - INFO - Epoch 3, train_loss: 0.061129, val_loss: 0.063584, val_mae: 0.187469
2024-12-20 15:46:16,100 - INFO - Epoch 4, train_loss: 0.052739, val_loss: 0.052775, val_mae: 0.164366
2024-12-20 15:46:38,360 - INFO - Epoch 5, train_loss: 0.048306, val_loss: 0.050444, val_mae: 0.158749
2024-12-20 15:47:00,130 - INFO - Epoch 6, train_loss: 0.041644, val_loss: 0.047203, val_mae: 0.154754
2024-12-20 15:47:20,942 - INFO - Epoch 7, train_loss: 0.040422, val_loss: 0.042442, val_mae: 0.145568
2024-12-20 15:47:42,500 - INFO - Epoch 8, train_loss: 0.036448, val_loss: 0.042563, val_mae: 0.146982
2024-12-20 15:48:03,857 - INFO - Epoch 9, train_loss: 0.033617, val_loss: 0.062069, val_mae: 0.194413
2024-12-20 15:48:24,985 - INFO - Epoch 10, train_loss: 0.032240, val_loss: 0.042969, val_mae: 0.148999
2024-12-20 15:48:46,098 - INFO - Epoch 11, train_loss: 0.029938, val_loss: 0.035920, val_mae: 0.129542
2024-12-20 15:49:07,939 - INFO - Epoch 12, train_loss: 0.027051, val_loss: 0.043688, val_mae: 0.147912
2024-12-20 15:49:30,252 - INFO - Epoch 13, train_loss: 0.025184, val_loss: 0.032556, val_mae: 0.123114
2024-12-20 15:49:51,924 - INFO - Epoch 14, train_loss: 0.023892, val_loss: 0.030963, val_mae: 0.126811
2024-12-20 15:50:13,554 - INFO - Epoch 15, train_loss: 0.022204, val_loss: 0.029813, val_mae: 0.120775
2024-12-20 15:50:35,054 - INFO - Epoch 16, train_loss: 0.019826, val_loss: 0.029059, val_mae: 0.119030
2024-12-20 15:50:56,881 - INFO - Epoch 17, train_loss: 0.019317, val_loss: 0.033171, val_mae: 0.121685
2024-12-20 15:51:18,598 - INFO - Epoch 18, train_loss: 0.017630, val_loss: 0.029219, val_mae: 0.113359
2024-12-20 15:51:40,473 - INFO - Epoch 19, train_loss: 0.016578, val_loss: 0.028233, val_mae: 0.117922
2024-12-20 15:52:02,257 - INFO - Epoch 20, train_loss: 0.014020, val_loss: 0.029588, val_mae: 0.116429
2024-12-20 15:52:24,446 - INFO - Epoch 21, train_loss: 0.014102, val_loss: 0.031297, val_mae: 0.116586
2024-12-20 15:52:45,818 - INFO - Epoch 22, train_loss: 0.016970, val_loss: 0.024111, val_mae: 0.107026
2024-12-20 15:53:07,921 - INFO - Epoch 23, train_loss: 0.012992, val_loss: 0.022296, val_mae: 0.106795
2024-12-20 15:53:29,167 - INFO - Epoch 24, train_loss: 0.010756, val_loss: 0.026090, val_mae: 0.102045
2024-12-20 15:53:50,318 - INFO - Epoch 25, train_loss: 0.011659, val_loss: 0.027242, val_mae: 0.111735
2024-12-20 15:54:12,372 - INFO - Epoch 26, train_loss: 0.011715, val_loss: 0.023417, val_mae: 0.103745
2024-12-20 15:54:34,692 - INFO - Epoch 27, train_loss: 0.010094, val_loss: 0.022136, val_mae: 0.097700
2024-12-20 15:54:56,625 - INFO - Epoch 28, train_loss: 0.011418, val_loss: 0.025204, val_mae: 0.109635
2024-12-20 15:55:17,535 - INFO - Epoch 29, train_loss: 0.010340, val_loss: 0.021646, val_mae: 0.098219
2024-12-20 15:55:38,717 - INFO - Epoch 30, train_loss: 0.010352, val_loss: 0.026649, val_mae: 0.114568
2024-12-20 15:56:00,405 - INFO - Epoch 31, train_loss: 0.010193, val_loss: 0.018136, val_mae: 0.090215
2024-12-20 15:56:21,410 - INFO - Epoch 32, train_loss: 0.007380, val_loss: 0.018638, val_mae: 0.089302
2024-12-20 15:56:42,635 - INFO - Epoch 33, train_loss: 0.007247, val_loss: 0.019448, val_mae: 0.095982
2024-12-20 15:57:04,121 - INFO - Epoch 34, train_loss: 0.006829, val_loss: 0.022382, val_mae: 0.090545
2024-12-20 15:57:26,695 - INFO - Epoch 35, train_loss: 0.006698, val_loss: 0.016945, val_mae: 0.084100
2024-12-20 15:57:48,025 - INFO - Epoch 36, train_loss: 0.004930, val_loss: 0.019951, val_mae: 0.090883
2024-12-20 15:58:09,952 - INFO - Epoch 37, train_loss: 0.006179, val_loss: 0.019575, val_mae: 0.088711
2024-12-20 15:58:32,003 - INFO - Epoch 38, train_loss: 0.005245, val_loss: 0.017995, val_mae: 0.083040
2024-12-20 15:58:54,012 - INFO - Epoch 39, train_loss: 0.004741, val_loss: 0.017415, val_mae: 0.087376
2024-12-20 15:59:15,499 - INFO - Epoch 40, train_loss: 0.004915, val_loss: 0.017447, val_mae: 0.082303
2024-12-20 15:59:37,709 - INFO - Epoch 41, train_loss: 0.004594, val_loss: 0.018554, val_mae: 0.086429
2024-12-20 16:00:00,803 - INFO - Epoch 42, train_loss: 0.005012, val_loss: 0.020307, val_mae: 0.087767
2024-12-20 16:00:23,729 - INFO - Epoch 43, train_loss: 0.005564, val_loss: 0.018434, val_mae: 0.082207
2024-12-20 16:00:47,566 - INFO - Epoch 44, train_loss: 0.003621, val_loss: 0.016302, val_mae: 0.077945
2024-12-20 16:01:10,385 - INFO - Epoch 45, train_loss: 0.002919, val_loss: 0.015721, val_mae: 0.078340
2024-12-20 16:01:33,524 - INFO - Epoch 46, train_loss: 0.003330, val_loss: 0.019752, val_mae: 0.090462
2024-12-20 16:01:55,618 - INFO - Epoch 47, train_loss: 0.003761, val_loss: 0.017012, val_mae: 0.078054
2024-12-20 16:02:16,900 - INFO - Epoch 48, train_loss: 0.003526, val_loss: 0.015330, val_mae: 0.074637
2024-12-20 16:02:38,189 - INFO - Epoch 49, train_loss: 0.002881, val_loss: 0.015234, val_mae: 0.076578
2024-12-20 16:02:59,364 - INFO - Epoch 50, train_loss: 0.002253, val_loss: 0.016570, val_mae: 0.075338
2024-12-20 16:03:20,386 - INFO - Epoch 51, train_loss: 0.003044, val_loss: 0.017082, val_mae: 0.083465
2024-12-20 16:03:41,895 - INFO - Epoch 52, train_loss: 0.002861, val_loss: 0.014196, val_mae: 0.069782
2024-12-20 16:04:03,470 - INFO - Epoch 53, train_loss: 0.002011, val_loss: 0.015872, val_mae: 0.078831
2024-12-20 16:04:24,992 - INFO - Epoch 54, train_loss: 0.001733, val_loss: 0.015018, val_mae: 0.071449
2024-12-20 16:04:46,355 - INFO - Epoch 55, train_loss: 0.001776, val_loss: 0.015083, val_mae: 0.069919
2024-12-20 16:05:07,916 - INFO - Epoch 56, train_loss: 0.002031, val_loss: 0.016134, val_mae: 0.075664
2024-12-20 16:05:29,876 - INFO - Epoch 57, train_loss: 0.001677, val_loss: 0.014019, val_mae: 0.069029
2024-12-20 16:05:51,120 - INFO - Epoch 58, train_loss: 0.001412, val_loss: 0.015494, val_mae: 0.070901
2024-12-20 16:06:13,176 - INFO - Epoch 59, train_loss: 0.001488, val_loss: 0.014139, val_mae: 0.069079
2024-12-20 16:06:35,556 - INFO - Epoch 60, train_loss: 0.001294, val_loss: 0.015275, val_mae: 0.070523
2024-12-20 16:06:57,984 - INFO - Epoch 61, train_loss: 0.001330, val_loss: 0.014945, val_mae: 0.070197
2024-12-20 16:07:20,141 - INFO - Epoch 62, train_loss: 0.001219, val_loss: 0.014108, val_mae: 0.069299
2024-12-20 16:07:43,839 - INFO - Epoch 63, train_loss: 0.001088, val_loss: 0.014871, val_mae: 0.070293
2024-12-20 16:08:07,696 - INFO - Epoch 64, train_loss: 0.001011, val_loss: 0.013837, val_mae: 0.068528
2024-12-20 16:08:31,284 - INFO - Epoch 65, train_loss: 0.000774, val_loss: 0.014067, val_mae: 0.067232
2024-12-20 16:08:54,756 - INFO - Epoch 66, train_loss: 0.000738, val_loss: 0.014054, val_mae: 0.066992
2024-12-20 16:09:18,471 - INFO - Epoch 67, train_loss: 0.000729, val_loss: 0.014617, val_mae: 0.068365
2024-12-20 16:09:41,515 - INFO - Epoch 68, train_loss: 0.000561, val_loss: 0.014071, val_mae: 0.066038
2024-12-20 16:10:04,075 - INFO - Epoch 69, train_loss: 0.000498, val_loss: 0.013814, val_mae: 0.067502
2024-12-20 16:10:26,727 - INFO - Epoch 70, train_loss: 0.000509, val_loss: 0.014326, val_mae: 0.066611
2024-12-20 16:10:50,075 - INFO - Epoch 71, train_loss: 0.000745, val_loss: 0.013885, val_mae: 0.066206
2024-12-20 16:11:11,797 - INFO - Epoch 72, train_loss: 0.000460, val_loss: 0.013994, val_mae: 0.065136
2024-12-20 16:11:33,365 - INFO - Epoch 73, train_loss: 0.000276, val_loss: 0.013549, val_mae: 0.064569
2024-12-20 16:11:55,717 - INFO - Epoch 74, train_loss: 0.000245, val_loss: 0.013328, val_mae: 0.064637
2024-12-20 16:12:17,285 - INFO - Epoch 75, train_loss: 0.000226, val_loss: 0.013924, val_mae: 0.065339
2024-12-20 16:12:38,805 - INFO - Epoch 76, train_loss: 0.000225, val_loss: 0.013713, val_mae: 0.064165
2024-12-20 16:13:00,197 - INFO - Epoch 77, train_loss: 0.000210, val_loss: 0.013671, val_mae: 0.064330
2024-12-20 16:13:22,130 - INFO - Epoch 78, train_loss: 0.000167, val_loss: 0.013587, val_mae: 0.064036
2024-12-20 16:13:43,741 - INFO - Epoch 79, train_loss: 0.000145, val_loss: 0.013589, val_mae: 0.064026
2024-12-20 16:14:05,647 - INFO - Epoch 80, train_loss: 0.000119, val_loss: 0.013639, val_mae: 0.063866
2024-12-20 16:14:27,992 - INFO - Epoch 81, train_loss: 0.000096, val_loss: 0.013484, val_mae: 0.064228
2024-12-20 16:14:50,440 - INFO - Epoch 82, train_loss: 0.000086, val_loss: 0.013692, val_mae: 0.064058
2024-12-20 16:15:12,714 - INFO - Epoch 83, train_loss: 0.000069, val_loss: 0.013458, val_mae: 0.063678
2024-12-20 16:15:35,675 - INFO - Epoch 84, train_loss: 0.000063, val_loss: 0.013700, val_mae: 0.064041
2024-12-20 16:15:59,277 - INFO - Epoch 85, train_loss: 0.000050, val_loss: 0.013505, val_mae: 0.063592
2024-12-20 16:16:23,613 - INFO - Epoch 86, train_loss: 0.000035, val_loss: 0.013560, val_mae: 0.063805
2024-12-20 16:16:47,823 - INFO - Epoch 87, train_loss: 0.000025, val_loss: 0.013509, val_mae: 0.063634
2024-12-20 16:17:12,070 - INFO - Epoch 88, train_loss: 0.000023, val_loss: 0.013555, val_mae: 0.063678
2024-12-20 16:17:35,986 - INFO - Epoch 89, train_loss: 0.000017, val_loss: 0.013491, val_mae: 0.063636
2024-12-20 16:17:59,040 - INFO - Epoch 90, train_loss: 0.000015, val_loss: 0.013559, val_mae: 0.063600
2024-12-20 16:18:20,887 - INFO - Epoch 91, train_loss: 0.000012, val_loss: 0.013553, val_mae: 0.063676
2024-12-20 16:18:42,965 - INFO - Epoch 92, train_loss: 0.000009, val_loss: 0.013533, val_mae: 0.063611
2024-12-20 16:19:04,273 - INFO - Epoch 93, train_loss: 0.000008, val_loss: 0.013526, val_mae: 0.063585
2024-12-20 16:19:25,361 - INFO - Epoch 94, train_loss: 0.000007, val_loss: 0.013527, val_mae: 0.063555
2024-12-20 16:19:47,044 - INFO - Epoch 95, train_loss: 0.000006, val_loss: 0.013514, val_mae: 0.063565
2024-12-20 16:20:08,836 - INFO - Epoch 96, train_loss: 0.000005, val_loss: 0.013525, val_mae: 0.063585
2024-12-20 16:20:30,021 - INFO - Epoch 97, train_loss: 0.000005, val_loss: 0.013522, val_mae: 0.063566
2024-12-20 16:20:51,457 - INFO - Epoch 98, train_loss: 0.000004, val_loss: 0.013524, val_mae: 0.063570
2024-12-20 16:21:13,847 - INFO - Epoch 99, train_loss: 0.000004, val_loss: 0.013522, val_mae: 0.063561
2024-12-20 16:21:35,354 - INFO - Epoch 100, train_loss: 0.000004, val_loss: 0.013522, val_mae: 0.063563
2024-12-20 16:21:37,202 - INFO - Test MAE: 0.063555 with best model at Epoch 94
