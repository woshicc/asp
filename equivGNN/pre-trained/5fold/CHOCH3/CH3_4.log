2024-12-20 17:34:36,355 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: CH3
2024-12-20 17:34:37,869 - INFO - dataset size: 5334, batch size: 8
2024-12-20 17:34:37,869 - INFO - train/valid/test size: 4268/1066/0
2024-12-20 17:34:39,577 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 17:34:41,951 - INFO - initial lr: 0.000200000, meanAE: 0.735694754668548
2024-12-20 17:35:03,725 - INFO - Epoch 1, train_loss: 0.254888, val_loss: 0.094089, val_mae: 0.243301
2024-12-20 17:35:26,231 - INFO - Epoch 2, train_loss: 0.080108, val_loss: 0.063574, val_mae: 0.193974
2024-12-20 17:35:48,162 - INFO - Epoch 3, train_loss: 0.061865, val_loss: 0.063600, val_mae: 0.197780
2024-12-20 17:36:10,692 - INFO - Epoch 4, train_loss: 0.052040, val_loss: 0.050192, val_mae: 0.171564
2024-12-20 17:36:33,137 - INFO - Epoch 5, train_loss: 0.048315, val_loss: 0.043651, val_mae: 0.159890
2024-12-20 17:36:55,672 - INFO - Epoch 6, train_loss: 0.044427, val_loss: 0.038403, val_mae: 0.147823
2024-12-20 17:37:18,083 - INFO - Epoch 7, train_loss: 0.040927, val_loss: 0.036284, val_mae: 0.145562
2024-12-20 17:37:40,193 - INFO - Epoch 8, train_loss: 0.038185, val_loss: 0.034560, val_mae: 0.141740
2024-12-20 17:38:01,703 - INFO - Epoch 9, train_loss: 0.035129, val_loss: 0.031620, val_mae: 0.131252
2024-12-20 17:38:23,733 - INFO - Epoch 10, train_loss: 0.033619, val_loss: 0.066772, val_mae: 0.213772
2024-12-20 17:38:45,396 - INFO - Epoch 11, train_loss: 0.034681, val_loss: 0.032353, val_mae: 0.132116
2024-12-20 17:39:07,013 - INFO - Epoch 12, train_loss: 0.031522, val_loss: 0.036580, val_mae: 0.149968
2024-12-20 17:39:28,553 - INFO - Epoch 13, train_loss: 0.028483, val_loss: 0.030658, val_mae: 0.132687
2024-12-20 17:39:50,098 - INFO - Epoch 14, train_loss: 0.026049, val_loss: 0.028466, val_mae: 0.127922
2024-12-20 17:40:11,738 - INFO - Epoch 15, train_loss: 0.022908, val_loss: 0.026823, val_mae: 0.121760
2024-12-20 17:40:33,051 - INFO - Epoch 16, train_loss: 0.020206, val_loss: 0.024958, val_mae: 0.117739
2024-12-20 17:40:54,561 - INFO - Epoch 17, train_loss: 0.018532, val_loss: 0.025782, val_mae: 0.120006
2024-12-20 17:41:16,080 - INFO - Epoch 18, train_loss: 0.021388, val_loss: 0.024441, val_mae: 0.116278
2024-12-20 17:41:37,706 - INFO - Epoch 19, train_loss: 0.020690, val_loss: 0.022606, val_mae: 0.105184
2024-12-20 17:41:59,153 - INFO - Epoch 20, train_loss: 0.019710, val_loss: 0.023783, val_mae: 0.115206
2024-12-20 17:42:20,761 - INFO - Epoch 21, train_loss: 0.017070, val_loss: 0.017683, val_mae: 0.096041
2024-12-20 17:42:42,699 - INFO - Epoch 22, train_loss: 0.016544, val_loss: 0.018882, val_mae: 0.098155
2024-12-20 17:43:04,194 - INFO - Epoch 23, train_loss: 0.016050, val_loss: 0.019349, val_mae: 0.099323
2024-12-20 17:43:25,720 - INFO - Epoch 24, train_loss: 0.012978, val_loss: 0.017474, val_mae: 0.095836
2024-12-20 17:43:47,337 - INFO - Epoch 25, train_loss: 0.012854, val_loss: 0.017582, val_mae: 0.093267
2024-12-20 17:44:09,502 - INFO - Epoch 26, train_loss: 0.013575, val_loss: 0.025722, val_mae: 0.111400
2024-12-20 17:44:31,763 - INFO - Epoch 27, train_loss: 0.011891, val_loss: 0.017450, val_mae: 0.089800
2024-12-20 17:44:54,006 - INFO - Epoch 28, train_loss: 0.011188, val_loss: 0.020324, val_mae: 0.093317
2024-12-20 17:45:16,119 - INFO - Epoch 29, train_loss: 0.015685, val_loss: 0.017253, val_mae: 0.083933
2024-12-20 17:45:37,865 - INFO - Epoch 30, train_loss: 0.018903, val_loss: 0.018482, val_mae: 0.098559
2024-12-20 17:45:59,144 - INFO - Epoch 31, train_loss: 0.013124, val_loss: 0.016298, val_mae: 0.086206
2024-12-20 17:46:21,080 - INFO - Epoch 32, train_loss: 0.009879, val_loss: 0.015562, val_mae: 0.089759
2024-12-20 17:46:43,281 - INFO - Epoch 33, train_loss: 0.008064, val_loss: 0.015243, val_mae: 0.084274
2024-12-20 17:47:04,884 - INFO - Epoch 34, train_loss: 0.006442, val_loss: 0.016075, val_mae: 0.086878
2024-12-20 17:47:26,003 - INFO - Epoch 35, train_loss: 0.006065, val_loss: 0.014467, val_mae: 0.078601
2024-12-20 17:47:47,746 - INFO - Epoch 36, train_loss: 0.005499, val_loss: 0.012521, val_mae: 0.076279
2024-12-20 17:48:09,149 - INFO - Epoch 37, train_loss: 0.005148, val_loss: 0.013310, val_mae: 0.078283
2024-12-20 17:48:30,265 - INFO - Epoch 38, train_loss: 0.005726, val_loss: 0.013528, val_mae: 0.080514
2024-12-20 17:48:51,554 - INFO - Epoch 39, train_loss: 0.007200, val_loss: 0.032951, val_mae: 0.106829
2024-12-20 17:49:13,783 - INFO - Epoch 40, train_loss: 0.006608, val_loss: 0.017234, val_mae: 0.079787
2024-12-20 17:49:35,639 - INFO - Epoch 41, train_loss: 0.004821, val_loss: 0.025221, val_mae: 0.107465
2024-12-20 17:49:57,491 - INFO - Epoch 42, train_loss: 0.007221, val_loss: 0.017053, val_mae: 0.084025
2024-12-20 17:50:19,047 - INFO - Epoch 43, train_loss: 0.004991, val_loss: 0.017872, val_mae: 0.080552
2024-12-20 17:50:40,666 - INFO - Epoch 44, train_loss: 0.005314, val_loss: 0.021412, val_mae: 0.089193
2024-12-20 17:51:02,446 - INFO - Epoch 45, train_loss: 0.004454, val_loss: 0.014467, val_mae: 0.074177
2024-12-20 17:51:23,945 - INFO - Epoch 46, train_loss: 0.003178, val_loss: 0.012572, val_mae: 0.072502
2024-12-20 17:51:45,991 - INFO - Epoch 47, train_loss: 0.003310, val_loss: 0.017090, val_mae: 0.087981
2024-12-20 17:52:08,345 - INFO - Epoch 48, train_loss: 0.003845, val_loss: 0.014596, val_mae: 0.071815
2024-12-20 17:52:30,309 - INFO - Epoch 49, train_loss: 0.002541, val_loss: 0.013209, val_mae: 0.070997
2024-12-20 17:52:52,876 - INFO - Epoch 50, train_loss: 0.003343, val_loss: 0.015360, val_mae: 0.074729
2024-12-20 17:53:14,977 - INFO - Epoch 51, train_loss: 0.002454, val_loss: 0.013013, val_mae: 0.071426
2024-12-20 17:53:36,716 - INFO - Epoch 52, train_loss: 0.002751, val_loss: 0.014434, val_mae: 0.076382
2024-12-20 17:53:57,660 - INFO - Epoch 53, train_loss: 0.003590, val_loss: 0.014367, val_mae: 0.074626
2024-12-20 17:54:19,056 - INFO - Epoch 54, train_loss: 0.002996, val_loss: 0.013730, val_mae: 0.069922
2024-12-20 17:54:39,999 - INFO - Epoch 55, train_loss: 0.002212, val_loss: 0.014722, val_mae: 0.068974
2024-12-20 17:55:00,893 - INFO - Epoch 56, train_loss: 0.002087, val_loss: 0.013950, val_mae: 0.069525
2024-12-20 17:55:21,710 - INFO - Epoch 57, train_loss: 0.002008, val_loss: 0.013585, val_mae: 0.068414
2024-12-20 17:55:42,856 - INFO - Epoch 58, train_loss: 0.001821, val_loss: 0.014726, val_mae: 0.070745
2024-12-20 17:56:04,035 - INFO - Epoch 59, train_loss: 0.001972, val_loss: 0.014421, val_mae: 0.072774
2024-12-20 17:56:25,042 - INFO - Epoch 60, train_loss: 0.001404, val_loss: 0.012474, val_mae: 0.064473
2024-12-20 17:56:46,122 - INFO - Epoch 61, train_loss: 0.001032, val_loss: 0.011961, val_mae: 0.065814
2024-12-20 17:57:08,131 - INFO - Epoch 62, train_loss: 0.001056, val_loss: 0.011769, val_mae: 0.065052
2024-12-20 17:57:30,466 - INFO - Epoch 63, train_loss: 0.001189, val_loss: 0.011233, val_mae: 0.065182
2024-12-20 17:57:52,002 - INFO - Epoch 64, train_loss: 0.001270, val_loss: 0.012384, val_mae: 0.065837
2024-12-20 17:58:13,767 - INFO - Epoch 65, train_loss: 0.001172, val_loss: 0.011590, val_mae: 0.064672
2024-12-20 17:58:35,592 - INFO - Epoch 66, train_loss: 0.000779, val_loss: 0.011731, val_mae: 0.063273
2024-12-20 17:58:57,324 - INFO - Epoch 67, train_loss: 0.000639, val_loss: 0.011751, val_mae: 0.063386
2024-12-20 17:59:18,769 - INFO - Epoch 68, train_loss: 0.000731, val_loss: 0.012236, val_mae: 0.063977
2024-12-20 17:59:40,656 - INFO - Epoch 69, train_loss: 0.000746, val_loss: 0.013257, val_mae: 0.063734
2024-12-20 18:00:02,823 - INFO - Epoch 70, train_loss: 0.000670, val_loss: 0.011983, val_mae: 0.062418
2024-12-20 18:00:25,145 - INFO - Epoch 71, train_loss: 0.000563, val_loss: 0.011361, val_mae: 0.061774
2024-12-20 18:00:47,350 - INFO - Epoch 72, train_loss: 0.000456, val_loss: 0.011892, val_mae: 0.062700
2024-12-20 18:01:09,848 - INFO - Epoch 73, train_loss: 0.000393, val_loss: 0.011423, val_mae: 0.062609
2024-12-20 18:01:31,569 - INFO - Epoch 74, train_loss: 0.000359, val_loss: 0.011324, val_mae: 0.062307
2024-12-20 18:01:53,244 - INFO - Epoch 75, train_loss: 0.000406, val_loss: 0.011633, val_mae: 0.061980
2024-12-20 18:02:15,188 - INFO - Epoch 76, train_loss: 0.000236, val_loss: 0.011840, val_mae: 0.064452
2024-12-20 18:02:36,696 - INFO - Epoch 77, train_loss: 0.000275, val_loss: 0.011705, val_mae: 0.062244
2024-12-20 18:02:58,203 - INFO - Epoch 78, train_loss: 0.000203, val_loss: 0.011710, val_mae: 0.061262
2024-12-20 18:03:19,121 - INFO - Epoch 79, train_loss: 0.000151, val_loss: 0.011488, val_mae: 0.061351
2024-12-20 18:03:40,916 - INFO - Epoch 80, train_loss: 0.000124, val_loss: 0.011534, val_mae: 0.061336
2024-12-20 18:04:02,100 - INFO - Epoch 81, train_loss: 0.000106, val_loss: 0.011643, val_mae: 0.061722
2024-12-20 18:04:23,796 - INFO - Epoch 82, train_loss: 0.000086, val_loss: 0.011647, val_mae: 0.061426
2024-12-20 18:04:45,649 - INFO - Epoch 83, train_loss: 0.000070, val_loss: 0.011714, val_mae: 0.061228
2024-12-20 18:05:07,282 - INFO - Epoch 84, train_loss: 0.000071, val_loss: 0.011649, val_mae: 0.061032
2024-12-20 18:05:28,700 - INFO - Epoch 85, train_loss: 0.000067, val_loss: 0.011657, val_mae: 0.061213
2024-12-20 18:05:50,515 - INFO - Epoch 86, train_loss: 0.000040, val_loss: 0.011532, val_mae: 0.060864
2024-12-20 18:06:12,129 - INFO - Epoch 87, train_loss: 0.000029, val_loss: 0.011583, val_mae: 0.060958
2024-12-20 18:06:33,719 - INFO - Epoch 88, train_loss: 0.000023, val_loss: 0.011590, val_mae: 0.060863
2024-12-20 18:06:55,343 - INFO - Epoch 89, train_loss: 0.000019, val_loss: 0.011582, val_mae: 0.060920
2024-12-20 18:07:17,201 - INFO - Epoch 90, train_loss: 0.000017, val_loss: 0.011561, val_mae: 0.060725
2024-12-20 18:07:38,983 - INFO - Epoch 91, train_loss: 0.000013, val_loss: 0.011517, val_mae: 0.060818
2024-12-20 18:08:01,454 - INFO - Epoch 92, train_loss: 0.000011, val_loss: 0.011591, val_mae: 0.060761
2024-12-20 18:08:23,383 - INFO - Epoch 93, train_loss: 0.000009, val_loss: 0.011564, val_mae: 0.060739
2024-12-20 18:08:46,045 - INFO - Epoch 94, train_loss: 0.000008, val_loss: 0.011569, val_mae: 0.060794
2024-12-20 18:09:08,555 - INFO - Epoch 95, train_loss: 0.000007, val_loss: 0.011575, val_mae: 0.060806
2024-12-20 18:09:30,964 - INFO - Epoch 96, train_loss: 0.000006, val_loss: 0.011568, val_mae: 0.060738
2024-12-20 18:09:52,255 - INFO - Epoch 97, train_loss: 0.000005, val_loss: 0.011567, val_mae: 0.060764
2024-12-20 18:10:14,135 - INFO - Epoch 98, train_loss: 0.000005, val_loss: 0.011570, val_mae: 0.060771
2024-12-20 18:10:35,568 - INFO - Epoch 99, train_loss: 0.000005, val_loss: 0.011569, val_mae: 0.060769
2024-12-20 18:10:57,211 - INFO - Epoch 100, train_loss: 0.000004, val_loss: 0.011569, val_mae: 0.060770
2024-12-20 18:10:58,978 - INFO - Test MAE: 0.060725 with best model at Epoch 90
