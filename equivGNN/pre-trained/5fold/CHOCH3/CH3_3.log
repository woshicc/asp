2024-12-20 16:58:02,692 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: CH3
2024-12-20 16:58:04,233 - INFO - dataset size: 5334, batch size: 8
2024-12-20 16:58:04,233 - INFO - train/valid/test size: 4267/1067/0
2024-12-20 16:58:05,960 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 16:58:08,300 - INFO - initial lr: 0.000200000, meanAE: 0.7521536540510021
2024-12-20 16:58:30,303 - INFO - Epoch 1, train_loss: 0.247804, val_loss: 0.094916, val_mae: 0.238072
2024-12-20 16:58:52,293 - INFO - Epoch 2, train_loss: 0.078804, val_loss: 0.064142, val_mae: 0.187726
2024-12-20 16:59:14,142 - INFO - Epoch 3, train_loss: 0.061482, val_loss: 0.066031, val_mae: 0.194458
2024-12-20 16:59:35,941 - INFO - Epoch 4, train_loss: 0.053650, val_loss: 0.048995, val_mae: 0.164033
2024-12-20 16:59:57,560 - INFO - Epoch 5, train_loss: 0.048161, val_loss: 0.045079, val_mae: 0.156124
2024-12-20 17:00:19,042 - INFO - Epoch 6, train_loss: 0.042480, val_loss: 0.040734, val_mae: 0.147450
2024-12-20 17:00:40,354 - INFO - Epoch 7, train_loss: 0.038819, val_loss: 0.045005, val_mae: 0.158037
2024-12-20 17:01:01,767 - INFO - Epoch 8, train_loss: 0.036963, val_loss: 0.045836, val_mae: 0.159691
2024-12-20 17:01:23,323 - INFO - Epoch 9, train_loss: 0.036221, val_loss: 0.035776, val_mae: 0.136545
2024-12-20 17:01:44,330 - INFO - Epoch 10, train_loss: 0.033022, val_loss: 0.036964, val_mae: 0.138450
2024-12-20 17:02:06,008 - INFO - Epoch 11, train_loss: 0.030517, val_loss: 0.036529, val_mae: 0.136048
2024-12-20 17:02:28,080 - INFO - Epoch 12, train_loss: 0.027679, val_loss: 0.040489, val_mae: 0.146750
2024-12-20 17:02:50,258 - INFO - Epoch 13, train_loss: 0.026902, val_loss: 0.031081, val_mae: 0.122769
2024-12-20 17:03:12,286 - INFO - Epoch 14, train_loss: 0.023874, val_loss: 0.029379, val_mae: 0.120771
2024-12-20 17:03:34,806 - INFO - Epoch 15, train_loss: 0.021349, val_loss: 0.028244, val_mae: 0.114621
2024-12-20 17:03:58,452 - INFO - Epoch 16, train_loss: 0.019508, val_loss: 0.041007, val_mae: 0.150513
2024-12-20 17:04:22,346 - INFO - Epoch 17, train_loss: 0.019107, val_loss: 0.049941, val_mae: 0.172162
2024-12-20 17:04:46,458 - INFO - Epoch 18, train_loss: 0.019055, val_loss: 0.024749, val_mae: 0.107652
2024-12-20 17:05:10,716 - INFO - Epoch 19, train_loss: 0.014826, val_loss: 0.021432, val_mae: 0.103236
2024-12-20 17:05:34,443 - INFO - Epoch 20, train_loss: 0.013280, val_loss: 0.032157, val_mae: 0.134015
2024-12-20 17:05:57,223 - INFO - Epoch 21, train_loss: 0.015211, val_loss: 0.026520, val_mae: 0.111689
2024-12-20 17:06:18,818 - INFO - Epoch 22, train_loss: 0.015417, val_loss: 0.024526, val_mae: 0.104264
2024-12-20 17:06:40,548 - INFO - Epoch 23, train_loss: 0.013686, val_loss: 0.026899, val_mae: 0.111917
2024-12-20 17:07:02,189 - INFO - Epoch 24, train_loss: 0.015998, val_loss: 0.022098, val_mae: 0.101007
2024-12-20 17:07:23,830 - INFO - Epoch 25, train_loss: 0.012162, val_loss: 0.021646, val_mae: 0.097522
2024-12-20 17:07:45,292 - INFO - Epoch 26, train_loss: 0.011203, val_loss: 0.023761, val_mae: 0.111975
2024-12-20 17:08:06,568 - INFO - Epoch 27, train_loss: 0.014213, val_loss: 0.022660, val_mae: 0.094757
2024-12-20 17:08:27,870 - INFO - Epoch 28, train_loss: 0.011700, val_loss: 0.019755, val_mae: 0.088219
2024-12-20 17:08:49,029 - INFO - Epoch 29, train_loss: 0.008607, val_loss: 0.018457, val_mae: 0.092750
2024-12-20 17:09:10,604 - INFO - Epoch 30, train_loss: 0.018614, val_loss: 0.032003, val_mae: 0.127452
2024-12-20 17:09:32,116 - INFO - Epoch 31, train_loss: 0.009848, val_loss: 0.021619, val_mae: 0.089514
2024-12-20 17:09:53,290 - INFO - Epoch 32, train_loss: 0.007831, val_loss: 0.017454, val_mae: 0.084195
2024-12-20 17:10:15,141 - INFO - Epoch 33, train_loss: 0.006601, val_loss: 0.019815, val_mae: 0.091095
2024-12-20 17:10:36,858 - INFO - Epoch 34, train_loss: 0.006666, val_loss: 0.016518, val_mae: 0.084906
2024-12-20 17:10:58,561 - INFO - Epoch 35, train_loss: 0.005466, val_loss: 0.021101, val_mae: 0.098745
2024-12-20 17:11:19,884 - INFO - Epoch 36, train_loss: 0.007354, val_loss: 0.019268, val_mae: 0.093935
2024-12-20 17:11:41,829 - INFO - Epoch 37, train_loss: 0.008560, val_loss: 0.020165, val_mae: 0.102719
2024-12-20 17:12:04,167 - INFO - Epoch 38, train_loss: 0.006354, val_loss: 0.015980, val_mae: 0.080649
2024-12-20 17:12:26,496 - INFO - Epoch 39, train_loss: 0.005037, val_loss: 0.024332, val_mae: 0.105197
2024-12-20 17:12:48,415 - INFO - Epoch 40, train_loss: 0.008236, val_loss: 0.017231, val_mae: 0.084853
2024-12-20 17:13:11,173 - INFO - Epoch 41, train_loss: 0.005393, val_loss: 0.015998, val_mae: 0.081034
2024-12-20 17:13:32,776 - INFO - Epoch 42, train_loss: 0.004878, val_loss: 0.016492, val_mae: 0.082017
2024-12-20 17:13:54,705 - INFO - Epoch 43, train_loss: 0.004250, val_loss: 0.014980, val_mae: 0.078552
2024-12-20 17:14:16,818 - INFO - Epoch 44, train_loss: 0.004994, val_loss: 0.013623, val_mae: 0.074763
2024-12-20 17:14:38,807 - INFO - Epoch 45, train_loss: 0.003763, val_loss: 0.015418, val_mae: 0.074204
2024-12-20 17:15:00,701 - INFO - Epoch 46, train_loss: 0.003927, val_loss: 0.014223, val_mae: 0.072825
2024-12-20 17:15:21,980 - INFO - Epoch 47, train_loss: 0.003790, val_loss: 0.016648, val_mae: 0.077772
2024-12-20 17:15:43,575 - INFO - Epoch 48, train_loss: 0.004459, val_loss: 0.015736, val_mae: 0.075352
2024-12-20 17:16:05,433 - INFO - Epoch 49, train_loss: 0.003512, val_loss: 0.014622, val_mae: 0.073955
2024-12-20 17:16:26,636 - INFO - Epoch 50, train_loss: 0.003773, val_loss: 0.015819, val_mae: 0.073650
2024-12-20 17:16:48,195 - INFO - Epoch 51, train_loss: 0.002642, val_loss: 0.015714, val_mae: 0.078667
2024-12-20 17:17:09,580 - INFO - Epoch 52, train_loss: 0.002240, val_loss: 0.014028, val_mae: 0.072377
2024-12-20 17:17:31,270 - INFO - Epoch 53, train_loss: 0.002397, val_loss: 0.014398, val_mae: 0.072775
2024-12-20 17:17:52,546 - INFO - Epoch 54, train_loss: 0.002599, val_loss: 0.013509, val_mae: 0.072892
2024-12-20 17:18:14,076 - INFO - Epoch 55, train_loss: 0.002059, val_loss: 0.014399, val_mae: 0.071163
2024-12-20 17:18:35,911 - INFO - Epoch 56, train_loss: 0.002059, val_loss: 0.014655, val_mae: 0.074494
2024-12-20 17:18:57,462 - INFO - Epoch 57, train_loss: 0.002117, val_loss: 0.013926, val_mae: 0.072876
2024-12-20 17:19:19,138 - INFO - Epoch 58, train_loss: 0.001847, val_loss: 0.014775, val_mae: 0.075446
2024-12-20 17:19:40,683 - INFO - Epoch 59, train_loss: 0.002218, val_loss: 0.012850, val_mae: 0.068034
2024-12-20 17:20:03,113 - INFO - Epoch 60, train_loss: 0.001309, val_loss: 0.013684, val_mae: 0.068430
2024-12-20 17:20:24,827 - INFO - Epoch 61, train_loss: 0.001669, val_loss: 0.012145, val_mae: 0.066005
2024-12-20 17:20:47,190 - INFO - Epoch 62, train_loss: 0.001700, val_loss: 0.012241, val_mae: 0.066482
2024-12-20 17:21:09,481 - INFO - Epoch 63, train_loss: 0.000917, val_loss: 0.013076, val_mae: 0.068036
2024-12-20 17:21:31,447 - INFO - Epoch 64, train_loss: 0.000860, val_loss: 0.012027, val_mae: 0.064194
2024-12-20 17:21:52,949 - INFO - Epoch 65, train_loss: 0.001198, val_loss: 0.012584, val_mae: 0.066052
2024-12-20 17:22:14,827 - INFO - Epoch 66, train_loss: 0.000905, val_loss: 0.012529, val_mae: 0.065341
2024-12-20 17:22:36,893 - INFO - Epoch 67, train_loss: 0.000922, val_loss: 0.012876, val_mae: 0.067375
2024-12-20 17:22:58,600 - INFO - Epoch 68, train_loss: 0.000967, val_loss: 0.012684, val_mae: 0.064679
2024-12-20 17:23:20,360 - INFO - Epoch 69, train_loss: 0.000791, val_loss: 0.011965, val_mae: 0.064868
2024-12-20 17:23:41,295 - INFO - Epoch 70, train_loss: 0.000522, val_loss: 0.012799, val_mae: 0.064464
2024-12-20 17:24:03,007 - INFO - Epoch 71, train_loss: 0.000397, val_loss: 0.011876, val_mae: 0.063561
2024-12-20 17:24:24,490 - INFO - Epoch 72, train_loss: 0.000466, val_loss: 0.012326, val_mae: 0.063174
2024-12-20 17:24:45,617 - INFO - Epoch 73, train_loss: 0.000478, val_loss: 0.012021, val_mae: 0.063345
2024-12-20 17:25:07,268 - INFO - Epoch 74, train_loss: 0.000410, val_loss: 0.012227, val_mae: 0.064026
2024-12-20 17:25:28,884 - INFO - Epoch 75, train_loss: 0.000369, val_loss: 0.012145, val_mae: 0.062392
2024-12-20 17:25:49,991 - INFO - Epoch 76, train_loss: 0.000316, val_loss: 0.012285, val_mae: 0.063113
2024-12-20 17:26:11,755 - INFO - Epoch 77, train_loss: 0.000186, val_loss: 0.011883, val_mae: 0.061974
2024-12-20 17:26:33,609 - INFO - Epoch 78, train_loss: 0.000144, val_loss: 0.012063, val_mae: 0.062877
2024-12-20 17:26:55,488 - INFO - Epoch 79, train_loss: 0.000124, val_loss: 0.011704, val_mae: 0.062066
2024-12-20 17:27:16,845 - INFO - Epoch 80, train_loss: 0.000124, val_loss: 0.011966, val_mae: 0.062352
2024-12-20 17:27:38,495 - INFO - Epoch 81, train_loss: 0.000117, val_loss: 0.011904, val_mae: 0.061768
2024-12-20 17:28:00,763 - INFO - Epoch 82, train_loss: 0.000102, val_loss: 0.011884, val_mae: 0.061773
2024-12-20 17:28:22,908 - INFO - Epoch 83, train_loss: 0.000084, val_loss: 0.011973, val_mae: 0.061961
2024-12-20 17:28:45,190 - INFO - Epoch 84, train_loss: 0.000063, val_loss: 0.011863, val_mae: 0.061651
2024-12-20 17:29:07,745 - INFO - Epoch 85, train_loss: 0.000046, val_loss: 0.011823, val_mae: 0.062015
2024-12-20 17:29:29,860 - INFO - Epoch 86, train_loss: 0.000040, val_loss: 0.011942, val_mae: 0.062012
2024-12-20 17:29:51,326 - INFO - Epoch 87, train_loss: 0.000034, val_loss: 0.011701, val_mae: 0.061608
2024-12-20 17:30:13,225 - INFO - Epoch 88, train_loss: 0.000030, val_loss: 0.011873, val_mae: 0.061811
2024-12-20 17:30:35,183 - INFO - Epoch 89, train_loss: 0.000022, val_loss: 0.011790, val_mae: 0.061597
2024-12-20 17:30:56,879 - INFO - Epoch 90, train_loss: 0.000017, val_loss: 0.011858, val_mae: 0.061753
2024-12-20 17:31:17,729 - INFO - Epoch 91, train_loss: 0.000013, val_loss: 0.011863, val_mae: 0.061578
2024-12-20 17:31:39,982 - INFO - Epoch 92, train_loss: 0.000011, val_loss: 0.011801, val_mae: 0.061562
2024-12-20 17:32:01,643 - INFO - Epoch 93, train_loss: 0.000009, val_loss: 0.011846, val_mae: 0.061649
2024-12-20 17:32:22,636 - INFO - Epoch 94, train_loss: 0.000008, val_loss: 0.011831, val_mae: 0.061607
2024-12-20 17:32:43,874 - INFO - Epoch 95, train_loss: 0.000007, val_loss: 0.011840, val_mae: 0.061610
2024-12-20 17:33:05,246 - INFO - Epoch 96, train_loss: 0.000006, val_loss: 0.011836, val_mae: 0.061603
2024-12-20 17:33:26,752 - INFO - Epoch 97, train_loss: 0.000006, val_loss: 0.011839, val_mae: 0.061613
2024-12-20 17:33:48,111 - INFO - Epoch 98, train_loss: 0.000005, val_loss: 0.011839, val_mae: 0.061623
2024-12-20 17:34:09,623 - INFO - Epoch 99, train_loss: 0.000005, val_loss: 0.011841, val_mae: 0.061623
2024-12-20 17:34:31,363 - INFO - Epoch 100, train_loss: 0.000005, val_loss: 0.011841, val_mae: 0.061623
2024-12-20 17:34:33,216 - INFO - Test MAE: 0.061562 with best model at Epoch 92
