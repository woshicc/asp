2024-12-20 18:11:02,394 - INFO - workdir: ./pre-trained/5fold/CHOCH3, adsorbate: H
2024-12-20 18:11:04,243 - INFO - dataset size: 6696, batch size: 8
2024-12-20 18:11:04,243 - INFO - train/valid/test size: 5356/1340/0
2024-12-20 18:11:05,828 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-20 18:11:08,587 - INFO - initial lr: 0.000200000, meanAE: 0.5778782210521103
2024-12-20 18:11:35,178 - INFO - Epoch 1, train_loss: 0.265253, val_loss: 0.169360, val_mae: 0.307848
2024-12-20 18:12:01,386 - INFO - Epoch 2, train_loss: 0.139076, val_loss: 0.092070, val_mae: 0.220881
2024-12-20 18:12:27,278 - INFO - Epoch 3, train_loss: 0.089151, val_loss: 0.065493, val_mae: 0.186569
2024-12-20 18:12:53,010 - INFO - Epoch 4, train_loss: 0.062517, val_loss: 0.042396, val_mae: 0.148522
2024-12-20 18:13:20,647 - INFO - Epoch 5, train_loss: 0.041980, val_loss: 0.032187, val_mae: 0.129577
2024-12-20 18:13:46,922 - INFO - Epoch 6, train_loss: 0.033169, val_loss: 0.031503, val_mae: 0.135228
2024-12-20 18:14:13,427 - INFO - Epoch 7, train_loss: 0.027911, val_loss: 0.027297, val_mae: 0.121426
2024-12-20 18:14:40,278 - INFO - Epoch 8, train_loss: 0.024691, val_loss: 0.024252, val_mae: 0.111513
2024-12-20 18:15:06,499 - INFO - Epoch 9, train_loss: 0.022428, val_loss: 0.021678, val_mae: 0.105340
2024-12-20 18:15:33,211 - INFO - Epoch 10, train_loss: 0.019694, val_loss: 0.024788, val_mae: 0.114249
2024-12-20 18:16:00,639 - INFO - Epoch 11, train_loss: 0.018923, val_loss: 0.018690, val_mae: 0.095045
2024-12-20 18:16:27,542 - INFO - Epoch 12, train_loss: 0.016970, val_loss: 0.018869, val_mae: 0.095945
2024-12-20 18:16:55,523 - INFO - Epoch 13, train_loss: 0.015242, val_loss: 0.022292, val_mae: 0.106322
2024-12-20 18:17:23,159 - INFO - Epoch 14, train_loss: 0.016169, val_loss: 0.025097, val_mae: 0.124110
2024-12-20 18:17:48,826 - INFO - Epoch 15, train_loss: 0.013659, val_loss: 0.016058, val_mae: 0.087054
2024-12-20 18:18:15,295 - INFO - Epoch 16, train_loss: 0.012814, val_loss: 0.018086, val_mae: 0.098941
2024-12-20 18:18:41,399 - INFO - Epoch 17, train_loss: 0.012308, val_loss: 0.019778, val_mae: 0.101906
2024-12-20 18:19:07,416 - INFO - Epoch 18, train_loss: 0.012320, val_loss: 0.014338, val_mae: 0.084716
2024-12-20 18:19:33,071 - INFO - Epoch 19, train_loss: 0.012015, val_loss: 0.016128, val_mae: 0.087795
2024-12-20 18:19:58,771 - INFO - Epoch 20, train_loss: 0.011973, val_loss: 0.016034, val_mae: 0.087824
2024-12-20 18:20:24,662 - INFO - Epoch 21, train_loss: 0.011447, val_loss: 0.016542, val_mae: 0.089880
2024-12-20 18:20:50,488 - INFO - Epoch 22, train_loss: 0.010610, val_loss: 0.015091, val_mae: 0.084892
2024-12-20 18:21:17,955 - INFO - Epoch 23, train_loss: 0.011960, val_loss: 0.016661, val_mae: 0.092116
2024-12-20 18:21:44,088 - INFO - Epoch 24, train_loss: 0.010467, val_loss: 0.018281, val_mae: 0.091005
2024-12-20 18:22:10,319 - INFO - Epoch 25, train_loss: 0.012447, val_loss: 0.018703, val_mae: 0.100622
2024-12-20 18:22:37,083 - INFO - Epoch 26, train_loss: 0.009359, val_loss: 0.012579, val_mae: 0.076393
2024-12-20 18:23:03,503 - INFO - Epoch 27, train_loss: 0.007331, val_loss: 0.012494, val_mae: 0.079603
2024-12-20 18:23:30,133 - INFO - Epoch 28, train_loss: 0.021906, val_loss: 0.013733, val_mae: 0.080614
2024-12-20 18:23:56,980 - INFO - Epoch 29, train_loss: 0.007673, val_loss: 0.011090, val_mae: 0.072607
2024-12-20 18:24:23,995 - INFO - Epoch 30, train_loss: 0.006882, val_loss: 0.010676, val_mae: 0.073581
2024-12-20 18:24:51,886 - INFO - Epoch 31, train_loss: 0.007924, val_loss: 0.009923, val_mae: 0.070225
2024-12-20 18:25:18,730 - INFO - Epoch 32, train_loss: 0.006181, val_loss: 0.010197, val_mae: 0.070219
2024-12-20 18:25:45,105 - INFO - Epoch 33, train_loss: 0.005624, val_loss: 0.009140, val_mae: 0.064428
2024-12-20 18:26:11,262 - INFO - Epoch 34, train_loss: 0.005642, val_loss: 0.010227, val_mae: 0.069707
2024-12-20 18:26:37,490 - INFO - Epoch 35, train_loss: 0.006272, val_loss: 0.012144, val_mae: 0.075518
2024-12-20 18:27:03,365 - INFO - Epoch 36, train_loss: 0.008647, val_loss: 0.010330, val_mae: 0.068847
2024-12-20 18:27:28,992 - INFO - Epoch 37, train_loss: 0.008512, val_loss: 0.010560, val_mae: 0.069574
2024-12-20 18:27:54,641 - INFO - Epoch 38, train_loss: 0.005241, val_loss: 0.008992, val_mae: 0.061621
2024-12-20 18:28:20,341 - INFO - Epoch 39, train_loss: 0.004321, val_loss: 0.009581, val_mae: 0.066167
2024-12-20 18:28:46,051 - INFO - Epoch 40, train_loss: 0.004967, val_loss: 0.010482, val_mae: 0.065845
2024-12-20 18:29:12,961 - INFO - Epoch 41, train_loss: 0.004568, val_loss: 0.009182, val_mae: 0.062806
2024-12-20 18:29:39,501 - INFO - Epoch 42, train_loss: 0.004095, val_loss: 0.011710, val_mae: 0.071833
2024-12-20 18:30:05,315 - INFO - Epoch 43, train_loss: 0.003839, val_loss: 0.011904, val_mae: 0.066480
2024-12-20 18:30:31,898 - INFO - Epoch 44, train_loss: 0.003698, val_loss: 0.012080, val_mae: 0.063118
2024-12-20 18:30:58,106 - INFO - Epoch 45, train_loss: 0.003175, val_loss: 0.010385, val_mae: 0.063747
2024-12-20 18:31:24,138 - INFO - Epoch 46, train_loss: 0.003681, val_loss: 0.008019, val_mae: 0.058850
2024-12-20 18:31:51,023 - INFO - Epoch 47, train_loss: 0.004570, val_loss: 0.009718, val_mae: 0.059385
2024-12-20 18:32:18,320 - INFO - Epoch 48, train_loss: 0.003229, val_loss: 0.008367, val_mae: 0.059993
2024-12-20 18:32:45,754 - INFO - Epoch 49, train_loss: 0.003225, val_loss: 0.008592, val_mae: 0.057959
2024-12-20 18:33:12,815 - INFO - Epoch 50, train_loss: 0.003157, val_loss: 0.009354, val_mae: 0.057997
2024-12-20 18:33:39,580 - INFO - Epoch 51, train_loss: 0.002210, val_loss: 0.009956, val_mae: 0.056903
2024-12-20 18:34:05,652 - INFO - Epoch 52, train_loss: 0.001928, val_loss: 0.009006, val_mae: 0.059312
2024-12-20 18:34:31,946 - INFO - Epoch 53, train_loss: 0.001835, val_loss: 0.011845, val_mae: 0.056263
2024-12-20 18:34:57,998 - INFO - Epoch 54, train_loss: 0.002304, val_loss: 0.011277, val_mae: 0.059544
2024-12-20 18:35:23,366 - INFO - Epoch 55, train_loss: 0.002451, val_loss: 0.008189, val_mae: 0.058666
2024-12-20 18:35:50,788 - INFO - Epoch 56, train_loss: 0.001756, val_loss: 0.010437, val_mae: 0.057376
2024-12-20 18:36:16,890 - INFO - Epoch 57, train_loss: 0.001633, val_loss: 0.009064, val_mae: 0.057767
2024-12-20 18:36:42,880 - INFO - Epoch 58, train_loss: 0.001645, val_loss: 0.009764, val_mae: 0.055310
2024-12-20 18:37:09,044 - INFO - Epoch 59, train_loss: 0.001522, val_loss: 0.007825, val_mae: 0.053866
2024-12-20 18:37:34,740 - INFO - Epoch 60, train_loss: 0.001286, val_loss: 0.010424, val_mae: 0.054584
2024-12-20 18:38:00,910 - INFO - Epoch 61, train_loss: 0.001022, val_loss: 0.008361, val_mae: 0.053525
2024-12-20 18:38:27,204 - INFO - Epoch 62, train_loss: 0.001020, val_loss: 0.010267, val_mae: 0.054099
2024-12-20 18:38:53,624 - INFO - Epoch 63, train_loss: 0.001098, val_loss: 0.008305, val_mae: 0.053927
2024-12-20 18:39:19,807 - INFO - Epoch 64, train_loss: 0.000898, val_loss: 0.009643, val_mae: 0.052775
2024-12-20 18:39:46,739 - INFO - Epoch 65, train_loss: 0.000782, val_loss: 0.008212, val_mae: 0.050726
2024-12-20 18:40:13,068 - INFO - Epoch 66, train_loss: 0.000772, val_loss: 0.009448, val_mae: 0.051260
2024-12-20 18:40:40,307 - INFO - Epoch 67, train_loss: 0.000701, val_loss: 0.008689, val_mae: 0.051199
2024-12-20 18:41:07,261 - INFO - Epoch 68, train_loss: 0.000586, val_loss: 0.009266, val_mae: 0.050711
2024-12-20 18:41:33,924 - INFO - Epoch 69, train_loss: 0.000610, val_loss: 0.007413, val_mae: 0.050869
2024-12-20 18:41:59,714 - INFO - Epoch 70, train_loss: 0.000550, val_loss: 0.009531, val_mae: 0.049858
2024-12-20 18:42:28,289 - INFO - Epoch 71, train_loss: 0.000513, val_loss: 0.007903, val_mae: 0.049652
2024-12-20 18:42:56,943 - INFO - Epoch 72, train_loss: 0.000427, val_loss: 0.009092, val_mae: 0.050323
2024-12-20 18:43:22,308 - INFO - Epoch 73, train_loss: 0.000363, val_loss: 0.008268, val_mae: 0.049208
2024-12-20 18:43:49,949 - INFO - Epoch 74, train_loss: 0.000314, val_loss: 0.008726, val_mae: 0.048911
2024-12-20 18:44:15,970 - INFO - Epoch 75, train_loss: 0.000263, val_loss: 0.008499, val_mae: 0.048973
2024-12-20 18:44:41,722 - INFO - Epoch 76, train_loss: 0.000218, val_loss: 0.008591, val_mae: 0.048367
2024-12-20 18:45:07,970 - INFO - Epoch 77, train_loss: 0.000188, val_loss: 0.008397, val_mae: 0.048404
2024-12-20 18:45:33,757 - INFO - Epoch 78, train_loss: 0.000190, val_loss: 0.008705, val_mae: 0.048946
2024-12-20 18:45:59,907 - INFO - Epoch 79, train_loss: 0.000182, val_loss: 0.008162, val_mae: 0.048106
2024-12-20 18:46:26,722 - INFO - Epoch 80, train_loss: 0.000147, val_loss: 0.009061, val_mae: 0.048254
2024-12-20 18:46:53,321 - INFO - Epoch 81, train_loss: 0.000131, val_loss: 0.008170, val_mae: 0.048046
2024-12-20 18:47:19,554 - INFO - Epoch 82, train_loss: 0.000100, val_loss: 0.008592, val_mae: 0.047254
2024-12-20 18:47:46,298 - INFO - Epoch 83, train_loss: 0.000091, val_loss: 0.008085, val_mae: 0.047382
2024-12-20 18:48:13,230 - INFO - Epoch 84, train_loss: 0.000074, val_loss: 0.008493, val_mae: 0.047585
2024-12-20 18:48:40,281 - INFO - Epoch 85, train_loss: 0.000059, val_loss: 0.008100, val_mae: 0.047579
2024-12-20 18:49:07,028 - INFO - Epoch 86, train_loss: 0.000054, val_loss: 0.008584, val_mae: 0.047744
2024-12-20 18:49:33,512 - INFO - Epoch 87, train_loss: 0.000042, val_loss: 0.008273, val_mae: 0.047347
2024-12-20 18:49:59,562 - INFO - Epoch 88, train_loss: 0.000038, val_loss: 0.008462, val_mae: 0.047292
2024-12-20 18:50:27,288 - INFO - Epoch 89, train_loss: 0.000032, val_loss: 0.008309, val_mae: 0.047332
2024-12-20 18:50:55,885 - INFO - Epoch 90, train_loss: 0.000027, val_loss: 0.008421, val_mae: 0.047226
2024-12-20 18:51:21,486 - INFO - Epoch 91, train_loss: 0.000025, val_loss: 0.008360, val_mae: 0.047127
2024-12-20 18:51:49,170 - INFO - Epoch 92, train_loss: 0.000021, val_loss: 0.008362, val_mae: 0.047133
2024-12-20 18:52:15,338 - INFO - Epoch 93, train_loss: 0.000020, val_loss: 0.008374, val_mae: 0.047098
2024-12-20 18:52:41,285 - INFO - Epoch 94, train_loss: 0.000017, val_loss: 0.008367, val_mae: 0.047117
2024-12-20 18:53:07,471 - INFO - Epoch 95, train_loss: 0.000016, val_loss: 0.008372, val_mae: 0.047193
2024-12-20 18:53:33,694 - INFO - Epoch 96, train_loss: 0.000015, val_loss: 0.008369, val_mae: 0.047113
2024-12-20 18:54:00,047 - INFO - Epoch 97, train_loss: 0.000014, val_loss: 0.008369, val_mae: 0.047118
2024-12-20 18:54:26,271 - INFO - Epoch 98, train_loss: 0.000013, val_loss: 0.008369, val_mae: 0.047112
2024-12-20 18:54:52,910 - INFO - Epoch 99, train_loss: 0.000013, val_loss: 0.008368, val_mae: 0.047108
2024-12-20 18:55:19,121 - INFO - Epoch 100, train_loss: 0.000013, val_loss: 0.008368, val_mae: 0.047108
2024-12-20 18:55:21,337 - INFO - Test MAE: 0.047098 with best model at Epoch 93
