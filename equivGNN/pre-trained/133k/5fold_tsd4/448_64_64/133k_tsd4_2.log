2025-04-09 20:36:05,835 - INFO - workdir: ./pre-trained/5fold_tsd4, adsorbate: 133k_tsd4
2025-04-09 20:38:07,463 - INFO - dataset size: 132752, batch size: 64
2025-04-09 20:38:07,463 - INFO - train/valid size: 106202/26550
2025-04-09 20:38:11,267 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 576x0e+64x1o+64x2e | 90112 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 27x0e -> 576x0e+64x1o+64x2e | 1990656 paths | 1990656 weights)
        )
        (second): Gate (576x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(448x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e | 208896 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1856]
          (tp): TensorProduct(448x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 576x0e+640x1o+640x2e | 1856 paths | 1856 weights)
          (linear_2): Linear(576x0e+640x1o+640x2e -> 576x0e+64x1o+64x2e | 413696 weights)
          (sc): FullyConnectedTensorProduct(448x0e+64x1o+64x2e x 27x0e -> 576x0e+64x1o+64x2e | 7188480 paths | 7188480 weights)
        )
        (second): Gate (576x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e)
      )
      (2): Convolution(
        (linear_1): Linear(448x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e | 208896 weights)
        (fc): FullyConnectedNet[8, 64, 64, 576]
        (tp): TensorProduct(448x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 576x0e | 576 paths | 576 weights)
        (linear_2): Linear(576x0e -> 128x0e | 73728 weights)
        (sc): FullyConnectedTensorProduct(448x0e+64x1o+64x2e x 27x0e -> 128x0e | 1548288 paths | 1548288 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2025-04-09 20:38:11,268 - INFO - total number of parameters: 11961472
2025-04-09 20:38:35,617 - INFO - initial lr: 0.000400000, meanAE: 1.5029680036343356
2025-04-09 20:45:07,810 - INFO - Epoch 1, train_loss: 0.246401, val_loss: 0.142122, val_mae: 0.142121
2025-04-09 20:51:39,701 - INFO - Epoch 2, train_loss: 0.122685, val_loss: 0.099855, val_mae: 0.099858
2025-04-09 20:58:12,824 - INFO - Epoch 3, train_loss: 0.090383, val_loss: 0.077997, val_mae: 0.078001
2025-04-09 21:04:47,129 - INFO - Epoch 4, train_loss: 0.077295, val_loss: 0.073523, val_mae: 0.073525
2025-04-09 21:11:21,981 - INFO - Epoch 5, train_loss: 0.069417, val_loss: 0.068170, val_mae: 0.068165
2025-04-09 21:17:54,787 - INFO - Epoch 6, train_loss: 0.064800, val_loss: 0.062064, val_mae: 0.062064
2025-04-09 21:24:25,964 - INFO - Epoch 7, train_loss: 0.060744, val_loss: 0.058578, val_mae: 0.058579
2025-04-09 21:30:56,531 - INFO - Epoch 8, train_loss: 0.057830, val_loss: 0.057230, val_mae: 0.057230
2025-04-09 21:37:26,321 - INFO - Epoch 9, train_loss: 0.055885, val_loss: 0.072666, val_mae: 0.072666
2025-04-09 21:43:56,400 - INFO - Epoch 10, train_loss: 0.053697, val_loss: 0.067241, val_mae: 0.067243
2025-04-09 21:50:26,197 - INFO - Epoch 11, train_loss: 0.051478, val_loss: 0.051772, val_mae: 0.051775
2025-04-09 21:56:58,067 - INFO - Epoch 12, train_loss: 0.050611, val_loss: 0.051195, val_mae: 0.051199
2025-04-09 22:03:31,654 - INFO - Epoch 13, train_loss: 0.048685, val_loss: 0.051908, val_mae: 0.051911
2025-04-09 22:10:06,909 - INFO - Epoch 14, train_loss: 0.047888, val_loss: 0.049361, val_mae: 0.049363
2025-04-09 22:16:40,809 - INFO - Epoch 15, train_loss: 0.046841, val_loss: 0.046528, val_mae: 0.046529
2025-04-09 22:23:13,769 - INFO - Epoch 16, train_loss: 0.045257, val_loss: 0.047817, val_mae: 0.047820
2025-04-09 22:29:46,859 - INFO - Epoch 17, train_loss: 0.045357, val_loss: 0.047042, val_mae: 0.047047
2025-04-09 22:36:19,303 - INFO - Epoch 18, train_loss: 0.044901, val_loss: 0.056204, val_mae: 0.056204
2025-04-09 22:42:52,245 - INFO - Epoch 19, train_loss: 0.043789, val_loss: 0.046559, val_mae: 0.046556
2025-04-09 22:49:24,403 - INFO - Epoch 20, train_loss: 0.043385, val_loss: 0.047647, val_mae: 0.047651
2025-04-09 22:55:56,779 - INFO - Epoch 21, train_loss: 0.043101, val_loss: 0.050241, val_mae: 0.050239
2025-04-09 23:02:28,075 - INFO - Epoch 22, train_loss: 0.042781, val_loss: 0.042264, val_mae: 0.042264
2025-04-09 23:08:58,833 - INFO - Epoch 23, train_loss: 0.041391, val_loss: 0.046080, val_mae: 0.046080
2025-04-09 23:15:29,976 - INFO - Epoch 24, train_loss: 0.041668, val_loss: 0.042441, val_mae: 0.042445
2025-04-09 23:21:59,951 - INFO - Epoch 25, train_loss: 0.041247, val_loss: 0.040534, val_mae: 0.040536
2025-04-09 23:28:29,017 - INFO - Epoch 26, train_loss: 0.040500, val_loss: 0.040456, val_mae: 0.040457
2025-04-09 23:35:08,225 - INFO - Epoch 27, train_loss: 0.040392, val_loss: 0.045351, val_mae: 0.045354
2025-04-09 23:41:33,420 - INFO - Epoch 28, train_loss: 0.039987, val_loss: 0.044504, val_mae: 0.044503
2025-04-09 23:47:58,555 - INFO - Epoch 29, train_loss: 0.039450, val_loss: 0.041809, val_mae: 0.041811
2025-04-09 23:54:23,455 - INFO - Epoch 30, train_loss: 0.039199, val_loss: 0.041596, val_mae: 0.041598
2025-04-10 00:00:48,409 - INFO - Epoch 31, train_loss: 0.038345, val_loss: 0.040239, val_mae: 0.040243
2025-04-10 00:07:13,279 - INFO - Epoch 32, train_loss: 0.037026, val_loss: 0.038611, val_mae: 0.038612
2025-04-10 00:13:41,792 - INFO - Epoch 33, train_loss: 0.035647, val_loss: 0.037733, val_mae: 0.037735
2025-04-10 00:20:07,385 - INFO - Epoch 34, train_loss: 0.034706, val_loss: 0.035949, val_mae: 0.035949
2025-04-10 00:26:32,336 - INFO - Epoch 35, train_loss: 0.033470, val_loss: 0.039620, val_mae: 0.039622
2025-04-10 00:32:57,597 - INFO - Epoch 36, train_loss: 0.032202, val_loss: 0.036816, val_mae: 0.036818
2025-04-10 00:39:56,026 - INFO - Epoch 37, train_loss: 0.031379, val_loss: 0.034369, val_mae: 0.034370
2025-04-10 00:47:16,973 - INFO - Epoch 38, train_loss: 0.030508, val_loss: 0.033726, val_mae: 0.033728
2025-04-10 00:53:48,007 - INFO - Epoch 39, train_loss: 0.029421, val_loss: 0.034742, val_mae: 0.034742
2025-04-10 01:00:15,186 - INFO - Epoch 40, train_loss: 0.028871, val_loss: 0.037108, val_mae: 0.037112
2025-04-10 01:06:47,992 - INFO - Epoch 41, train_loss: 0.027924, val_loss: 0.033022, val_mae: 0.033025
2025-04-10 01:13:14,826 - INFO - Epoch 42, train_loss: 0.027010, val_loss: 0.032906, val_mae: 0.032908
2025-04-10 01:19:41,126 - INFO - Epoch 43, train_loss: 0.026397, val_loss: 0.033886, val_mae: 0.033889
2025-04-10 01:26:06,395 - INFO - Epoch 44, train_loss: 0.025705, val_loss: 0.030181, val_mae: 0.030183
2025-04-10 01:32:31,424 - INFO - Epoch 45, train_loss: 0.025282, val_loss: 0.029055, val_mae: 0.029057
2025-04-10 01:38:56,632 - INFO - Epoch 46, train_loss: 0.024576, val_loss: 0.030113, val_mae: 0.030113
2025-04-10 01:45:21,876 - INFO - Epoch 47, train_loss: 0.023773, val_loss: 0.028513, val_mae: 0.028516
2025-04-10 01:51:47,098 - INFO - Epoch 48, train_loss: 0.023261, val_loss: 0.030596, val_mae: 0.030599
2025-04-10 01:58:12,352 - INFO - Epoch 49, train_loss: 0.022961, val_loss: 0.028625, val_mae: 0.028630
2025-04-10 02:04:37,439 - INFO - Epoch 50, train_loss: 0.022341, val_loss: 0.027830, val_mae: 0.027832
2025-04-10 02:11:02,633 - INFO - Epoch 51, train_loss: 0.021809, val_loss: 0.026841, val_mae: 0.026844
2025-04-10 02:17:27,926 - INFO - Epoch 52, train_loss: 0.021363, val_loss: 0.026442, val_mae: 0.026444
2025-04-10 02:23:53,723 - INFO - Epoch 53, train_loss: 0.020784, val_loss: 0.026814, val_mae: 0.026816
2025-04-10 02:30:20,351 - INFO - Epoch 54, train_loss: 0.020246, val_loss: 0.025628, val_mae: 0.025631
2025-04-10 02:36:46,840 - INFO - Epoch 55, train_loss: 0.019754, val_loss: 0.025934, val_mae: 0.025937
2025-04-10 02:43:12,123 - INFO - Epoch 56, train_loss: 0.019258, val_loss: 0.025275, val_mae: 0.025277
2025-04-10 02:49:38,082 - INFO - Epoch 57, train_loss: 0.019050, val_loss: 0.025442, val_mae: 0.025445
2025-04-10 02:56:03,799 - INFO - Epoch 58, train_loss: 0.018604, val_loss: 0.027532, val_mae: 0.027534
2025-04-10 03:02:28,726 - INFO - Epoch 59, train_loss: 0.017933, val_loss: 0.024998, val_mae: 0.025001
2025-04-10 03:08:54,113 - INFO - Epoch 60, train_loss: 0.017527, val_loss: 0.024517, val_mae: 0.024519
2025-04-10 03:15:19,397 - INFO - Epoch 61, train_loss: 0.017139, val_loss: 0.024644, val_mae: 0.024647
2025-04-10 03:21:44,814 - INFO - Epoch 62, train_loss: 0.016731, val_loss: 0.024786, val_mae: 0.024788
2025-04-10 03:28:10,078 - INFO - Epoch 63, train_loss: 0.016258, val_loss: 0.023390, val_mae: 0.023391
2025-04-10 03:34:35,733 - INFO - Epoch 64, train_loss: 0.015825, val_loss: 0.024097, val_mae: 0.024099
2025-04-10 03:41:00,677 - INFO - Epoch 65, train_loss: 0.015547, val_loss: 0.022581, val_mae: 0.022583
2025-04-10 03:47:26,100 - INFO - Epoch 66, train_loss: 0.015117, val_loss: 0.022090, val_mae: 0.022092
2025-04-10 03:53:51,293 - INFO - Epoch 67, train_loss: 0.014690, val_loss: 0.022365, val_mae: 0.022366
2025-04-10 04:00:16,667 - INFO - Epoch 68, train_loss: 0.014290, val_loss: 0.021661, val_mae: 0.021662
2025-04-10 04:06:41,919 - INFO - Epoch 69, train_loss: 0.014194, val_loss: 0.023707, val_mae: 0.023709
2025-04-10 04:13:07,557 - INFO - Epoch 70, train_loss: 0.013765, val_loss: 0.021815, val_mae: 0.021816
2025-04-10 04:19:33,396 - INFO - Epoch 71, train_loss: 0.013240, val_loss: 0.022302, val_mae: 0.022304
2025-04-10 04:26:00,047 - INFO - Epoch 72, train_loss: 0.012862, val_loss: 0.021647, val_mae: 0.021649
2025-04-10 04:32:25,606 - INFO - Epoch 73, train_loss: 0.012642, val_loss: 0.021266, val_mae: 0.021268
2025-04-10 04:38:51,435 - INFO - Epoch 74, train_loss: 0.012138, val_loss: 0.020916, val_mae: 0.020919
2025-04-10 04:45:17,291 - INFO - Epoch 75, train_loss: 0.011832, val_loss: 0.020726, val_mae: 0.020728
2025-04-10 04:51:42,714 - INFO - Epoch 76, train_loss: 0.011501, val_loss: 0.020642, val_mae: 0.020643
2025-04-10 04:58:08,843 - INFO - Epoch 77, train_loss: 0.011144, val_loss: 0.020515, val_mae: 0.020517
2025-04-10 05:04:34,042 - INFO - Epoch 78, train_loss: 0.010807, val_loss: 0.020233, val_mae: 0.020236
2025-04-10 05:11:00,122 - INFO - Epoch 79, train_loss: 0.010455, val_loss: 0.019973, val_mae: 0.019975
2025-04-10 05:17:26,090 - INFO - Epoch 80, train_loss: 0.010225, val_loss: 0.020086, val_mae: 0.020088
2025-04-10 05:23:51,628 - INFO - Epoch 81, train_loss: 0.009670, val_loss: 0.019882, val_mae: 0.019884
2025-04-10 05:30:17,099 - INFO - Epoch 82, train_loss: 0.009515, val_loss: 0.020095, val_mae: 0.020098
2025-04-10 05:36:43,293 - INFO - Epoch 83, train_loss: 0.009167, val_loss: 0.019070, val_mae: 0.019072
2025-04-10 05:43:08,862 - INFO - Epoch 84, train_loss: 0.008758, val_loss: 0.018967, val_mae: 0.018969
2025-04-10 05:49:34,105 - INFO - Epoch 85, train_loss: 0.008456, val_loss: 0.018830, val_mae: 0.018832
2025-04-10 05:55:59,653 - INFO - Epoch 86, train_loss: 0.008039, val_loss: 0.018632, val_mae: 0.018634
2025-04-10 06:02:24,872 - INFO - Epoch 87, train_loss: 0.007743, val_loss: 0.018774, val_mae: 0.018776
2025-04-10 06:08:50,547 - INFO - Epoch 88, train_loss: 0.007389, val_loss: 0.018398, val_mae: 0.018400
2025-04-10 06:15:15,692 - INFO - Epoch 89, train_loss: 0.007054, val_loss: 0.018664, val_mae: 0.018666
2025-04-10 06:21:40,677 - INFO - Epoch 90, train_loss: 0.006806, val_loss: 0.018289, val_mae: 0.018291
2025-04-10 06:28:05,933 - INFO - Epoch 91, train_loss: 0.006436, val_loss: 0.018146, val_mae: 0.018148
2025-04-10 06:34:31,592 - INFO - Epoch 92, train_loss: 0.006131, val_loss: 0.018069, val_mae: 0.018070
2025-04-10 06:40:56,768 - INFO - Epoch 93, train_loss: 0.005798, val_loss: 0.017976, val_mae: 0.017978
2025-04-10 06:47:22,836 - INFO - Epoch 94, train_loss: 0.005523, val_loss: 0.017707, val_mae: 0.017709
2025-04-10 06:53:48,820 - INFO - Epoch 95, train_loss: 0.005257, val_loss: 0.017700, val_mae: 0.017701
2025-04-10 07:00:15,101 - INFO - Epoch 96, train_loss: 0.004920, val_loss: 0.017809, val_mae: 0.017811
2025-04-10 07:06:41,374 - INFO - Epoch 97, train_loss: 0.004614, val_loss: 0.017488, val_mae: 0.017489
2025-04-10 07:13:08,003 - INFO - Epoch 98, train_loss: 0.004316, val_loss: 0.017450, val_mae: 0.017452
2025-04-10 07:19:33,679 - INFO - Epoch 99, train_loss: 0.004066, val_loss: 0.017401, val_mae: 0.017403
2025-04-10 07:25:59,930 - INFO - Epoch 100, train_loss: 0.003814, val_loss: 0.017360, val_mae: 0.017362
2025-04-10 07:26:22,503 - INFO - Test MAE: 0.017362 with best model at Epoch 100
