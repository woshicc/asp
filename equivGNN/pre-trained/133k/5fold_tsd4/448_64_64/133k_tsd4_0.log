2025-04-09 20:34:42,952 - INFO - workdir: ./pre-trained/5fold_tsd4, adsorbate: 133k_tsd4
2025-04-09 20:36:08,944 - INFO - dataset size: 132752, batch size: 64
2025-04-09 20:36:08,945 - INFO - train/valid size: 106201/26551
2025-04-09 20:36:14,585 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 576x0e+64x1o+64x2e | 90112 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 27x0e -> 576x0e+64x1o+64x2e | 1990656 paths | 1990656 weights)
        )
        (second): Gate (576x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(448x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e | 208896 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1856]
          (tp): TensorProduct(448x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 576x0e+640x1o+640x2e | 1856 paths | 1856 weights)
          (linear_2): Linear(576x0e+640x1o+640x2e -> 576x0e+64x1o+64x2e | 413696 weights)
          (sc): FullyConnectedTensorProduct(448x0e+64x1o+64x2e x 27x0e -> 576x0e+64x1o+64x2e | 7188480 paths | 7188480 weights)
        )
        (second): Gate (576x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e)
      )
      (2): Convolution(
        (linear_1): Linear(448x0e+64x1o+64x2e -> 448x0e+64x1o+64x2e | 208896 weights)
        (fc): FullyConnectedNet[8, 64, 64, 576]
        (tp): TensorProduct(448x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 576x0e | 576 paths | 576 weights)
        (linear_2): Linear(576x0e -> 128x0e | 73728 weights)
        (sc): FullyConnectedTensorProduct(448x0e+64x1o+64x2e x 27x0e -> 128x0e | 1548288 paths | 1548288 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2025-04-09 20:36:14,586 - INFO - total number of parameters: 11961472
2025-04-09 20:36:38,479 - INFO - initial lr: 0.000400000, meanAE: 1.5021800577833098
2025-04-09 20:43:06,849 - INFO - Epoch 1, train_loss: 0.246998, val_loss: 0.137093, val_mae: 0.137095
2025-04-09 20:49:36,592 - INFO - Epoch 2, train_loss: 0.123395, val_loss: 0.099041, val_mae: 0.099042
2025-04-09 20:56:08,271 - INFO - Epoch 3, train_loss: 0.089822, val_loss: 0.077357, val_mae: 0.077355
2025-04-09 21:02:39,223 - INFO - Epoch 4, train_loss: 0.076653, val_loss: 0.074641, val_mae: 0.074644
2025-04-09 21:09:10,492 - INFO - Epoch 5, train_loss: 0.069214, val_loss: 0.067754, val_mae: 0.067755
2025-04-09 21:15:42,217 - INFO - Epoch 6, train_loss: 0.064646, val_loss: 0.092067, val_mae: 0.092067
2025-04-09 21:22:19,083 - INFO - Epoch 7, train_loss: 0.060834, val_loss: 0.074054, val_mae: 0.074057
2025-04-09 21:28:49,992 - INFO - Epoch 8, train_loss: 0.058002, val_loss: 0.056043, val_mae: 0.056044
2025-04-09 21:35:23,907 - INFO - Epoch 9, train_loss: 0.055802, val_loss: 0.056285, val_mae: 0.056288
2025-04-09 21:41:55,458 - INFO - Epoch 10, train_loss: 0.053124, val_loss: 0.053315, val_mae: 0.053315
2025-04-09 21:48:26,907 - INFO - Epoch 11, train_loss: 0.051940, val_loss: 0.049044, val_mae: 0.049044
2025-04-09 21:55:04,240 - INFO - Epoch 12, train_loss: 0.050180, val_loss: 0.049729, val_mae: 0.049724
2025-04-09 22:01:41,757 - INFO - Epoch 13, train_loss: 0.048386, val_loss: 0.050986, val_mae: 0.050985
2025-04-09 22:08:19,953 - INFO - Epoch 14, train_loss: 0.048013, val_loss: 0.059300, val_mae: 0.059298
2025-04-09 22:14:56,227 - INFO - Epoch 15, train_loss: 0.046677, val_loss: 0.046999, val_mae: 0.046994
2025-04-09 22:21:34,355 - INFO - Epoch 16, train_loss: 0.045581, val_loss: 0.047237, val_mae: 0.047237
2025-04-09 22:28:12,461 - INFO - Epoch 17, train_loss: 0.045532, val_loss: 0.047891, val_mae: 0.047891
2025-04-09 22:34:48,907 - INFO - Epoch 18, train_loss: 0.044807, val_loss: 0.048457, val_mae: 0.048457
2025-04-09 22:41:24,890 - INFO - Epoch 19, train_loss: 0.043886, val_loss: 0.047478, val_mae: 0.047478
2025-04-09 22:48:01,189 - INFO - Epoch 20, train_loss: 0.043156, val_loss: 0.045598, val_mae: 0.045598
2025-04-09 22:54:36,394 - INFO - Epoch 21, train_loss: 0.042834, val_loss: 0.051962, val_mae: 0.051960
2025-04-09 23:01:11,422 - INFO - Epoch 22, train_loss: 0.042437, val_loss: 0.047836, val_mae: 0.047833
2025-04-09 23:07:49,308 - INFO - Epoch 23, train_loss: 0.041912, val_loss: 0.046826, val_mae: 0.046825
2025-04-09 23:14:25,081 - INFO - Epoch 24, train_loss: 0.041530, val_loss: 0.045431, val_mae: 0.045428
2025-04-09 23:21:00,188 - INFO - Epoch 25, train_loss: 0.041128, val_loss: 0.046723, val_mae: 0.046721
2025-04-09 23:27:35,340 - INFO - Epoch 26, train_loss: 0.040722, val_loss: 0.044204, val_mae: 0.044203
2025-04-09 23:34:11,224 - INFO - Epoch 27, train_loss: 0.040171, val_loss: 0.043970, val_mae: 0.043968
2025-04-09 23:40:46,244 - INFO - Epoch 28, train_loss: 0.039554, val_loss: 0.043614, val_mae: 0.043613
2025-04-09 23:47:20,570 - INFO - Epoch 29, train_loss: 0.039204, val_loss: 0.039914, val_mae: 0.039910
2025-04-09 23:53:54,762 - INFO - Epoch 30, train_loss: 0.038769, val_loss: 0.042192, val_mae: 0.042192
2025-04-10 00:00:29,973 - INFO - Epoch 31, train_loss: 0.038349, val_loss: 0.040514, val_mae: 0.040512
2025-04-10 00:07:09,051 - INFO - Epoch 32, train_loss: 0.037156, val_loss: 0.038841, val_mae: 0.038838
2025-04-10 00:13:44,790 - INFO - Epoch 33, train_loss: 0.035576, val_loss: 0.040979, val_mae: 0.040977
2025-04-10 00:20:25,070 - INFO - Epoch 34, train_loss: 0.034751, val_loss: 0.037009, val_mae: 0.037008
2025-04-10 00:27:02,779 - INFO - Epoch 35, train_loss: 0.033362, val_loss: 0.038230, val_mae: 0.038230
2025-04-10 00:33:38,211 - INFO - Epoch 36, train_loss: 0.032162, val_loss: 0.036504, val_mae: 0.036498
2025-04-10 00:40:14,026 - INFO - Epoch 37, train_loss: 0.031430, val_loss: 0.036952, val_mae: 0.036952
2025-04-10 00:46:49,116 - INFO - Epoch 38, train_loss: 0.030500, val_loss: 0.034252, val_mae: 0.034253
2025-04-10 00:53:21,793 - INFO - Epoch 39, train_loss: 0.029540, val_loss: 0.032367, val_mae: 0.032364
2025-04-10 00:59:59,460 - INFO - Epoch 40, train_loss: 0.028759, val_loss: 0.032312, val_mae: 0.032309
2025-04-10 01:06:42,979 - INFO - Epoch 41, train_loss: 0.028043, val_loss: 0.032052, val_mae: 0.032049
2025-04-10 01:13:26,153 - INFO - Epoch 42, train_loss: 0.027137, val_loss: 0.031565, val_mae: 0.031564
2025-04-10 01:20:08,041 - INFO - Epoch 43, train_loss: 0.026299, val_loss: 0.034864, val_mae: 0.034862
2025-04-10 01:26:49,773 - INFO - Epoch 44, train_loss: 0.025755, val_loss: 0.029574, val_mae: 0.029574
2025-04-10 01:33:27,421 - INFO - Epoch 45, train_loss: 0.025237, val_loss: 0.030935, val_mae: 0.030935
2025-04-10 01:40:05,682 - INFO - Epoch 46, train_loss: 0.024359, val_loss: 0.029438, val_mae: 0.029436
2025-04-10 01:46:48,335 - INFO - Epoch 47, train_loss: 0.024004, val_loss: 0.028906, val_mae: 0.028904
2025-04-10 01:53:24,673 - INFO - Epoch 48, train_loss: 0.023229, val_loss: 0.030161, val_mae: 0.030159
2025-04-10 02:00:02,174 - INFO - Epoch 49, train_loss: 0.022808, val_loss: 0.028783, val_mae: 0.028781
2025-04-10 02:06:35,297 - INFO - Epoch 50, train_loss: 0.022349, val_loss: 0.027543, val_mae: 0.027540
2025-04-10 02:13:10,003 - INFO - Epoch 51, train_loss: 0.021817, val_loss: 0.029132, val_mae: 0.029131
2025-04-10 02:19:43,716 - INFO - Epoch 52, train_loss: 0.021331, val_loss: 0.027691, val_mae: 0.027690
2025-04-10 02:26:18,098 - INFO - Epoch 53, train_loss: 0.020670, val_loss: 0.026615, val_mae: 0.026614
2025-04-10 02:32:51,143 - INFO - Epoch 54, train_loss: 0.020336, val_loss: 0.027734, val_mae: 0.027733
2025-04-10 02:39:25,112 - INFO - Epoch 55, train_loss: 0.019824, val_loss: 0.025970, val_mae: 0.025967
2025-04-10 02:46:10,758 - INFO - Epoch 56, train_loss: 0.019387, val_loss: 0.026693, val_mae: 0.026690
2025-04-10 02:52:56,121 - INFO - Epoch 57, train_loss: 0.018962, val_loss: 0.024934, val_mae: 0.024933
2025-04-10 02:59:43,192 - INFO - Epoch 58, train_loss: 0.018361, val_loss: 0.025283, val_mae: 0.025281
2025-04-10 03:06:27,006 - INFO - Epoch 59, train_loss: 0.017900, val_loss: 0.025210, val_mae: 0.025208
2025-04-10 03:13:15,670 - INFO - Epoch 60, train_loss: 0.017459, val_loss: 0.025451, val_mae: 0.025449
2025-04-10 03:19:53,835 - INFO - Epoch 61, train_loss: 0.017182, val_loss: 0.029185, val_mae: 0.029182
2025-04-10 03:26:33,122 - INFO - Epoch 62, train_loss: 0.016759, val_loss: 0.024387, val_mae: 0.024387
2025-04-10 03:33:10,351 - INFO - Epoch 63, train_loss: 0.016256, val_loss: 0.027739, val_mae: 0.027736
2025-04-10 03:39:48,495 - INFO - Epoch 64, train_loss: 0.016043, val_loss: 0.023802, val_mae: 0.023799
2025-04-10 03:46:24,983 - INFO - Epoch 65, train_loss: 0.015431, val_loss: 0.023674, val_mae: 0.023672
2025-04-10 03:53:02,192 - INFO - Epoch 66, train_loss: 0.015134, val_loss: 0.023344, val_mae: 0.023343
2025-04-10 03:59:38,059 - INFO - Epoch 67, train_loss: 0.014713, val_loss: 0.022669, val_mae: 0.022667
2025-04-10 04:06:14,264 - INFO - Epoch 68, train_loss: 0.014262, val_loss: 0.023074, val_mae: 0.023072
2025-04-10 04:12:47,905 - INFO - Epoch 69, train_loss: 0.013965, val_loss: 0.022175, val_mae: 0.022173
2025-04-10 04:19:21,448 - INFO - Epoch 70, train_loss: 0.013596, val_loss: 0.023431, val_mae: 0.023430
2025-04-10 04:26:03,969 - INFO - Epoch 71, train_loss: 0.013165, val_loss: 0.021627, val_mae: 0.021625
2025-04-10 04:32:35,717 - INFO - Epoch 72, train_loss: 0.012956, val_loss: 0.021806, val_mae: 0.021804
2025-04-10 04:39:09,269 - INFO - Epoch 73, train_loss: 0.012530, val_loss: 0.021314, val_mae: 0.021312
2025-04-10 04:45:42,075 - INFO - Epoch 74, train_loss: 0.012168, val_loss: 0.021610, val_mae: 0.021609
2025-04-10 04:52:16,548 - INFO - Epoch 75, train_loss: 0.011827, val_loss: 0.021931, val_mae: 0.021929
2025-04-10 04:58:48,914 - INFO - Epoch 76, train_loss: 0.011477, val_loss: 0.020792, val_mae: 0.020790
2025-04-10 05:05:21,564 - INFO - Epoch 77, train_loss: 0.011141, val_loss: 0.020285, val_mae: 0.020283
2025-04-10 05:11:55,070 - INFO - Epoch 78, train_loss: 0.010800, val_loss: 0.020290, val_mae: 0.020288
2025-04-10 05:18:26,729 - INFO - Epoch 79, train_loss: 0.010470, val_loss: 0.020201, val_mae: 0.020199
2025-04-10 05:25:00,803 - INFO - Epoch 80, train_loss: 0.010155, val_loss: 0.019937, val_mae: 0.019936
2025-04-10 05:31:32,708 - INFO - Epoch 81, train_loss: 0.009716, val_loss: 0.021350, val_mae: 0.021348
2025-04-10 05:38:06,885 - INFO - Epoch 82, train_loss: 0.009468, val_loss: 0.019849, val_mae: 0.019847
2025-04-10 05:44:38,527 - INFO - Epoch 83, train_loss: 0.009085, val_loss: 0.019319, val_mae: 0.019316
2025-04-10 05:51:11,976 - INFO - Epoch 84, train_loss: 0.008921, val_loss: 0.019794, val_mae: 0.019792
2025-04-10 05:57:43,736 - INFO - Epoch 85, train_loss: 0.008393, val_loss: 0.019195, val_mae: 0.019193
2025-04-10 06:04:16,853 - INFO - Epoch 86, train_loss: 0.008090, val_loss: 0.019244, val_mae: 0.019243
2025-04-10 06:10:49,382 - INFO - Epoch 87, train_loss: 0.007740, val_loss: 0.018989, val_mae: 0.018987
2025-04-10 06:17:21,934 - INFO - Epoch 88, train_loss: 0.007441, val_loss: 0.018717, val_mae: 0.018715
2025-04-10 06:23:54,928 - INFO - Epoch 89, train_loss: 0.007109, val_loss: 0.019044, val_mae: 0.019041
2025-04-10 06:30:27,604 - INFO - Epoch 90, train_loss: 0.006764, val_loss: 0.018731, val_mae: 0.018729
2025-04-10 06:37:02,333 - INFO - Epoch 91, train_loss: 0.006493, val_loss: 0.018536, val_mae: 0.018534
2025-04-10 06:43:35,268 - INFO - Epoch 92, train_loss: 0.006171, val_loss: 0.018230, val_mae: 0.018228
2025-04-10 06:50:10,205 - INFO - Epoch 93, train_loss: 0.005856, val_loss: 0.018335, val_mae: 0.018333
2025-04-10 06:56:43,661 - INFO - Epoch 94, train_loss: 0.005537, val_loss: 0.018116, val_mae: 0.018115
2025-04-10 07:03:16,980 - INFO - Epoch 95, train_loss: 0.005230, val_loss: 0.017991, val_mae: 0.017989
2025-04-10 07:09:51,876 - INFO - Epoch 96, train_loss: 0.004944, val_loss: 0.017893, val_mae: 0.017891
2025-04-10 07:16:25,322 - INFO - Epoch 97, train_loss: 0.004638, val_loss: 0.017898, val_mae: 0.017896
2025-04-10 07:22:58,862 - INFO - Epoch 98, train_loss: 0.004363, val_loss: 0.017811, val_mae: 0.017809
2025-04-10 07:29:32,967 - INFO - Epoch 99, train_loss: 0.004094, val_loss: 0.017747, val_mae: 0.017745
2025-04-10 07:36:07,737 - INFO - Epoch 100, train_loss: 0.003850, val_loss: 0.017707, val_mae: 0.017705
2025-04-10 07:36:29,899 - INFO - Test MAE: 0.017705 with best model at Epoch 100
