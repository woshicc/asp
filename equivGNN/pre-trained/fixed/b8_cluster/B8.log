2024-12-22 11:57:38,928 - INFO - workdir: ./pre-trained/random, adsorbate: B8
2024-12-22 11:57:40,520 - INFO - dataset size: 8000, batch size: 8
2024-12-22 11:57:40,520 - INFO - train/valid/test size: 7000/1000/0
2024-12-22 11:57:42,090 - INFO - equivGNN(
  (atom_embedding): Linear(92x0e -> 128x0e | 11776 weights)
  (mp): MessagePassing(
    (layers): ModuleList(
      (0): Compose(
        (first): Convolution(
          (linear_1): Linear(128x0e -> 128x0e | 16384 weights)
          (fc): FullyConnectedNet[8, 64, 64, 384]
          (tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e -> 128x0e+128x1o+128x2e | 384 paths | 384 weights)
          (linear_2): Linear(128x0e+128x1o+128x2e -> 192x0e+64x1o+64x2e | 40960 weights)
          (sc): FullyConnectedTensorProduct(128x0e x 26x0e -> 192x0e+64x1o+64x2e | 638976 paths | 638976 weights)
        )
        (second): Gate (192x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e)
      )
      (1): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x2e -> 64x0e+64x1o+64x2e | 12288 weights)
          (fc): FullyConnectedNet[8, 64, 64, 960]
          (tp): TensorProduct(64x0e+64x1o+64x2e x 1x0e+1x1o+1x2e -> 192x0e+256x1o+128x1e+128x2o+256x2e | 960 paths | 960 weights)
          (linear_2): Linear(192x0e+256x1o+128x1e+128x2o+256x2e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 110592 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x2e x 26x0e -> 320x0e+64x1o+64x1e+64x2o+64x2e | 745472 paths | 745472 weights)
        )
        (second): Gate (320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (2): Compose(
        (first): Convolution(
          (linear_1): Linear(64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0e+64x1o+64x1e+64x2o+64x2e | 20480 weights)
          (fc): FullyConnectedNet[8, 64, 64, 1728]
          (tp): TensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 128x0o+192x0e+384x1o+320x1e+320x2o+384x2e | 1728 paths | 1728 weights)
          (linear_2): Linear(128x0o+192x0e+384x1o+320x1e+320x2o+384x2e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 159744 weights)
          (sc): FullyConnectedTensorProduct(64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 64x0o+320x0e+64x1o+64x1e+64x2o+64x2e | 958464 paths | 958464 weights)
        )
        (second): Gate (64x0o+320x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e)
      )
      (3): Convolution(
        (linear_1): Linear(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e -> 64x0o+64x0e+64x1o+64x1e+64x2o+64x2e | 24576 weights)
        (fc): FullyConnectedNet[8, 64, 64, 192]
        (tp): TensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 1x0e+1x1o+1x2e -> 192x0e | 192 paths | 192 weights)
        (linear_2): Linear(192x0e -> 128x0e | 24576 weights)
        (sc): FullyConnectedTensorProduct(64x0o+64x0e+64x1o+64x1e+64x2o+64x2e x 26x0e -> 128x0e | 212992 paths | 212992 weights)
      )
    )
  )
  (readout): Sequential(
    (0): Linear(128x0e -> 128x0e | 16384 weights)
    (1): SiLU()
    (2): Linear(128x0e -> 1x0e | 128 weights)
  )
)
2024-12-22 11:57:44,328 - INFO - initial lr: 0.000200000, meanAE: 11.160180411021745
2024-12-22 11:58:13,685 - INFO - Epoch 1, train_loss: 14.616942, val_loss: 0.891800, val_mae: 0.717804
2024-12-22 11:58:42,236 - INFO - Epoch 2, train_loss: 0.416538, val_loss: 0.316316, val_mae: 0.447144
2024-12-22 11:59:10,915 - INFO - Epoch 3, train_loss: 0.215929, val_loss: 0.168450, val_mae: 0.308903
2024-12-22 11:59:40,831 - INFO - Epoch 4, train_loss: 0.176823, val_loss: 0.188079, val_mae: 0.345093
2024-12-22 12:00:12,445 - INFO - Epoch 5, train_loss: 0.166632, val_loss: 0.192397, val_mae: 0.345369
2024-12-22 12:00:43,722 - INFO - Epoch 6, train_loss: 0.147286, val_loss: 0.139617, val_mae: 0.277905
2024-12-22 12:01:14,637 - INFO - Epoch 7, train_loss: 0.147614, val_loss: 0.129146, val_mae: 0.270754
2024-12-22 12:01:44,166 - INFO - Epoch 8, train_loss: 0.161607, val_loss: 0.095060, val_mae: 0.224118
2024-12-22 12:02:14,356 - INFO - Epoch 9, train_loss: 0.130394, val_loss: 0.108355, val_mae: 0.243091
2024-12-22 12:02:45,719 - INFO - Epoch 10, train_loss: 0.136774, val_loss: 0.117512, val_mae: 0.232974
2024-12-22 12:03:14,213 - INFO - Epoch 11, train_loss: 0.134608, val_loss: 0.177564, val_mae: 0.338319
2024-12-22 12:03:42,602 - INFO - Epoch 12, train_loss: 0.122971, val_loss: 0.092000, val_mae: 0.220148
2024-12-22 12:04:10,660 - INFO - Epoch 13, train_loss: 0.124409, val_loss: 0.207464, val_mae: 0.390954
2024-12-22 12:04:39,004 - INFO - Epoch 14, train_loss: 0.114183, val_loss: 0.508470, val_mae: 0.489549
2024-12-22 12:05:07,501 - INFO - Epoch 15, train_loss: 0.129894, val_loss: 0.087606, val_mae: 0.208721
2024-12-22 12:05:37,670 - INFO - Epoch 16, train_loss: 0.192479, val_loss: 0.262059, val_mae: 0.418985
2024-12-22 12:06:05,270 - INFO - Epoch 17, train_loss: 0.100133, val_loss: 0.225170, val_mae: 0.411634
2024-12-22 12:06:33,891 - INFO - Epoch 18, train_loss: 0.105878, val_loss: 0.088181, val_mae: 0.221896
2024-12-22 12:07:02,458 - INFO - Epoch 19, train_loss: 0.128783, val_loss: 0.102484, val_mae: 0.239985
2024-12-22 12:07:32,119 - INFO - Epoch 20, train_loss: 0.105008, val_loss: 0.104173, val_mae: 0.253633
2024-12-22 12:08:02,486 - INFO - Epoch 21, train_loss: 0.105545, val_loss: 0.197693, val_mae: 0.299541
2024-12-22 12:08:33,551 - INFO - Epoch 22, train_loss: 0.107780, val_loss: 0.259246, val_mae: 0.385713
2024-12-22 12:09:04,468 - INFO - Epoch 23, train_loss: 0.101749, val_loss: 0.146706, val_mae: 0.285544
2024-12-22 12:09:35,143 - INFO - Epoch 24, train_loss: 0.096013, val_loss: 0.131250, val_mae: 0.271070
2024-12-22 12:10:04,018 - INFO - Epoch 25, train_loss: 0.087826, val_loss: 0.068170, val_mae: 0.183626
2024-12-22 12:10:34,556 - INFO - Epoch 26, train_loss: 0.094878, val_loss: 0.048980, val_mae: 0.158805
2024-12-22 12:11:04,683 - INFO - Epoch 27, train_loss: 0.088885, val_loss: 0.078253, val_mae: 0.204184
2024-12-22 12:11:32,993 - INFO - Epoch 28, train_loss: 0.081006, val_loss: 0.066198, val_mae: 0.199474
2024-12-22 12:12:00,869 - INFO - Epoch 29, train_loss: 0.062880, val_loss: 0.069910, val_mae: 0.201018
2024-12-22 12:12:29,093 - INFO - Epoch 30, train_loss: 0.062928, val_loss: 0.055538, val_mae: 0.176390
2024-12-22 12:12:57,181 - INFO - Epoch 31, train_loss: 0.077943, val_loss: 0.116314, val_mae: 0.277217
2024-12-22 12:13:28,257 - INFO - Epoch 32, train_loss: 0.049304, val_loss: 0.035111, val_mae: 0.131242
2024-12-22 12:13:56,024 - INFO - Epoch 33, train_loss: 0.042220, val_loss: 0.065522, val_mae: 0.206731
2024-12-22 12:14:24,585 - INFO - Epoch 34, train_loss: 0.059550, val_loss: 0.168823, val_mae: 0.287361
2024-12-22 12:14:53,659 - INFO - Epoch 35, train_loss: 0.038969, val_loss: 0.052462, val_mae: 0.179921
2024-12-22 12:15:22,855 - INFO - Epoch 36, train_loss: 0.047596, val_loss: 0.107425, val_mae: 0.272892
2024-12-22 12:15:53,323 - INFO - Epoch 37, train_loss: 0.038831, val_loss: 0.068731, val_mae: 0.171555
2024-12-22 12:16:24,539 - INFO - Epoch 38, train_loss: 0.039857, val_loss: 0.030078, val_mae: 0.117833
2024-12-22 12:16:56,163 - INFO - Epoch 39, train_loss: 0.029890, val_loss: 0.075770, val_mae: 0.203310
2024-12-22 12:17:27,477 - INFO - Epoch 40, train_loss: 0.045321, val_loss: 0.021824, val_mae: 0.106053
2024-12-22 12:17:57,648 - INFO - Epoch 41, train_loss: 0.031087, val_loss: 0.023452, val_mae: 0.108692
2024-12-22 12:18:29,521 - INFO - Epoch 42, train_loss: 0.030202, val_loss: 0.055589, val_mae: 0.176360
2024-12-22 12:18:59,539 - INFO - Epoch 43, train_loss: 0.028453, val_loss: 0.023486, val_mae: 0.102072
2024-12-22 12:19:28,110 - INFO - Epoch 44, train_loss: 0.026521, val_loss: 0.019196, val_mae: 0.097689
2024-12-22 12:19:56,893 - INFO - Epoch 45, train_loss: 0.033745, val_loss: 0.026152, val_mae: 0.121550
2024-12-22 12:20:25,316 - INFO - Epoch 46, train_loss: 0.021548, val_loss: 0.030223, val_mae: 0.124967
2024-12-22 12:20:53,612 - INFO - Epoch 47, train_loss: 0.022790, val_loss: 0.051696, val_mae: 0.156614
2024-12-22 12:21:21,360 - INFO - Epoch 48, train_loss: 0.022074, val_loss: 0.035248, val_mae: 0.124414
2024-12-22 12:21:48,569 - INFO - Epoch 49, train_loss: 0.017730, val_loss: 0.015190, val_mae: 0.083230
2024-12-22 12:22:15,132 - INFO - Epoch 50, train_loss: 0.020246, val_loss: 0.034082, val_mae: 0.131166
2024-12-22 12:22:42,807 - INFO - Epoch 51, train_loss: 0.015984, val_loss: 0.024342, val_mae: 0.120052
2024-12-22 12:23:11,263 - INFO - Epoch 52, train_loss: 0.014966, val_loss: 0.029821, val_mae: 0.125890
2024-12-22 12:23:40,861 - INFO - Epoch 53, train_loss: 0.016169, val_loss: 0.066221, val_mae: 0.207976
2024-12-22 12:24:12,208 - INFO - Epoch 54, train_loss: 0.015938, val_loss: 0.027215, val_mae: 0.110868
2024-12-22 12:24:44,031 - INFO - Epoch 55, train_loss: 0.014228, val_loss: 0.014267, val_mae: 0.078583
2024-12-22 12:25:16,386 - INFO - Epoch 56, train_loss: 0.012918, val_loss: 0.017857, val_mae: 0.088327
2024-12-22 12:25:46,947 - INFO - Epoch 57, train_loss: 0.015221, val_loss: 0.017061, val_mae: 0.083890
2024-12-22 12:26:17,756 - INFO - Epoch 58, train_loss: 0.011584, val_loss: 0.014619, val_mae: 0.085080
2024-12-22 12:26:49,472 - INFO - Epoch 59, train_loss: 0.009871, val_loss: 0.016854, val_mae: 0.095167
2024-12-22 12:27:18,592 - INFO - Epoch 60, train_loss: 0.010244, val_loss: 0.012311, val_mae: 0.076596
2024-12-22 12:27:47,199 - INFO - Epoch 61, train_loss: 0.010957, val_loss: 0.014752, val_mae: 0.079337
2024-12-22 12:28:15,384 - INFO - Epoch 62, train_loss: 0.012430, val_loss: 0.020519, val_mae: 0.108997
2024-12-22 12:28:43,377 - INFO - Epoch 63, train_loss: 0.007406, val_loss: 0.014239, val_mae: 0.082205
2024-12-22 12:29:11,590 - INFO - Epoch 64, train_loss: 0.007539, val_loss: 0.015495, val_mae: 0.084034
2024-12-22 12:29:39,815 - INFO - Epoch 65, train_loss: 0.007212, val_loss: 0.013383, val_mae: 0.077543
2024-12-22 12:30:07,544 - INFO - Epoch 66, train_loss: 0.005284, val_loss: 0.013338, val_mae: 0.075322
2024-12-22 12:30:37,503 - INFO - Epoch 67, train_loss: 0.007033, val_loss: 0.011102, val_mae: 0.066585
2024-12-22 12:31:08,552 - INFO - Epoch 68, train_loss: 0.005120, val_loss: 0.010664, val_mae: 0.064119
2024-12-22 12:31:41,605 - INFO - Epoch 69, train_loss: 0.005404, val_loss: 0.015444, val_mae: 0.080097
2024-12-22 12:32:16,287 - INFO - Epoch 70, train_loss: 0.005179, val_loss: 0.008436, val_mae: 0.061076
2024-12-22 12:32:51,319 - INFO - Epoch 71, train_loss: 0.004368, val_loss: 0.008153, val_mae: 0.059436
2024-12-22 12:33:26,396 - INFO - Epoch 72, train_loss: 0.004501, val_loss: 0.012273, val_mae: 0.071918
2024-12-22 12:33:58,545 - INFO - Epoch 73, train_loss: 0.004254, val_loss: 0.014094, val_mae: 0.077212
2024-12-22 12:34:30,487 - INFO - Epoch 74, train_loss: 0.003267, val_loss: 0.009886, val_mae: 0.058950
2024-12-22 12:35:02,087 - INFO - Epoch 75, train_loss: 0.003234, val_loss: 0.008144, val_mae: 0.056426
2024-12-22 12:35:31,328 - INFO - Epoch 76, train_loss: 0.002939, val_loss: 0.016174, val_mae: 0.098294
2024-12-22 12:36:00,757 - INFO - Epoch 77, train_loss: 0.002284, val_loss: 0.007755, val_mae: 0.055819
2024-12-22 12:36:29,750 - INFO - Epoch 78, train_loss: 0.002334, val_loss: 0.007630, val_mae: 0.053679
2024-12-22 12:36:58,137 - INFO - Epoch 79, train_loss: 0.001994, val_loss: 0.006747, val_mae: 0.051856
2024-12-22 12:37:26,046 - INFO - Epoch 80, train_loss: 0.002429, val_loss: 0.008374, val_mae: 0.054938
2024-12-22 12:37:54,379 - INFO - Epoch 81, train_loss: 0.002137, val_loss: 0.007493, val_mae: 0.054062
2024-12-22 12:38:24,154 - INFO - Epoch 82, train_loss: 0.001560, val_loss: 0.007605, val_mae: 0.053260
2024-12-22 12:38:54,572 - INFO - Epoch 83, train_loss: 0.001454, val_loss: 0.007630, val_mae: 0.052029
2024-12-22 12:39:26,570 - INFO - Epoch 84, train_loss: 0.001332, val_loss: 0.007564, val_mae: 0.052733
2024-12-22 12:40:00,650 - INFO - Epoch 85, train_loss: 0.001231, val_loss: 0.006833, val_mae: 0.051316
2024-12-22 12:40:35,400 - INFO - Epoch 86, train_loss: 0.001143, val_loss: 0.006582, val_mae: 0.051154
2024-12-22 12:41:09,781 - INFO - Epoch 87, train_loss: 0.000969, val_loss: 0.006643, val_mae: 0.049918
2024-12-22 12:41:43,489 - INFO - Epoch 88, train_loss: 0.000894, val_loss: 0.006688, val_mae: 0.049866
2024-12-22 12:42:16,082 - INFO - Epoch 89, train_loss: 0.000802, val_loss: 0.006778, val_mae: 0.049404
2024-12-22 12:42:47,910 - INFO - Epoch 90, train_loss: 0.000835, val_loss: 0.006512, val_mae: 0.049530
2024-12-22 12:43:17,002 - INFO - Epoch 91, train_loss: 0.000724, val_loss: 0.006467, val_mae: 0.048636
2024-12-22 12:43:46,013 - INFO - Epoch 92, train_loss: 0.000659, val_loss: 0.006471, val_mae: 0.048968
2024-12-22 12:44:15,289 - INFO - Epoch 93, train_loss: 0.000638, val_loss: 0.006244, val_mae: 0.048056
2024-12-22 12:44:44,621 - INFO - Epoch 94, train_loss: 0.000585, val_loss: 0.006448, val_mae: 0.048602
2024-12-22 12:45:13,154 - INFO - Epoch 95, train_loss: 0.000563, val_loss: 0.006249, val_mae: 0.048347
2024-12-22 12:45:41,465 - INFO - Epoch 96, train_loss: 0.000547, val_loss: 0.006339, val_mae: 0.048097
2024-12-22 12:46:09,523 - INFO - Epoch 97, train_loss: 0.000529, val_loss: 0.006302, val_mae: 0.048043
2024-12-22 12:46:39,683 - INFO - Epoch 98, train_loss: 0.000517, val_loss: 0.006292, val_mae: 0.048002
2024-12-22 12:47:10,571 - INFO - Epoch 99, train_loss: 0.000505, val_loss: 0.006300, val_mae: 0.047990
2024-12-22 12:47:43,833 - INFO - Epoch 100, train_loss: 0.000500, val_loss: 0.006313, val_mae: 0.048014
2024-12-22 12:47:45,492 - INFO - Test MAE: 0.047990 with best model at Epoch 99
